<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>14 Confidence Intervals | MATH 340 Notes</title>
  <meta name="description" content="14 Confidence Intervals | MATH 340 Notes" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="14 Confidence Intervals | MATH 340 Notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="14 Confidence Intervals | MATH 340 Notes" />
  
  
  

<meta name="author" content="Mike Hitchman" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estimation.html"/>
<link rel="next" href="sampling-in-R.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://github.com/mphitchman/math340.git" target="blank">Math 340 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="sets.html"><a href="sets.html"><i class="fa fa-check"></i><b>2</b> Sets</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sets.html"><a href="sets.html#algebra-of-sets"><i class="fa fa-check"></i><b>2.1</b> Algebra of Sets</a></li>
<li class="chapter" data-level="2.2" data-path="sets.html"><a href="sets.html#size-of-sets"><i class="fa fa-check"></i><b>2.2</b> Set sizes</a></li>
<li class="chapter" data-level="2.3" data-path="sets.html"><a href="sets.html#sets-in-r"><i class="fa fa-check"></i><b>2.3</b> Sets in R</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html"><i class="fa fa-check"></i><b>3</b> Discrete Probability Distributions</a>
<ul>
<li class="chapter" data-level="3.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#sample-space"><i class="fa fa-check"></i><b>3.1</b> Sample Space</a></li>
<li class="chapter" data-level="3.2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#discrete-rv-initial"><i class="fa fa-check"></i><b>3.2</b> Discrete Random Variables</a></li>
<li class="chapter" data-level="3.3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#calculating-probabilities"><i class="fa fa-check"></i><b>3.3</b> Calculating Probabilities</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#sample-point-method"><i class="fa fa-check"></i><b>3.3.1</b> Sample Point Method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="counting.html"><a href="counting.html"><i class="fa fa-check"></i><b>4</b> Counting Techniques</a>
<ul>
<li class="chapter" data-level="4.1" data-path="counting.html"><a href="counting.html#multipiclation-principle"><i class="fa fa-check"></i><b>4.1</b> Multipiclation Principle</a></li>
<li class="chapter" data-level="4.2" data-path="counting.html"><a href="counting.html#permutations"><i class="fa fa-check"></i><b>4.2</b> Permutations</a></li>
<li class="chapter" data-level="4.3" data-path="counting.html"><a href="counting.html#combinations"><i class="fa fa-check"></i><b>4.3</b> Combinations</a></li>
<li class="chapter" data-level="4.4" data-path="counting.html"><a href="counting.html#multinomial-coefficients"><i class="fa fa-check"></i><b>4.4</b> Multinomial Coefficients</a></li>
<li class="chapter" data-level="4.5" data-path="counting.html"><a href="counting.html#balls-and-bins"><i class="fa fa-check"></i><b>4.5</b> Balls and Bins</a></li>
<li class="chapter" data-level="4.6" data-path="counting.html"><a href="counting.html#prob-with-counting-tools"><i class="fa fa-check"></i><b>4.6</b> Calculating More Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>5</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="5.1" data-path="probability-theory.html"><a href="probability-theory.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>5.1</b> Conditional Probability and Independence</a></li>
<li class="chapter" data-level="5.2" data-path="probability-theory.html"><a href="probability-theory.html#two-laws-of-probability"><i class="fa fa-check"></i><b>5.2</b> Two Laws of Probability</a></li>
<li class="chapter" data-level="5.3" data-path="probability-theory.html"><a href="probability-theory.html#event-composition-method"><i class="fa fa-check"></i><b>5.3</b> Event-Composition Method</a></li>
<li class="chapter" data-level="5.4" data-path="probability-theory.html"><a href="probability-theory.html#bayes-rule"><i class="fa fa-check"></i><b>5.4</b> Bayes’ Rule</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>6</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#expected-value"><i class="fa fa-check"></i><b>6.1</b> Expected Value</a></li>
<li class="chapter" data-level="6.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance"><i class="fa fa-check"></i><b>6.2</b> Variance</a></li>
<li class="chapter" data-level="6.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#properties-of-expected-value"><i class="fa fa-check"></i><b>6.3</b> Properties of Expected Value</a></li>
<li class="chapter" data-level="6.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#tchebysheffs-theorem"><i class="fa fa-check"></i><b>6.4</b> Tchebysheff’s Theorem</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html"><i class="fa fa-check"></i><b>7</b> Important Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="7.1" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#binomial"><i class="fa fa-check"></i><b>7.1</b> Binomial Distributions</a></li>
<li class="chapter" data-level="7.2" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#geometric"><i class="fa fa-check"></i><b>7.2</b> Geometric Distributions</a></li>
<li class="chapter" data-level="7.3" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#negative-binomial"><i class="fa fa-check"></i><b>7.3</b> Negative Binomial Distribution</a></li>
<li class="chapter" data-level="7.4" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#hypergometric"><i class="fa fa-check"></i><b>7.4</b> Hypergeometric Distribution</a></li>
<li class="chapter" data-level="7.5" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#poisson"><i class="fa fa-check"></i><b>7.5</b> Poisson Distribution</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#poisson-process"><i class="fa fa-check"></i><b>7.5.1</b> Poisson Process</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="moments-and-moment-generating-functions.html"><a href="moments-and-moment-generating-functions.html"><i class="fa fa-check"></i><b>8</b> Moments and Moment-Generating Functions</a></li>
<li class="chapter" data-level="9" data-path="continuous-rv.html"><a href="continuous-rv.html"><i class="fa fa-check"></i><b>9</b> Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="9.1" data-path="continuous-rv.html"><a href="continuous-rv.html#distribution-functions"><i class="fa fa-check"></i><b>9.1</b> Distribution Functions</a></li>
<li class="chapter" data-level="9.2" data-path="continuous-rv.html"><a href="continuous-rv.html#expected-value-for-continuous-random-variables"><i class="fa fa-check"></i><b>9.2</b> Expected Value for Continuous Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html"><i class="fa fa-check"></i><b>10</b> Important Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="10.1" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#uniform-continuous"><i class="fa fa-check"></i><b>10.1</b> Uniform Distribution</a></li>
<li class="chapter" data-level="10.2" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#exponential-distribution"><i class="fa fa-check"></i><b>10.2</b> Exponential Distribution</a></li>
<li class="chapter" data-level="10.3" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#normal"><i class="fa fa-check"></i><b>10.3</b> Normal Distribution</a></li>
<li class="chapter" data-level="10.4" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#gamma-distribution"><i class="fa fa-check"></i><b>10.4</b> Gamma Distribution</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#exponential-distribution-1"><i class="fa fa-check"></i><b>10.4.1</b> Exponential Distribution</a></li>
<li class="chapter" data-level="10.4.2" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#chi-square-distribution"><i class="fa fa-check"></i><b>10.4.2</b> Chi-square distribution</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#beta-distribution"><i class="fa fa-check"></i><b>10.5</b> Beta Distribution</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="mgf.html"><a href="mgf.html"><i class="fa fa-check"></i><b>11</b> Moment Generating Functions</a></li>
<li class="chapter" data-level="12" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>12</b> Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="12.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#sums-of-random-variables"><i class="fa fa-check"></i><b>12.1</b> Sums of Random Variables</a></li>
<li class="chapter" data-level="12.2" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#t-distribution"><i class="fa fa-check"></i><b>12.2</b> T distribution</a></li>
<li class="chapter" data-level="12.3" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>12.3</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="12.4" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#normal-approximation-to-a-binomial-distribution"><i class="fa fa-check"></i><b>12.4</b> Normal Approximation to a binomial distribution</a>
<ul>
<li class="chapter" data-level="" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#continuity-correction"><i class="fa fa-check"></i>Continuity Correction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>13</b> Estimation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="estimation.html"><a href="estimation.html#unbiased-estimators"><i class="fa fa-check"></i><b>13.1</b> Unbiased Estimators</a></li>
<li class="chapter" data-level="13.2" data-path="estimation.html"><a href="estimation.html#order-statistics"><i class="fa fa-check"></i><b>13.2</b> Order Statistics</a></li>
<li class="chapter" data-level="13.3" data-path="estimation.html"><a href="estimation.html#common-unbiased-estimators"><i class="fa fa-check"></i><b>13.3</b> Common Unbiased Estimators</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="estimation.html"><a href="estimation.html#estimating-mu-a-population-mean"><i class="fa fa-check"></i><b>13.3.1</b> Estimating <span class="math inline">\(\mu,\)</span> a population mean</a></li>
<li class="chapter" data-level="13.3.2" data-path="estimation.html"><a href="estimation.html#estimating-p-a-population-proportion"><i class="fa fa-check"></i><b>13.3.2</b> Estimating <span class="math inline">\(p,\)</span> a population proportion</a></li>
<li class="chapter" data-level="13.3.3" data-path="estimation.html"><a href="estimation.html#estimating-mu_1---mu_2-the-difference-of-two-population-means"><i class="fa fa-check"></i><b>13.3.3</b> Estimating <span class="math inline">\(\mu_1 - \mu_2,\)</span> the difference of two population means</a></li>
<li class="chapter" data-level="13.3.4" data-path="estimation.html"><a href="estimation.html#estimating-p_1---p_2-the-difference-of-two-population-proportions"><i class="fa fa-check"></i><b>13.3.4</b> Estimating <span class="math inline">\(p_1 - p_2,\)</span> the difference of two population proportions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>14</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="14.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#pivotal-quantities"><i class="fa fa-check"></i><b>14.1</b> Pivotal Quantities</a></li>
<li class="chapter" data-level="14.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#large-sample-confidence-intervals"><i class="fa fa-check"></i><b>14.2</b> Large sample confidence intervals</a>
<ul>
<li class="chapter" data-level="" data-path="confidence-intervals.html"><a href="confidence-intervals.html#confidence-intervals-for-mu_1-mu_2"><i class="fa fa-check"></i>Confidence Intervals for <span class="math inline">\(\mu_1-\mu_2\)</span></a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Using R</b></span></li>
<li class="chapter" data-level="A" data-path="sampling-in-R.html"><a href="sampling-in-R.html"><i class="fa fa-check"></i><b>A</b> Sampling in R</a>
<ul>
<li class="chapter" data-level="A.1" data-path="sampling-in-R.html"><a href="sampling-in-R.html#vectors-R"><i class="fa fa-check"></i><b>A.1</b> Data vectors</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#vector-types"><i class="fa fa-check"></i>vector types</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#matrices"><i class="fa fa-check"></i>Matrices</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#data-frames"><i class="fa fa-check"></i>data frames</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#common-vector-commands"><i class="fa fa-check"></i>common vector commands</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#comparison-operators"><i class="fa fa-check"></i>Comparison Operators</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sum-and-which"><i class="fa fa-check"></i><code>sum()</code> and <code>which()</code></a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#extracting-elements"><i class="fa fa-check"></i>extracting elements</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#comparing-vectors"><i class="fa fa-check"></i>comparing vectors</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#vector-arithmetic"><i class="fa fa-check"></i>vector arithmetic</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#concatenate-vectors"><i class="fa fa-check"></i>concatenate vectors</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="sampling-in-R.html"><a href="sampling-in-R.html#special-vectors"><i class="fa fa-check"></i><b>A.2</b> Special vectors</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#consecutive-integers"><i class="fa fa-check"></i>consecutive integers</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#letters"><i class="fa fa-check"></i>letters</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#rep"><i class="fa fa-check"></i><code>rep()</code></a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#table"><i class="fa fa-check"></i><code>table()</code></a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#seq"><i class="fa fa-check"></i><code>seq()</code></a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sampling-in-R-section"><i class="fa fa-check"></i><b>A.3</b> Sampling</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sample-options"><i class="fa fa-check"></i><code>sample()</code> options</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sample-without-replacement"><i class="fa fa-check"></i>Sample without replacement</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sample-with-replacement"><i class="fa fa-check"></i>Sample with replacement</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sample-with-custom-probabilities"><i class="fa fa-check"></i>Sample with custom probabilities</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#example-lefties"><i class="fa fa-check"></i>Example: Lefties</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="sampling-in-R.html"><a href="sampling-in-R.html#repeated-sampling"><i class="fa fa-check"></i><b>A.4</b> Repeated Sampling</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#using-a-for-loop"><i class="fa fa-check"></i>using a <code>for</code> loop</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#using-replicate"><i class="fa fa-check"></i>using <code>replicate()</code></a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sampling-commands"><i class="fa fa-check"></i><b>A.5</b> Summary of R commands</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#defining-vectors"><i class="fa fa-check"></i>defining vectors</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#summarizing-vectors"><i class="fa fa-check"></i>summarizing vectors</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sampling-from-vectors"><i class="fa fa-check"></i>sampling from vectors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="R-sim-probability.html"><a href="R-sim-probability.html"><i class="fa fa-check"></i><b>B</b> Simulating Probability in R</a>
<ul>
<li class="chapter" data-level="B.1" data-path="R-sim-probability.html"><a href="R-sim-probability.html#diff-2dice-R"><i class="fa fa-check"></i><b>B.1</b> Difference of two dice</a></li>
<li class="chapter" data-level="B.2" data-path="R-sim-probability.html"><a href="R-sim-probability.html#license-plates-R"><i class="fa fa-check"></i><b>B.2</b> Oregon License Plates</a></li>
<li class="chapter" data-level="B.3" data-path="R-sim-probability.html"><a href="R-sim-probability.html#id_10sided-die-R"><i class="fa fa-check"></i><b>B.3</b> Rolling a 10-sided die</a></li>
<li class="chapter" data-level="B.4" data-path="R-sim-probability.html"><a href="R-sim-probability.html#marbles-urn-R"><i class="fa fa-check"></i><b>B.4</b> Marbles from an urn</a></li>
<li class="chapter" data-level="B.5" data-path="R-sim-probability.html"><a href="R-sim-probability.html#flip-coin-R"><i class="fa fa-check"></i><b>B.5</b> Tracking runs of Heads in coin flips</a></li>
<li class="chapter" data-level="B.6" data-path="R-sim-probability.html"><a href="R-sim-probability.html#partition-set-R"><i class="fa fa-check"></i><b>B.6</b> Splitting a set into multiple subsets</a></li>
<li class="chapter" data-level="B.7" data-path="R-sim-probability.html"><a href="R-sim-probability.html#pollsters-R"><i class="fa fa-check"></i><b>B.7</b> Pollsters</a></li>
<li class="chapter" data-level="B.8" data-path="R-sim-probability.html"><a href="R-sim-probability.html#same-birthday-R"><i class="fa fa-check"></i><b>B.8</b> Matching Birthdays</a></li>
<li class="chapter" data-level="B.9" data-path="R-sim-probability.html"><a href="R-sim-probability.html#flipping-coins-with-fibonacci"><i class="fa fa-check"></i><b>B.9</b> Flipping Coins with Fibonacci</a></li>
<li class="chapter" data-level="B.10" data-path="R-sim-probability.html"><a href="R-sim-probability.html#seats-on-an-airplane"><i class="fa fa-check"></i><b>B.10</b> Seats on an airplane</a></li>
<li class="chapter" data-level="B.11" data-path="R-sim-probability.html"><a href="R-sim-probability.html#drawing-names-for-homemades"><i class="fa fa-check"></i><b>B.11</b> Drawing names for Homemades</a>
<ul>
<li class="chapter" data-level="" data-path="R-sim-probability.html"><a href="R-sim-probability.html#mathematical-addendum-to-the-question-of-drawing-names."><i class="fa fa-check"></i>Mathematical addendum to the question of drawing names.</a></li>
</ul></li>
<li class="chapter" data-level="B.12" data-path="R-sim-probability.html"><a href="R-sim-probability.html#idiots-delight"><i class="fa fa-check"></i><b>B.12</b> Idiot’s Delight</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="R-discreteRV.html"><a href="R-discreteRV.html"><i class="fa fa-check"></i><b>C</b> Discrete Random Variables in R</a>
<ul>
<li class="chapter" data-level="C.1" data-path="R-discreteRV.html"><a href="R-discreteRV.html#binomialR"><i class="fa fa-check"></i><b>C.1</b> Binomial <code>binom</code></a>
<ul>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#dbinom---probability-function"><i class="fa fa-check"></i><code>dbinom()</code> - probability function</a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#pbinom---cumulative-probability"><i class="fa fa-check"></i><code>pbinom()</code> - cumulative probability</a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#qbinom---quantiles"><i class="fa fa-check"></i><code>qbinom()</code> - quantiles</a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#rbinom---sampling"><i class="fa fa-check"></i><code>rbinom()</code> - sampling</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="R-discreteRV.html"><a href="R-discreteRV.html#geometricR"><i class="fa fa-check"></i><b>C.2</b> Geometric <code>geom</code></a></li>
<li class="chapter" data-level="C.3" data-path="R-discreteRV.html"><a href="R-discreteRV.html#negbinomR"><i class="fa fa-check"></i><b>C.3</b> Negative Binomial <code>nbinom</code></a></li>
<li class="chapter" data-level="C.4" data-path="R-discreteRV.html"><a href="R-discreteRV.html#hyperR"><i class="fa fa-check"></i><b>C.4</b> Hypergeometric <code>hyper</code></a></li>
<li class="chapter" data-level="C.5" data-path="R-discreteRV.html"><a href="R-discreteRV.html#poissonR"><i class="fa fa-check"></i><b>C.5</b> Poisson <code>pois</code></a></li>
<li class="chapter" data-level="C.6" data-path="R-discreteRV.html"><a href="R-discreteRV.html#custom-discrete-R"><i class="fa fa-check"></i><b>C.6</b> Homemade Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#expected-value-of-x"><i class="fa fa-check"></i>Expected Value of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#variance-of-x"><i class="fa fa-check"></i>Variance of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#distribution-plots"><i class="fa fa-check"></i>Distribution Plots</a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#sampling"><i class="fa fa-check"></i>Sampling</a></li>
<li class="chapter" data-level="C.6.1" data-path="R-discreteRV.html"><a href="R-discreteRV.html#discrete-uniform-distribution"><i class="fa fa-check"></i><b>C.6.1</b> Discrete Uniform Distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="R-continuousRV.html"><a href="R-continuousRV.html"><i class="fa fa-check"></i><b>D</b> Continuous Random Variables in R</a>
<ul>
<li class="chapter" data-level="D.1" data-path="R-continuousRV.html"><a href="R-continuousRV.html#unifR"><i class="fa fa-check"></i><b>D.1</b> Uniform Distribution</a>
<ul>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#picking-random-numbers"><i class="fa fa-check"></i>Picking random numbers</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#picking-random-points-in-the-unit-square"><i class="fa fa-check"></i>Picking random points in the unit square</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimate-the-value-of-pi"><i class="fa fa-check"></i>Estimate the value of <span class="math inline">\(\pi\)</span></a></li>
</ul></li>
<li class="chapter" data-level="D.2" data-path="R-continuousRV.html"><a href="R-continuousRV.html#normalR"><i class="fa fa-check"></i><b>D.2</b> Normal Distribution <code>norm</code></a>
<ul>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#sampling-distribution-of-a-sample-mean"><i class="fa fa-check"></i>Sampling Distribution of a sample mean</a></li>
</ul></li>
<li class="chapter" data-level="D.3" data-path="R-continuousRV.html"><a href="R-continuousRV.html#expR"><i class="fa fa-check"></i><b>D.3</b> Exponential Distribution <code>exp</code></a>
<ul>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#a-memoryless-distribution"><i class="fa fa-check"></i>A Memoryless distribution</a></li>
</ul></li>
<li class="chapter" data-level="D.4" data-path="R-continuousRV.html"><a href="R-continuousRV.html#gammaR"><i class="fa fa-check"></i><b>D.4</b> Gamma Distribution <code>gamma</code></a></li>
<li class="chapter" data-level="D.5" data-path="R-continuousRV.html"><a href="R-continuousRV.html#chiR"><i class="fa fa-check"></i><b>D.5</b> Chi-square Distribution <code>chisq</code></a></li>
<li class="chapter" data-level="D.6" data-path="R-continuousRV.html"><a href="R-continuousRV.html#betaR"><i class="fa fa-check"></i><b>D.6</b> Beta distribution <code>beta</code></a></li>
<li class="chapter" data-level="D.7" data-path="R-continuousRV.html"><a href="R-continuousRV.html#custom-continuous-R"><i class="fa fa-check"></i><b>D.7</b> Homemade Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#input-the-density-function"><i class="fa fa-check"></i>Input the density function</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#visualize-the-density-function"><i class="fa fa-check"></i>Visualize the density function</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimating-integrals-with-riemann-sums"><i class="fa fa-check"></i>Estimating Integrals with Riemann Sums</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimating-probabilities"><i class="fa fa-check"></i>Estimating Probabilities</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#the-distribution-function-fx"><i class="fa fa-check"></i>The distribution function <span class="math inline">\(F(X)\)</span></a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimating-moments"><i class="fa fa-check"></i>Estimating Moments</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#expected-value-1"><i class="fa fa-check"></i>Expected Value</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH 340 Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="confidence-intervals" class="section level1 hasAnchor" number="14">
<h1><span class="header-section-number">14</span> Confidence Intervals<a href="confidence-intervals.html#confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In many of the examples in Chapter <a href="estimation.html#estimation">13</a> we built confidence intervals, interval estimators that specify the method for using a sample to calculate two numbers that form the endpoints of an interval that likely (with some pre-assigned probability) contains the paramter of interest.</p>
<div id="pivotal-quantities" class="section level2 hasAnchor" number="14.1">
<h2><span class="header-section-number">14.1</span> Pivotal Quantities<a href="confidence-intervals.html#pivotal-quantities" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Here is the general scene for a <strong>confidence interval</strong> for a parameter <span class="math inline">\(\theta\)</span>. We use a sample to determine the <strong>lower</strong> and <strong>upper confidence limit estimators</strong>, <span class="math inline">\(\hat{\theta}_L\)</span> and <span class="math inline">\(\hat{\theta}_U\)</span>. If <span class="math display">\[P(\hat{\theta}_L \leq \theta \leq \hat{\theta_U}) = 1 - \alpha\]</span> the probability <span class="math inline">\(1-\alpha\)</span> is called the <strong>confidence level</strong>.</p>
<p>One method for finding confidence intervals is called the <strong>pivotal method</strong>, which leverages a <strong>pivotal quantity</strong>, which is a quantity with two features:</p>
<ol style="list-style-type: decimal">
<li>It is a function of the data <span class="math inline">\(X_1, \ldots, X_n\)</span> and the parameter of interest <span class="math inline">\(\theta,\)</span> and</li>
<li>its probability distribution does not depend on <span class="math inline">\(\theta\)</span>.</li>
</ol>
<div class="example">
<p><span id="exm:unlabeled-div-62" class="example"><strong>Example 14.1  </strong></span>If a population mean <span class="math inline">\(\mu\)</span> is the parameter of interest, and we have sample <span class="math inline">\(X_1, \ldots, X_n,\)</span> then a good pivotal quantity, assuming <span class="math inline">\(X_i\)</span> is approximately <span class="math inline">\(N(\mu,\sigma),\)</span> is <span class="math display">\[T = \frac{\overline{X}-\mu}{S/\sqrt{n}}.\]</span> It meets both requirements here: it is a function of the data and the parameter <span class="math inline">\(\mu,\)</span> and it lives in a <span class="math inline">\(t(n-1)\)</span> distribution, which is independent of <span class="math inline">\(\mu\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-63" class="example"><strong>Example 14.2  </strong></span>If a population proportion <span class="math inline">\(p\)</span> is the parameter of interest, and we have sample proportion <span class="math inline">\(\hat{p}\)</span> (from a sample of size <span class="math inline">\(n\)</span>), then the pivotal quantity <span class="math display">\[Z = \frac{\hat{p}-p}{\sqrt{\hat{p}(1-\hat{p})/n}}\]</span> is approximately <span class="math inline">\(N(0,1),\)</span> a distribution independent of <span class="math inline">\(p\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-64" class="example"><strong>Example 14.3  </strong></span>Consider <span class="math inline">\(X_1, \ldots, X_n\)</span> drawn from the uniform distribution <span class="math inline">\(U(0,\theta)\)</span> and <span class="math inline">\(Y = \text{max}(X_1, \ldots, X_n)\)</span>. We proved in Example <a href="estimation.html#exm:estimating-uniform-parameter">13.1</a> that <span class="math display">\[F_Y(y) = \left(\frac{y}{\theta}\right)^n ~~~\text{ and }~~~ f_Y(y) = \frac{n}{\theta^n}y^{n-1},\]</span> for <span class="math inline">\(0 \leq y \leq \theta\)</span>.
Now, let <span class="math inline">\(U = \frac{1}{\theta}Y,\)</span> which is just a function of the data and <span class="math inline">\(\theta\)</span>.</p>
<p>The distribution function for <span class="math inline">\(U\)</span> is
<span class="math display">\[\begin{align*}
F_U(u) &amp;= P(U \leq u)\\
      &amp;= P(Y/\theta \leq u)\\
      &amp;= P(Y \leq u\cdot \theta)\\
      &amp;= F_Y(u\theta) \\
      &amp;= \left(\frac{u\theta}{\theta}\right)^n &amp;\text{ for } 0 \leq u \leq 1\\
      &amp;= u^n &amp; \text{ for } 0 \leq u \leq 1,
\end{align*}\]</span></p>
<p>which doesn’t depend on <span class="math inline">\(\theta\)</span>. So <span class="math inline">\(U = Y/\theta\)</span> is a pivotal quantity.</p>
<p>Let’s use <span class="math inline">\(U\)</span> to build a 95% confidence interval for <span class="math inline">\(\theta\)</span> based on a sample <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> drawn from the uniform distribution <span class="math inline">\(U(0,\theta)\)</span>.</p>
<p>In particular, we find estimators <span class="math inline">\(\hat{\theta}_L\)</span> and <span class="math inline">\(\hat{\theta}_U\)</span> so that <span class="math inline">\(P(\hat{\theta}_L \leq \theta \leq \hat{\theta}_U) = .95\)</span>.</p>
<p>Well, we know the distribution of the pivotal quantity <span class="math inline">\(U = Y/\theta,\)</span> where <span class="math inline">\(Y\)</span> is the max of the data, so one solution here is to find constants <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> between 0 and 1 so that</p>
<ul>
<li><span class="math inline">\(P(U &lt; a) = 0.025\)</span></li>
<li><span class="math inline">\(P(U &gt; b) = 0.025\)</span></li>
</ul>
<p><span class="math display">\[.025 = P(U &lt; a) = F_U(a) = a^n \implies a = \sqrt[n]{.025}\]</span>
and
<span class="math display">\[.025 = P(U &gt; b) = 1-F_U(b) = 1 - b^n \implies b = \sqrt[n]{.975}.\]</span>
With this we obtain a general form for a 95% confidence interval for <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[\begin{align*}
.95 &amp;= P\left(\frac{1}{\sqrt[n]{.025}} &lt; U &lt; \frac{1}{\sqrt[n]{.975}}\right)\\
    &amp;= P\left(\frac{1}{\sqrt[n]{.025}} &lt; \frac{Y}{\theta} &lt; \frac{1}{\sqrt[n]{.975}}\right)\\
    &amp;= P\left(\frac{1}{\sqrt[n]{.025}} &gt; \frac{\theta}{Y} &gt; \frac{1}{\sqrt[n]{.975}}\right)\\
    &amp;= P\left(\frac{Y}{\sqrt[n]{.975}} &lt; \theta &lt; \frac{Y}{\sqrt[n]{.025}}\right).
\end{align*}\]</span></p>
<p>We see that <span class="math inline">\(\hat{\theta}_L = \frac{Y}{\sqrt[n]{.975}}\)</span> and <span class="math inline">\(\hat{\theta}_U = \frac{Y}{\sqrt[n]{.025}}\)</span>.</p>
<p>Let’s put this interval formula to use. Here’s a random sample of size 25 drawn in R from a <span class="math inline">\(U(0,64)\)</span> distribution (though let’s pretend we don’t actually know <span class="math inline">\(\theta = 64\)</span> here.)</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="confidence-intervals.html#cb30-1" tabindex="-1"></a>theta <span class="ot">=</span> <span class="dv">64</span></span>
<span id="cb30-2"><a href="confidence-intervals.html#cb30-2" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">25</span></span>
<span id="cb30-3"><a href="confidence-intervals.html#cb30-3" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">runif</span>(n,<span class="dv">0</span>,theta)</span>
<span id="cb30-4"><a href="confidence-intervals.html#cb30-4" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">max</span>(x)</span>
<span id="cb30-5"><a href="confidence-intervals.html#cb30-5" tabindex="-1"></a>L <span class="ot">=</span> y<span class="sc">/</span>(.<span class="dv">975</span>)<span class="sc">^</span>(<span class="dv">1</span><span class="sc">/</span>n) <span class="co">#lower bound estimator for 95% CI</span></span>
<span id="cb30-6"><a href="confidence-intervals.html#cb30-6" tabindex="-1"></a>U <span class="ot">=</span> y<span class="sc">/</span>(.<span class="dv">025</span>)<span class="sc">^</span>(<span class="dv">1</span><span class="sc">/</span>n) <span class="co">#upper bound estimator for 95% CI</span></span>
<span id="cb30-7"><a href="confidence-intervals.html#cb30-7" tabindex="-1"></a><span class="fu">c</span>(L,U) <span class="co">#confidence interval</span></span></code></pre></div>
<pre><code>## [1] 60.10592 69.59208</code></pre>
<p>Did our confidence interval actually capture the value of the parameter (64)?
The confidence level of 95% gives us confidence that it does, in this sense: If we were to repeat the sampling procedure a large number of times, each time using our new sample to determine a new confidence interval for <span class="math inline">\(\theta,\)</span> then we should expect about 95% of the intervals to contain the parameter <span class="math inline">\(\theta\)</span>.</p>
<p>We can check this using R, first writing a little function out of the code above for producing the interval.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="confidence-intervals.html#cb32-1" tabindex="-1"></a>conf_int_for_theta <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">n=</span><span class="dv">25</span>,<span class="at">theta=</span><span class="dv">64</span>){</span>
<span id="cb32-2"><a href="confidence-intervals.html#cb32-2" tabindex="-1"></a>  x <span class="ot">=</span> <span class="fu">runif</span>(n,<span class="dv">0</span>,theta)</span>
<span id="cb32-3"><a href="confidence-intervals.html#cb32-3" tabindex="-1"></a>  y <span class="ot">=</span> <span class="fu">max</span>(x)</span>
<span id="cb32-4"><a href="confidence-intervals.html#cb32-4" tabindex="-1"></a>  L <span class="ot">=</span> y<span class="sc">/</span>(.<span class="dv">975</span>)<span class="sc">^</span>(<span class="dv">1</span><span class="sc">/</span>n) </span>
<span id="cb32-5"><a href="confidence-intervals.html#cb32-5" tabindex="-1"></a>  U <span class="ot">=</span> y<span class="sc">/</span>(.<span class="dv">025</span>)<span class="sc">^</span>(<span class="dv">1</span><span class="sc">/</span>n)</span>
<span id="cb32-6"><a href="confidence-intervals.html#cb32-6" tabindex="-1"></a>  check <span class="ot">=</span> <span class="fu">ifelse</span>(((L <span class="sc">&lt;=</span> theta)<span class="sc">&amp;</span>(theta <span class="sc">&lt;=</span> U)),<span class="dv">1</span>,<span class="dv">0</span>)<span class="co">#1 if interval captures theta, 0 else</span></span>
<span id="cb32-7"><a href="confidence-intervals.html#cb32-7" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">c</span>(L,U,check)) <span class="co">#returns the interval and whether it captured theta</span></span>
<span id="cb32-8"><a href="confidence-intervals.html#cb32-8" tabindex="-1"></a>}</span>
<span id="cb32-9"><a href="confidence-intervals.html#cb32-9" tabindex="-1"></a></span>
<span id="cb32-10"><a href="confidence-intervals.html#cb32-10" tabindex="-1"></a>results <span class="ot">=</span> <span class="fu">c</span>() <span class="co"># a vector storing whether interval generated from data captures theta, for 100 trials</span></span>
<span id="cb32-11"><a href="confidence-intervals.html#cb32-11" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb32-12"><a href="confidence-intervals.html#cb32-12" tabindex="-1"></a>  results[i]<span class="ot">=</span><span class="fu">conf_int_for_theta</span>()[<span class="dv">3</span>]</span>
<span id="cb32-13"><a href="confidence-intervals.html#cb32-13" tabindex="-1"></a>}</span>
<span id="cb32-14"><a href="confidence-intervals.html#cb32-14" tabindex="-1"></a><span class="fu">table</span>(results)</span></code></pre></div>
<pre><code>## results
##  0  1 
##  3 97</code></pre>
<p>In this simulation we drew 100 different random samples of size 25, each time generating a confidence interval for <span class="math inline">\(\theta\)</span> and found that 97 of the 100 intervals captured <span class="math inline">\(\theta\)</span>. We would expect in the long run that 95% of such confidence intervals would capture <span class="math inline">\(\theta\)</span>.</p>
</div>
<p>We have, generally,</p>
<ul>
<li><strong>2-sided confidence intervals for <span class="math inline">\(\theta\)</span></strong>: <span class="math inline">\([\hat{\theta}_L,\hat{\theta}_U],\)</span> where <span class="math inline">\(P(\hat{\theta}_L \leq \theta \leq \hat{\theta}_U)=1-\alpha,\)</span></li>
<li><strong>1-sided confidence intervals for <span class="math inline">\(\theta\)</span></strong>:
<ul>
<li><span class="math inline">\([\hat{\theta}_L,\infty),\)</span> where <span class="math inline">\(P(\hat{\theta}_L \leq \theta)=1-\alpha,\)</span></li>
<li><span class="math inline">\((-\infty,\hat{\theta}_U],\)</span> where <span class="math inline">\(P(\theta \leq \hat{\theta}_U)=1-\alpha\)</span>.</li>
</ul></li>
</ul>
<p>The interval <span class="math inline">\([\hat{\theta}_L,\infty)\)</span> is called a <strong>lower 1-sided</strong> confidence interval, and in this case <span class="math inline">\(\hat{\theta}_L\)</span> is called the <strong>lower confidence limit</strong>, and <span class="math inline">\((-\infty,\hat{\theta}_U]\)</span> is called an <strong>upper 1-sided</strong> confidence interval, and in this case <span class="math inline">\(\hat{\theta}_U\)</span> is called the <strong>upper confidence limit</strong></p>
<p>Goals for a good confidence interval:</p>
<ol style="list-style-type: decimal">
<li>It captures <span class="math inline">\(\theta\)</span> with high probability</li>
<li>It is narrow!</li>
</ol>
</div>
<div id="large-sample-confidence-intervals" class="section level2 hasAnchor" number="14.2">
<h2><span class="header-section-number">14.2</span> Large sample confidence intervals<a href="confidence-intervals.html#large-sample-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose <span class="math inline">\(\theta\)</span> is a parameter and <span class="math inline">\(\hat{\theta}\)</span> is an unbiased estimator of <span class="math inline">\(\theta\)</span> such that <span class="math inline">\(\hat{\theta}\)</span> is <span class="math inline">\(N(\theta,\sigma_{\hat{\theta}})\)</span>. Then <span class="math display">\[Z = \frac{\hat{\theta}-\theta}{\sigma_{\hat{\theta}}}\]</span> is <span class="math inline">\(N(0,1)\)</span> a nice pivotal quantity we can use to construct confidence intervals.</p>
<p>Suppose the desired confidence level is <span class="math inline">\(1 - \alpha\)</span> (it is common to let <span class="math inline">\(\alpha = .05,\)</span> which corresponds to 95% confidence).
Let <span class="math inline">\(\pm z_{\alpha/2}\)</span> denote the values in the tails of the <span class="math inline">\(N(0,1)\)</span> distribution such that <span class="math display">\[P\left(-z_{\alpha/2} \leq Z \leq z_{\alpha/2}\right) = 1-\alpha,\]</span> as pictured in Figure <a href="confidence-intervals.html#fig:alpha-over-2-tails">14.1</a>, where <span class="math inline">\(\pm z_{\alpha/2}\)</span> are denoted z_low and z_high.</p>
<p>Then
<span class="math display">\[\begin{align*}
P\left(-z_{\alpha/2} \leq Z \leq z_{\alpha/2}\right) &amp;= 1-\alpha \\
P\left(-z_{\alpha/2} \leq \frac{\hat{\theta}-\theta}{\sigma_{\hat{\theta}}} \leq z_{\alpha/2}\right) &amp;= 1-\alpha \\
P\left(\hat{\theta}-z_{\alpha/2}\sigma_{\hat{\theta}} \leq \theta \leq \hat{\theta}+z_{\alpha/2}\sigma_{\hat{\theta}}\right) &amp;= 1-\alpha
\end{align*}\]</span></p>
<blockquote>
<p>In this setting, a level <span class="math inline">\((1-\alpha)\)</span> confidence interval for <span class="math inline">\(\theta\)</span> is the interval
<span class="math display">\[(\hat{\theta}-z_{\alpha/2}\sigma_{\hat{\theta}}~,~\hat{\theta}+z_{\alpha/2}\sigma_{\hat{\theta}}).\]</span></p>
</blockquote>
<p>Note that in R,</p>
<ul>
<li><span class="math inline">\(-z_{\alpha/2} =\)</span> <code>qnorm</code><span class="math inline">\((\alpha/2),\)</span> and</li>
<li><span class="math inline">\(z_{\alpha/2} =\)</span> -<code>qnorm</code><span class="math inline">\((\alpha/2)\)</span> = <code>qnorm</code><span class="math inline">\((1-\alpha+\alpha/2)\)</span>.</li>
</ul>
<div class="figure"><span style="display:block;" id="fig:alpha-over-2-tails"></span>
<img src="math340-notes_files/figure-html/alpha-over-2-tails-1.png" alt="Finding z scores used to build a 2-sided confidence interval with desired confidence level" width="384" />
<p class="caption">
Figure 14.1: Finding z scores used to build a 2-sided confidence interval with desired confidence level
</p>
</div>
<p>Similarly, a level <span class="math inline">\((1-\alpha)\)</span> <strong>lower bound for <span class="math inline">\(\theta\)</span></strong> is <span class="math display">\[\hat{\theta} - z_{\alpha}\cdot \sigma_{\hat{\theta}}\]</span> (which defines the lower one-sided confidence interval <span class="math inline">\([\hat{\theta} - z_{\alpha}\cdot \sigma_{\hat{\theta}},\infty)\)</span>) (see Figure <a href="confidence-intervals.html#fig:lower-one-sided-CI">14.2</a>).</p>
<p>A level <span class="math inline">\((1-\alpha)\)</span> <strong>upper bound for <span class="math inline">\(\theta\)</span></strong> is <span class="math display">\[\hat{\theta} + z_{\alpha}\cdot \sigma_{\hat{\theta}}\]</span> (which defines the upper one-sided confidence interval <span class="math inline">\((-\infty,\hat{\theta}+z_{\alpha}\cdot \sigma_{\hat{\theta}}]\)</span>) (see Figure <a href="confidence-intervals.html#fig:upper-one-sided-CI">14.3</a>). Note</p>
<ul>
<li><span class="math inline">\(z_\alpha =\)</span> <code>qnorm</code><span class="math inline">\((\alpha)\)</span></li>
</ul>
<div class="figure"><span style="display:block;" id="fig:lower-one-sided-CI"></span>
<img src="math340-notes_files/figure-html/lower-one-sided-CI-1.png" alt="z scores corrsponding to lower 1-sided confidence interval" width="384" />
<p class="caption">
Figure 14.2: z scores corrsponding to lower 1-sided confidence interval
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:upper-one-sided-CI"></span>
<img src="math340-notes_files/figure-html/upper-one-sided-CI-1.png" alt="z scores corrsponding to upper 1-sided confidence interval" width="384" />
<p class="caption">
Figure 14.3: z scores corrsponding to upper 1-sided confidence interval
</p>
</div>
<p>The scene outlined above applies to many situations, thanks to the Central Limit Theorem, including the four common scenarios mention in Chapter <a href="estimation.html#estimation">13</a>:</p>
<ul>
<li>1 mean <span class="math inline">\(\mu,\)</span> estimated with sample mean <span class="math inline">\(\overline{X},\)</span></li>
<li>1 proportion <span class="math inline">\(p,\)</span> estimate with sample proportion <span class="math inline">\(\hat{p},\)</span></li>
<li>difference of two means <span class="math inline">\(\mu_1-\mu_2,\)</span> estimated with <span class="math inline">\(\overline{X_1}-\overline{X_2},\)</span></li>
<li>difference of two proportions <span class="math inline">\(p_1-p_2,\)</span> estimated with <span class="math inline">\(\hat{p_1}-\hat{p_2}\)</span>.</li>
</ul>
<p>We summarize these confidence intervals here:</p>
<p><strong>Common level <span class="math inline">\((1-\alpha)\)</span> confidence intervals</strong></p>
<blockquote>
<ol style="list-style-type: decimal">
<li>For <span class="math inline">\(\mu\)</span>: <span class="math display">\[\overline{X} \pm z_{\alpha/2} \cdot  \frac{\sigma}{\sqrt{n}}\]</span></li>
<li>For <span class="math inline">\(p\)</span>: <span class="math display">\[\hat{p} \pm z_{\alpha/2} \sqrt{\frac{p(1-p)}{n}}\]</span></li>
<li>For <span class="math inline">\(\mu_1-\mu_2\)</span>: <span class="math display">\[\left(\overline{X_1}-\overline{X_2}\right)\pm z_{\alpha/2} \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}\]</span></li>
<li>For <span class="math inline">\(p_1-p_2\)</span>: <span class="math display">\[\left(\hat{p}_1-\hat{p}_2\right)\pm z_{\alpha/2} \sqrt{\frac{p_1(1-p_1)}{n_1}+\frac{p_2(1-p_2)}{n_2}}\]</span></li>
</ol>
</blockquote>
<p>For large sample sizes (<span class="math inline">\(n\geq 30\)</span> is often sufficient), <span class="math inline">\(S\)</span> can be used for unknown <span class="math inline">\(\sigma\)</span> in confidence intervals for means, and sample proportions <span class="math inline">\(\hat{p}\)</span> can be used for unknown <span class="math inline">\(p\)</span>.
For small sample sizes, when <span class="math inline">\(\sigma\)</span> is unknown, we shall use <span class="math inline">\(T = \frac{\overline{X}-\mu}{S/\sqrt{n}}\)</span> when estimating means, and we have the following confidence interval for <span class="math inline">\(\mu\)</span>:</p>
<blockquote>
<p>For small sample sizes, when <span class="math inline">\(\sigma\)</span> is unknown, we estimate <span class="math inline">\(\mu\)</span> with <span class="math display">\[\displaystyle \overline{X} \pm t_{\alpha/2} \cdot  \frac{S}{\sqrt{n}}\]</span></p>
</blockquote>
<p>Let’s work through several examples.</p>
<div class="example">
<p><span id="exm:unlabeled-div-65" class="example"><strong>Example 14.4  </strong></span>Suppose we gather a sample of size <span class="math inline">\(n = 20\)</span> from a <span class="math inline">\(N(\mu,2)\)</span> population, and find <span class="math inline">\(\overline{x} = 16.3\)</span>. Find a 98% confidence interval for <span class="math inline">\(\mu\)</span>.</p>
<p>Here 98% confidence <span class="math inline">\(\leftrightarrow \alpha = 0.02,\)</span> and <span class="math inline">\(z_{\alpha/2} = z_{.01}\)</span> = <code>qnorm(.99)</code> = 2.326.</p>
<p>So our 98% confidence interval for the population mean <span class="math inline">\(\mu\)</span> is <span class="math display">\[\overline{x} \pm 2.326 \cdot \frac{2}{\sqrt{20}},\]</span>
or <span class="math display">\[16.3 \pm 1.04,\]</span> or <span class="math display">\[15.26 \text{ to } 17.34.\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-66" class="example"><strong>Example 14.5  </strong></span>Suppose in this example we don’t know <span class="math inline">\(\sigma = 2,\)</span> but in our sample of size 20 from <span class="math inline">\(N(\mu,\sigma),\)</span> <span class="math inline">\(\overline{x} = 16.3\)</span> and <span class="math inline">\(s = 2.13\)</span>. Find a 98% confidence interval for <span class="math inline">\(\mu\)</span>.</p>
<p>Using a sample standard deviation <span class="math inline">\(s\)</span> in place of <span class="math inline">\(\sigma\)</span> requires us to use <span class="math inline">\(t\)</span> instead of <span class="math inline">\(z\)</span>. In particular, instead of using <span class="math inline">\(z_{.01} = 2.326,\)</span> we must use <span class="math inline">\(t_{.01}(19),\)</span> the value in the t(19) distribution that has 1% of the distribution greater than it.</p>
<p>So <span class="math inline">\(t_{.01}(19)\)</span> = <code>qt(.99,19)</code> = 2.539. (This t-score will always be larger than the corresponding z-score, making the confidence interval wider than it would have been if we knew <span class="math inline">\(\sigma\)</span>.</p>
<p>Our confidence interval looks like:
<span class="math display">\[\overline{x} \pm 2.539 \cdot \frac{2.13}{\sqrt{20}},\]</span>
which simplifies to <span class="math display">\[16.3 \pm 1.21,\]</span> or, equivalently <span class="math display">\[15.09 \text{ to } 17.51.\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-67" class="example"><strong>Example 14.6  </strong></span>In a poll of 500 likely voters, 260 say they support a particular local measure. Based on this sample, find a 90% confidence interval for <span class="math inline">\(p,\)</span> the proportion of all likely voters in favor of this measure.</p>
<p>We use the large sample confidence interval for <span class="math inline">\(p\)</span>. From the data, <span class="math inline">\(n = 500,\)</span> <span class="math inline">\(\hat{p} = 260/500 = .52,\)</span> and for 90% confidence <span class="math inline">\(\alpha = 0.1,\)</span> so <span class="math display">\[z_{\alpha/2} = z_{.05} = 1.645,\]</span>
(computed in R with <code>qnorm(.95)</code>). Now evaluate:</p>
<p><span class="math display">\[\begin{align*}
\hat{p} \pm z_{\alpha/2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n}} &amp;= .52 \pm 1.645 \sqrt{\frac{(.52)(.48)}{500}}\\
&amp;= .52 \pm .037\\
&amp;= .483 \text{ to } .557.
\end{align*}\]</span></p>
<p>It looks like it will be a close vote! We do not have convincing evidence, really, that <span class="math inline">\(p &gt; .5\)</span> since .5 lands inside the interval.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-68" class="example"><strong>Example 14.7  (Angles of spider webs) </strong></span>The <a href="https://www.google.com/books/edition/A_Handbook_of_Small_Data_Sets/vWu-MJM_obsC?hl=en">Handbook of Small Data Sets</a> published in 1994 has lots of interesting, small data sets. Here’s one small data set:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="confidence-intervals.html#cb34-1" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">25</span>,<span class="dv">12</span>,<span class="dv">31</span>,<span class="dv">26</span>,<span class="dv">17</span>,<span class="dv">15</span>,<span class="dv">24</span>,<span class="dv">10</span>,<span class="dv">16</span>,<span class="dv">12</span>)</span></code></pre></div>
<p>Spider webs’ angles made with the vertical to the earth’s surface have a <a href="https://en.wikipedia.org/wiki/Von_Mises_distribution">von Mises circular distribution</a> with known mean direction, <span class="math inline">\(\mu,\)</span> and <span class="math inline">\(\mu\)</span> varies from species to species. For instance,</p>
<ul>
<li><em>Isoxya cicatricosa</em> has <span class="math inline">\(\mu = 28.12^\circ,\)</span> while</li>
<li><em>Araneus rufipalpus</em> has <span class="math inline">\(\mu = 15.66^\circ,\)</span> obviously.</li>
</ul>
<p>The question arose (in the article “Sequential analysis for angular data”, by Gadsden and Kanji, (1981), <em>The Statistician</em>, <strong>30</strong>, 119-129) of which species had constructed the 10 webs whose angles were listed above in the vector <code>X</code>.</p>
<p>Treating the data as a simple random sample we can construct a 95% confidence interval for <span class="math inline">\(\mu\)</span>. Since the sample size is small, we use <span class="math inline">\(t_{\alpha/2},\)</span> rather than <span class="math inline">\(z_{\alpha/2},\)</span> where, here <span class="math inline">\(\alpha = .05\)</span>. Let’s crunch out the interval in R.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="confidence-intervals.html#cb35-1" tabindex="-1"></a><span class="co">#summary statistics</span></span>
<span id="cb35-2"><a href="confidence-intervals.html#cb35-2" tabindex="-1"></a>n <span class="ot">=</span> <span class="fu">length</span>(X)</span>
<span id="cb35-3"><a href="confidence-intervals.html#cb35-3" tabindex="-1"></a>xbar <span class="ot">=</span> <span class="fu">mean</span>(X)</span>
<span id="cb35-4"><a href="confidence-intervals.html#cb35-4" tabindex="-1"></a>s <span class="ot">=</span> <span class="fu">sd</span>(X)</span>
<span id="cb35-5"><a href="confidence-intervals.html#cb35-5" tabindex="-1"></a>tstar <span class="ot">=</span> <span class="fu">qt</span>(.<span class="dv">975</span>,<span class="dv">9</span>) <span class="co">#we let tstar denote t_{alpha/2}</span></span>
<span id="cb35-6"><a href="confidence-intervals.html#cb35-6" tabindex="-1"></a>xbar <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span>tstar<span class="sc">*</span>s<span class="sc">/</span><span class="fu">sqrt</span>(n)</span></code></pre></div>
<pre><code>## [1] 13.67688 23.92312</code></pre>
<p>Based on the interval, which contains the known mean for <em>Araneus rufipalpus</em>, but not the known mean <em>Isoxya cicatricosa</em>, we have good evidence that these webs were made by the former type of spider.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-69" class="example"><strong>Example 14.8  (Annual Snowfall in Buffalo, NY) </strong></span>Here’s another data set from the Handbook of Small Data Sets: The annual snowfall in Buffalo, NY (in inches) for the 63 years from 1910 to 1972.</p>
<pre><code>##   year  snow
## 1 1910 126.4
## 2 1911  82.4
## 3 1912  78.1
## 4 1913  51.1
## 5 1914  90.9</code></pre>
<p>Let’s find a 95% confidence interval for the mean annual snowfall in Buffalo, taking the above snowfall column as a simple random sample of annual snowfall. Here are the summary statistics:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="confidence-intervals.html#cb38-1" tabindex="-1"></a>X <span class="ot">=</span> snowfall<span class="sc">$</span>snow <span class="co">#snow fall column as vector X</span></span>
<span id="cb38-2"><a href="confidence-intervals.html#cb38-2" tabindex="-1"></a>n <span class="ot">=</span> <span class="fu">length</span>(X)</span>
<span id="cb38-3"><a href="confidence-intervals.html#cb38-3" tabindex="-1"></a>xbar <span class="ot">=</span> <span class="fu">mean</span>(X)</span>
<span id="cb38-4"><a href="confidence-intervals.html#cb38-4" tabindex="-1"></a>s <span class="ot">=</span> <span class="fu">sd</span>(X)</span></code></pre></div>
<p>For 95% confidence, <span class="math inline">\(\alpha = .05,\)</span> and <span class="math inline">\(z_{\alpha/2} = z_{.025} \approx 1.96.\)</span></p>
<p>Since <span class="math inline">\(n\)</span> is large, we use the confidence interval formula below with <span class="math inline">\(s\)</span> plugged in for <span class="math inline">\(\sigma\)</span>:</p>
<p><span class="math display">\[\overline{x} \pm z_{\alpha/2} \cdot  \frac{\sigma}{\sqrt{n}}\]</span>
and we arrive at the interval</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="confidence-intervals.html#cb39-1" tabindex="-1"></a>xbar <span class="sc">+</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">qnorm</span>(.<span class="dv">025</span>)<span class="sc">*</span>s<span class="sc">/</span><span class="fu">sqrt</span>(n)</span></code></pre></div>
<pre><code>## [1] 74.43965 86.15400</code></pre>
</div>
<div id="confidence-intervals-for-mu_1-mu_2" class="section level3 unnumbered hasAnchor">
<h3>Confidence Intervals for <span class="math inline">\(\mu_1-\mu_2\)</span><a href="confidence-intervals.html#confidence-intervals-for-mu_1-mu_2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose we have two samples from two populations:
-an independent sample from population 1 which yields <span class="math inline">\(n_1,\)</span> <span class="math inline">\(\overline{x}_1,\)</span> <span class="math inline">\(s_1,\)</span> and
-an independent sample from population 1 which yields <span class="math inline">\(n_2,\)</span> <span class="math inline">\(\overline{x}_2,\)</span> <span class="math inline">\(s_2\)</span>.
Moreover, the two samples are independent.</p>
<p>Recall, if Population 1 is <span class="math inline">\(N(\mu_1,\sigma_1)\)</span> and Population 2 is <span class="math inline">\(N(\mu_2,\sigma_2\)</span>), then a 95% confidence interval for <span class="math inline">\(\mu_1-\mu_2\)</span> is
<span class="math display">\[\left(\overline{X_1}-\overline{X_2}\right)\pm z_{\alpha/2} \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}.\]</span>
If <span class="math inline">\(\sigma_1\)</span> and <span class="math inline">\(\sigma_2\)</span> are unknown, but <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span> are fairly large, it is reasonable to replace <span class="math inline">\(\sigma_1\)</span> and <span class="math inline">\(\sigma_2\)</span> with <span class="math inline">\(s_1\)</span> and <span class="math inline">\(s_2,\)</span> respectively.</p>
<p>If <span class="math inline">\(n_1, n_2\)</span> are small (<span class="math inline">\(\leq 30\)</span>) it’s better to use a t-distribution.</p>
<p>Let’s consider the special case that <span class="math inline">\(\sigma_1\)</span> and <span class="math inline">\(\sigma_2\)</span> are unknown but equal. Letting <span class="math inline">\(\sigma^2\)</span> denote this common value. In this case we consider the pooled sample variance:
<span class="math display">\[s_p^2 = \frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}\]</span> as our (best) estimate of <span class="math inline">\(\sigma^2\)</span>. Then our level <span class="math inline">\((1-\alpha)\)</span> confidence interval for <span class="math inline">\(\mu_1-\mu_2\)</span> is <span class="math display">\[\left(\overline{X_1}-\overline{X_2}\right)\pm t_{\alpha/2}S_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}},\]</span>
where <span class="math inline">\(t_{\alpha/2}\)</span> live in a t-distribution with <span class="math inline">\(n_1+n_2-2\)</span> degrees of freedom.</p>
<div class="example">
<p><span id="exm:unlabeled-div-70" class="example"><strong>Example 14.9  </strong></span>The silver content (% Ag) of a number of Byzantine coins discovered in Cyprus was determined. Nine of the coins came from the first coinage of the reign of King Manuel, I, Comnenus (1143-1180); and 7 of the coins came from a coinage many years later.</p>
<p><strong>The data</strong></p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="confidence-intervals.html#cb41-1" tabindex="-1"></a>Ag1 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">5.9</span>,<span class="fl">6.8</span>,<span class="fl">6.4</span>,<span class="fl">7.0</span>,<span class="fl">6.6</span>,<span class="fl">7.7</span>,<span class="fl">7.2</span>,<span class="fl">6.9</span>,<span class="fl">6.2</span>)</span>
<span id="cb41-2"><a href="confidence-intervals.html#cb41-2" tabindex="-1"></a>Ag2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">5.3</span>,<span class="fl">5.6</span>,<span class="fl">5.5</span>,<span class="fl">5.1</span>,<span class="fl">6.2</span>,<span class="fl">5.8</span>,<span class="fl">5.8</span>) </span></code></pre></div>
<p>These data appear in <em>The Handbook of Small Data Sets</em> (p. 118), and are based on this article:</p>
<p>Hendy, M.F. and Charles J.A. (1970), <em>The production techniques, silver content and circulation history of the twelfth-century Byzantine Trachy.</em> Archaeonetry, 12. 13-21)</p>
<p><strong>The question</strong></p>
<p>Is there a significant difference in the silver content of coins minted early and late in Manuel’s reign?</p>
<p>Let’s conduct a small sample confidence interval for the difference in the two population means <span class="math inline">\(\mu_1 - \mu_2\)</span> from the summary statistics:</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
sample
</th>
<th style="text-align:right;">
n
</th>
<th style="text-align:right;">
xbar
</th>
<th style="text-align:right;">
s
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
6.74
</td>
<td style="text-align:right;">
0.543
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
5.61
</td>
<td style="text-align:right;">
0.363
</td>
</tr>
</tbody>
</table>
<p>The pooled sample standard deviation is then <span class="math display">\[s_p = \sqrt{\frac{8\cdot s_1^2 + 6 \cdot s_2^2}{14}} \approx .474,\]</span>
and for 95% confidence we use <span class="math inline">\(t^*\)</span> = <code>qt(.975,14)</code> = 2.145. With all these values we have the following 95% confidence interval for <span class="math inline">\(\mu_1 = \mu_2\)</span>: <span class="math display">\[0.62 \text{ to } 1.64.\]</span>
The entire interval lies above 0, so we have good evidence here of a difference between <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\mu_2\)</span>.</p>
</div>
<p>Was it reasonable in the previous example to assume the two populations have equal variance? Might differences in silver content in these two eras make it likely that other production differences existed as well (that might make variation in silver content from coin to coin also change)?</p>
<p>If <span class="math inline">\(\sigma_1^2\)</span> and <span class="math inline">\(\sigma_2^2\)</span> are unknown, sample sizes are samll, and its unreasonalbe to assume <span class="math inline">\(\sigma_1^2\)</span> and <span class="math inline">\(\sigma_2^2\)</span> are equal, one often sees the following (approximate) level <span class="math inline">\((1-\alpha)\)</span> confidence interval for <span class="math inline">\(\mu_1 - \mu_2\)</span>:
<span class="math display">\[\overline{X}_1 - \overline{X}_2 \pm t_{\alpha/2} \cdot \sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}\]</span> where <span class="math inline">\(t_{\alpha/2}\)</span> lives in a t-distribution with degrees of freedom equal to the minimum of <span class="math inline">\(n_1 - 1\)</span> and <span class="math inline">\(n_2 - 1\)</span>.
So for the coin example, we would use <span class="math inline">\(t^*\)</span> = <code>qt(.975,6)</code> = 2.447, giving us a wider confidence interval in the end:
<span class="math display">\[0.574 \text{ to } 1.686,\]</span> but still one that suggests a difference between <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\mu_2\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-71" class="example"><strong>Example 14.10  (Recent Buffalo Snowfall) </strong></span>With climate change, it may be unreasonable to assume the average annual snowfall now is the same as it was 100 years ago.</p>
<p>Let <span class="math inline">\(\mu_1\)</span> denote the “old” mean average annual snowfall (and we assume the data from 1910 to 1972 is a random sample from the “old” population”), and <span class="math inline">\(\mu_2\)</span> denots the “new” mean average annual snowfall in Buffalo (from which the annual snowfall from 2000 to 2021, found at <a href="https://www.buffalo.org/snow">buffalo.or/snow</a>, is a random sample.) Do these data provide evidence that <span class="math inline">\(\mu_1 \neq \mu_2\)</span>?</p>
<p>Here are the 2001-2022 data:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="confidence-intervals.html#cb42-1" tabindex="-1"></a>Y <span class="ot">=</span> <span class="fu">c</span>(<span class="fl">158.7</span>,<span class="fl">132.4</span>,<span class="fl">111.3</span>,<span class="fl">100.9</span>,<span class="fl">109.1</span>,<span class="fl">78.2</span>,<span class="fl">88.9</span>,<span class="fl">103.8</span>,<span class="fl">100.2</span>,<span class="fl">74.1</span>,<span class="fl">111.8</span>,</span>
<span id="cb42-2"><a href="confidence-intervals.html#cb42-2" tabindex="-1"></a>      <span class="fl">36.7</span>,<span class="fl">58.8</span>,<span class="fl">129.9</span>,<span class="fl">112.9</span>,<span class="fl">55.1</span>,<span class="fl">76.1</span>,<span class="fl">112.3</span>,<span class="fl">118.8</span>,<span class="fl">69.2</span>,<span class="fl">77.2</span>,<span class="fl">97.4</span>)</span></code></pre></div>
<p>A 95% confidence interval for the difference <span class="math inline">\(\mu_X-\mu_Y\)</span>:</p>
<p>TODO</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-72" class="example"><strong>Example 14.11  (A one-sided confidence interval) </strong></span>The measures of the outside diameter <span class="math inline">\(x_i\)</span> (in inches) for 9 grains of the same type:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="confidence-intervals.html#cb43-1" tabindex="-1"></a>diam <span class="ot">=</span> <span class="fu">c</span>(<span class="fl">2.021</span>,<span class="fl">2.002</span>,<span class="fl">2.001</span>,<span class="fl">2.005</span>,<span class="fl">1.990</span>,<span class="fl">1.990</span>,<span class="fl">2.009</span>,<span class="fl">1.983</span>,<span class="fl">1.987</span>)</span></code></pre></div>
<p>Assume the distribution is normal. Is <span class="math inline">\(\mu \geq 2\)</span>?</p>
<p>Let’s find a 1-sided lower bound 95% confidence interval for <span class="math inline">\(\mu,\)</span> and see what that gets us.</p>
<p>Since <span class="math inline">\(n = 9\)</span> is small and <span class="math inline">\(\sigma\)</span> is unknown, we use the t-distribution.</p>
<p>Summary statistics:</p>
<ul>
<li><span class="math inline">\(n = 9,\)</span></li>
<li><span class="math inline">\(\overline{x}\)</span> = <code>mean(diam)</code> = 1.9987.</li>
<li><span class="math inline">\(s\)</span> = <code>sd(diam)</code> = 0.0122</li>
</ul>
<p>For a lower bound 95% confidence interval, <span class="math inline">\(\alpha=.05\)</span> and we use <span class="math display">\[t_{\alpha} = t_{.05}(8) = qt(.95,8) = 1.86,\]</span>
and the lower 1-sided interval is</p>
<p><span class="math display">\[\begin{align*}
(\overline{x}-t_{.05}(8)\cdot \frac{s}{\sqrt{n}},\infty) &amp;= (1.9987 - 1.86\cdot\frac{0.0122}{\sqrt{9}},\infty) \\
&amp;= (1.991,\infty)
\end{align*}\]</span></p>
<p>This confidence interval does not convince me that <span class="math inline">\(\mu \geq 2\)</span>.
(If the interval had been something like <span class="math inline">\([2.01,\infty),\)</span> then I would be more convinced since we’re confident that <span class="math inline">\(\mu\)</span> is within the confidence interval, but with the interval <span class="math inline">\([1.991,\infty),\)</span> best we can say is we’re confident <span class="math inline">\(\mu \geq 1.99\)</span>.</p>
</div>

</div>
</div>
</div>



</div>
            </section>

          </div>
        </div>
      </div>
<a href="estimation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sampling-in-R.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["math340-notes.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
