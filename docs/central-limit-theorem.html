<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>12 Central Limit Theorem | MATH 340 Notes</title>
  <meta name="description" content="12 Central Limit Theorem | MATH 340 Notes" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="12 Central Limit Theorem | MATH 340 Notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="12 Central Limit Theorem | MATH 340 Notes" />
  
  
  

<meta name="author" content="Mike Hitchman" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="mgf.html"/>
<link rel="next" href="estimation.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://github.com/mphitchman/math340.git" target="blank">Math 340 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="sets.html"><a href="sets.html"><i class="fa fa-check"></i><b>2</b> Sets</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sets.html"><a href="sets.html#algebra-of-sets"><i class="fa fa-check"></i><b>2.1</b> Algebra of Sets</a></li>
<li class="chapter" data-level="2.2" data-path="sets.html"><a href="sets.html#size-of-sets"><i class="fa fa-check"></i><b>2.2</b> Set sizes</a></li>
<li class="chapter" data-level="2.3" data-path="sets.html"><a href="sets.html#sets-in-r"><i class="fa fa-check"></i><b>2.3</b> Sets in R</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html"><i class="fa fa-check"></i><b>3</b> Discrete Probability Distributions</a>
<ul>
<li class="chapter" data-level="3.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#sample-space"><i class="fa fa-check"></i><b>3.1</b> Sample Space</a></li>
<li class="chapter" data-level="3.2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#discrete-random-variables"><i class="fa fa-check"></i><b>3.2</b> Discrete Random Variables</a></li>
<li class="chapter" data-level="3.3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#calculating-probabilities"><i class="fa fa-check"></i><b>3.3</b> Calculating Probabilities</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#sample-point-method"><i class="fa fa-check"></i><b>3.3.1</b> Sample Point Method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="counting.html"><a href="counting.html"><i class="fa fa-check"></i><b>4</b> Counting Techniques</a>
<ul>
<li class="chapter" data-level="4.1" data-path="counting.html"><a href="counting.html#multipiclation-principle"><i class="fa fa-check"></i><b>4.1</b> Multipiclation Principle</a></li>
<li class="chapter" data-level="4.2" data-path="counting.html"><a href="counting.html#permutations"><i class="fa fa-check"></i><b>4.2</b> Permutations</a></li>
<li class="chapter" data-level="4.3" data-path="counting.html"><a href="counting.html#combinations"><i class="fa fa-check"></i><b>4.3</b> Combinations</a></li>
<li class="chapter" data-level="4.4" data-path="counting.html"><a href="counting.html#multinomial-coefficients"><i class="fa fa-check"></i><b>4.4</b> Multinomial Coefficients</a></li>
<li class="chapter" data-level="4.5" data-path="counting.html"><a href="counting.html#balls-and-bins"><i class="fa fa-check"></i><b>4.5</b> Balls and Bins</a></li>
<li class="chapter" data-level="4.6" data-path="counting.html"><a href="counting.html#prob-with-counting-tools"><i class="fa fa-check"></i><b>4.6</b> Calculating More Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>5</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="5.1" data-path="probability-theory.html"><a href="probability-theory.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>5.1</b> Conditional Probability and Independence</a></li>
<li class="chapter" data-level="5.2" data-path="probability-theory.html"><a href="probability-theory.html#two-laws-of-probability"><i class="fa fa-check"></i><b>5.2</b> Two Laws of Probability</a></li>
<li class="chapter" data-level="5.3" data-path="probability-theory.html"><a href="probability-theory.html#event-composition-method"><i class="fa fa-check"></i><b>5.3</b> Event-Composition Method</a></li>
<li class="chapter" data-level="5.4" data-path="probability-theory.html"><a href="probability-theory.html#bayes-rule"><i class="fa fa-check"></i><b>5.4</b> Bayes’ Rule</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="discrete-random-variables-1.html"><a href="discrete-random-variables-1.html"><i class="fa fa-check"></i><b>6</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="discrete-random-variables-1.html"><a href="discrete-random-variables-1.html#expected-value"><i class="fa fa-check"></i><b>6.1</b> Expected Value</a></li>
<li class="chapter" data-level="6.2" data-path="discrete-random-variables-1.html"><a href="discrete-random-variables-1.html#variance"><i class="fa fa-check"></i><b>6.2</b> Variance</a></li>
<li class="chapter" data-level="6.3" data-path="discrete-random-variables-1.html"><a href="discrete-random-variables-1.html#properties-of-expected-value"><i class="fa fa-check"></i><b>6.3</b> Properties of Expected Value</a></li>
<li class="chapter" data-level="6.4" data-path="discrete-random-variables-1.html"><a href="discrete-random-variables-1.html#tchebysheffs-theorem"><i class="fa fa-check"></i><b>6.4</b> Tchebysheff’s Theorem</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html"><i class="fa fa-check"></i><b>7</b> Important Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="7.1" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#binomial"><i class="fa fa-check"></i><b>7.1</b> Binomial Distributions</a></li>
<li class="chapter" data-level="7.2" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#geometric"><i class="fa fa-check"></i><b>7.2</b> Geometric Distributions</a></li>
<li class="chapter" data-level="7.3" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#negative-binomial"><i class="fa fa-check"></i><b>7.3</b> Negative Binomial Distribution</a></li>
<li class="chapter" data-level="7.4" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#hypergometric"><i class="fa fa-check"></i><b>7.4</b> Hypergeometric Distribution</a></li>
<li class="chapter" data-level="7.5" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#poisson"><i class="fa fa-check"></i><b>7.5</b> Poisson Distribution</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#poisson-process"><i class="fa fa-check"></i><b>7.5.1</b> Poisson Process</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="moments-and-moment-generating-functions.html"><a href="moments-and-moment-generating-functions.html"><i class="fa fa-check"></i><b>8</b> Moments and Moment-Generating Functions</a></li>
<li class="chapter" data-level="9" data-path="continuous-rv.html"><a href="continuous-rv.html"><i class="fa fa-check"></i><b>9</b> Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="9.1" data-path="continuous-rv.html"><a href="continuous-rv.html#distribution-functions"><i class="fa fa-check"></i><b>9.1</b> Distribution Functions</a></li>
<li class="chapter" data-level="9.2" data-path="continuous-rv.html"><a href="continuous-rv.html#expected-value-for-continuous-random-variables"><i class="fa fa-check"></i><b>9.2</b> Expected Value for Continuous Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html"><i class="fa fa-check"></i><b>10</b> Important Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="10.1" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#uniform-continuous"><i class="fa fa-check"></i><b>10.1</b> Uniform Distribution</a></li>
<li class="chapter" data-level="10.2" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#exponential-distribution"><i class="fa fa-check"></i><b>10.2</b> Exponential Distribution</a></li>
<li class="chapter" data-level="10.3" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#normal"><i class="fa fa-check"></i><b>10.3</b> Normal Distribution</a></li>
<li class="chapter" data-level="10.4" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#gamma-distribution"><i class="fa fa-check"></i><b>10.4</b> Gamma Distribution</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#exponential-distribution-1"><i class="fa fa-check"></i><b>10.4.1</b> Exponential Distribution</a></li>
<li class="chapter" data-level="10.4.2" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#chi-square-distribution"><i class="fa fa-check"></i><b>10.4.2</b> Chi-square distribution</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#beta-distribution"><i class="fa fa-check"></i><b>10.5</b> Beta Distribution</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="mgf.html"><a href="mgf.html"><i class="fa fa-check"></i><b>11</b> Moment Generating Functions</a></li>
<li class="chapter" data-level="12" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>12</b> Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="12.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#sums-of-random-variables"><i class="fa fa-check"></i><b>12.1</b> Sums of Random Variables</a></li>
<li class="chapter" data-level="12.2" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#t-distribution"><i class="fa fa-check"></i><b>12.2</b> T distribution</a></li>
<li class="chapter" data-level="12.3" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>12.3</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="12.4" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#normal-approximation-to-a-binomial-distribution"><i class="fa fa-check"></i><b>12.4</b> Normal Approximation to a binomial distribution</a>
<ul>
<li class="chapter" data-level="" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#continuity-correction"><i class="fa fa-check"></i>Continuity Correction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>13</b> Estimation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="estimation.html"><a href="estimation.html#unbiased-estimators"><i class="fa fa-check"></i><b>13.1</b> Unbiased Estimators</a></li>
<li class="chapter" data-level="13.2" data-path="estimation.html"><a href="estimation.html#order-statistics"><i class="fa fa-check"></i><b>13.2</b> Order Statistics</a></li>
<li class="chapter" data-level="13.3" data-path="estimation.html"><a href="estimation.html#common-unbiased-estimators"><i class="fa fa-check"></i><b>13.3</b> Common Unbiased Estimators</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="estimation.html"><a href="estimation.html#estimating-mu-a-population-mean"><i class="fa fa-check"></i><b>13.3.1</b> Estimating <span class="math inline">\(\mu\)</span>, a population mean</a></li>
<li class="chapter" data-level="13.3.2" data-path="estimation.html"><a href="estimation.html#estimating-p-a-population-proportion"><i class="fa fa-check"></i><b>13.3.2</b> Estimating <span class="math inline">\(p\)</span>, a population proportion</a></li>
<li class="chapter" data-level="13.3.3" data-path="estimation.html"><a href="estimation.html#estimating-mu_1---mu_2-the-difference-of-two-population-means"><i class="fa fa-check"></i><b>13.3.3</b> Estimating <span class="math inline">\(\mu_1 - \mu_2\)</span>, the difference of two population means</a></li>
<li class="chapter" data-level="13.3.4" data-path="estimation.html"><a href="estimation.html#estimating-p_1---p_2-the-difference-of-two-population-proportions"><i class="fa fa-check"></i><b>13.3.4</b> Estimating <span class="math inline">\(p_1 - p_2\)</span>, the difference of two population proportions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>14</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="14.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#pivotal-quantities"><i class="fa fa-check"></i><b>14.1</b> Pivotal Quantities</a></li>
<li class="chapter" data-level="14.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#large-sample-confidence-intervals"><i class="fa fa-check"></i><b>14.2</b> Large sample confidence intervals</a>
<ul>
<li class="chapter" data-level="" data-path="confidence-intervals.html"><a href="confidence-intervals.html#confidence-intervals-for-mu_1-mu_2"><i class="fa fa-check"></i>Confidence Intervals for <span class="math inline">\(\mu_1-\mu_2\)</span></a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Using R</b></span></li>
<li class="chapter" data-level="A" data-path="sampling-in-R.html"><a href="sampling-in-R.html"><i class="fa fa-check"></i><b>A</b> Sampling in R</a>
<ul>
<li class="chapter" data-level="A.1" data-path="sampling-in-R.html"><a href="sampling-in-R.html#vectors-R"><i class="fa fa-check"></i><b>A.1</b> Data vectors</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#vector-types"><i class="fa fa-check"></i>vector types</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#matrices"><i class="fa fa-check"></i>Matrices</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#data-frames"><i class="fa fa-check"></i>data frames</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#common-vector-commands"><i class="fa fa-check"></i>common vector commands</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#comparison-operators"><i class="fa fa-check"></i>Comparison Operators</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sum-and-which"><i class="fa fa-check"></i><code>sum()</code> and <code>which()</code></a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#extracting-elements"><i class="fa fa-check"></i>extracting elements</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#comparing-vectors"><i class="fa fa-check"></i>comparing vectors</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#vector-arithmetic"><i class="fa fa-check"></i>vector arithmetic</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#concatenate-vectors"><i class="fa fa-check"></i>concatenate vectors</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="sampling-in-R.html"><a href="sampling-in-R.html#special-vectors"><i class="fa fa-check"></i><b>A.2</b> Special vectors</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#consecutive-integers"><i class="fa fa-check"></i>consecutive integers</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#letters"><i class="fa fa-check"></i>letters</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#rep"><i class="fa fa-check"></i><code>rep()</code></a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#table"><i class="fa fa-check"></i><code>table()</code></a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#seq"><i class="fa fa-check"></i><code>seq()</code></a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sampling-in-R-section"><i class="fa fa-check"></i><b>A.3</b> Sampling</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sample-options"><i class="fa fa-check"></i><code>sample()</code> options</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sample-without-replacement"><i class="fa fa-check"></i>Sample without replacement</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sample-with-replacement"><i class="fa fa-check"></i>Sample with replacement</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sample-with-custom-probabilities"><i class="fa fa-check"></i>Sample with custom probabilities</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#example-lefties"><i class="fa fa-check"></i>Example: Lefties</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="sampling-in-R.html"><a href="sampling-in-R.html#repeated-sampling"><i class="fa fa-check"></i><b>A.4</b> Repeated Sampling</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#using-a-for-loop"><i class="fa fa-check"></i>using a <code>for</code> loop</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#using-replicate"><i class="fa fa-check"></i>using <code>replicate()</code></a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sampling-commands"><i class="fa fa-check"></i><b>A.5</b> Summary of R commands</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#defining-vectors"><i class="fa fa-check"></i>defining vectors</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#summarizing-vectors"><i class="fa fa-check"></i>summarizing vectors</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sampling-from-vectors"><i class="fa fa-check"></i>sampling from vectors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="R-sim-probability.html"><a href="R-sim-probability.html"><i class="fa fa-check"></i><b>B</b> Simulating Probability in R</a>
<ul>
<li class="chapter" data-level="B.1" data-path="R-sim-probability.html"><a href="R-sim-probability.html#diff-2dice-R"><i class="fa fa-check"></i><b>B.1</b> Difference of two dice</a></li>
<li class="chapter" data-level="B.2" data-path="R-sim-probability.html"><a href="R-sim-probability.html#license-plates-R"><i class="fa fa-check"></i><b>B.2</b> Oregon License Plates</a></li>
<li class="chapter" data-level="B.3" data-path="R-sim-probability.html"><a href="R-sim-probability.html#id_10sided-die-R"><i class="fa fa-check"></i><b>B.3</b> Rolling a 10-sided die</a></li>
<li class="chapter" data-level="B.4" data-path="R-sim-probability.html"><a href="R-sim-probability.html#marbles-urn-R"><i class="fa fa-check"></i><b>B.4</b> Marbles from an urn</a></li>
<li class="chapter" data-level="B.5" data-path="R-sim-probability.html"><a href="R-sim-probability.html#flip-coin-R"><i class="fa fa-check"></i><b>B.5</b> Tracking runs of Heads in coin flips</a></li>
<li class="chapter" data-level="B.6" data-path="R-sim-probability.html"><a href="R-sim-probability.html#partition-set-R"><i class="fa fa-check"></i><b>B.6</b> Splitting a set into multiple subsets</a></li>
<li class="chapter" data-level="B.7" data-path="R-sim-probability.html"><a href="R-sim-probability.html#pollsters-R"><i class="fa fa-check"></i><b>B.7</b> Pollsters</a></li>
<li class="chapter" data-level="B.8" data-path="R-sim-probability.html"><a href="R-sim-probability.html#same-birthday-R"><i class="fa fa-check"></i><b>B.8</b> Matching Birthdays</a></li>
<li class="chapter" data-level="B.9" data-path="R-sim-probability.html"><a href="R-sim-probability.html#flipping-coins-with-fibonacci"><i class="fa fa-check"></i><b>B.9</b> Flipping Coins with Fibonacci</a></li>
<li class="chapter" data-level="B.10" data-path="R-sim-probability.html"><a href="R-sim-probability.html#seats-on-an-airplane"><i class="fa fa-check"></i><b>B.10</b> Seats on an airplane</a></li>
<li class="chapter" data-level="B.11" data-path="R-sim-probability.html"><a href="R-sim-probability.html#drawing-names-for-homemades"><i class="fa fa-check"></i><b>B.11</b> Drawing names for Homemades</a>
<ul>
<li class="chapter" data-level="" data-path="R-sim-probability.html"><a href="R-sim-probability.html#mathematical-addendum-to-the-question-of-drawing-names."><i class="fa fa-check"></i>Mathematical addendum to the question of drawing names.</a></li>
</ul></li>
<li class="chapter" data-level="B.12" data-path="R-sim-probability.html"><a href="R-sim-probability.html#idiots-delight"><i class="fa fa-check"></i><b>B.12</b> Idiot’s Delight</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="R-discreteRV.html"><a href="R-discreteRV.html"><i class="fa fa-check"></i><b>C</b> Discrete Random Variables in R</a>
<ul>
<li class="chapter" data-level="C.1" data-path="R-discreteRV.html"><a href="R-discreteRV.html#binomialR"><i class="fa fa-check"></i><b>C.1</b> Binomial <code>binom</code></a>
<ul>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#dbinom---probability-function"><i class="fa fa-check"></i><code>dbinom()</code> - probability function</a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#pbinom---cumulative-probability"><i class="fa fa-check"></i><code>pbinom()</code> - cumulative probability</a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#qbinom---quantiles"><i class="fa fa-check"></i><code>qbinom()</code> - quantiles</a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#rbinom---sampling"><i class="fa fa-check"></i><code>rbinom()</code> - sampling</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="R-discreteRV.html"><a href="R-discreteRV.html#geometricR"><i class="fa fa-check"></i><b>C.2</b> Geometric <code>geom</code></a></li>
<li class="chapter" data-level="C.3" data-path="R-discreteRV.html"><a href="R-discreteRV.html#negbinomR"><i class="fa fa-check"></i><b>C.3</b> Negative Binomial <code>nbinom</code></a></li>
<li class="chapter" data-level="C.4" data-path="R-discreteRV.html"><a href="R-discreteRV.html#hyperR"><i class="fa fa-check"></i><b>C.4</b> Hypergeometric <code>hyper</code></a></li>
<li class="chapter" data-level="C.5" data-path="R-discreteRV.html"><a href="R-discreteRV.html#poissonR"><i class="fa fa-check"></i><b>C.5</b> Poisson <code>pois</code></a></li>
<li class="chapter" data-level="C.6" data-path="R-discreteRV.html"><a href="R-discreteRV.html#custom-discrete-R"><i class="fa fa-check"></i><b>C.6</b> Homemade Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#expected-value-of-x"><i class="fa fa-check"></i>Expected Value of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#variance-of-x"><i class="fa fa-check"></i>Variance of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#distribution-plots"><i class="fa fa-check"></i>Distribution Plots</a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#sampling"><i class="fa fa-check"></i>Sampling</a></li>
<li class="chapter" data-level="C.6.1" data-path="R-discreteRV.html"><a href="R-discreteRV.html#discrete-uniform-distribution"><i class="fa fa-check"></i><b>C.6.1</b> Discrete Uniform Distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="R-continuousRV.html"><a href="R-continuousRV.html"><i class="fa fa-check"></i><b>D</b> Continuous Random Variables in R</a>
<ul>
<li class="chapter" data-level="D.1" data-path="R-continuousRV.html"><a href="R-continuousRV.html#unifR"><i class="fa fa-check"></i><b>D.1</b> Uniform Distribution</a>
<ul>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#picking-random-numbers"><i class="fa fa-check"></i>Picking random numbers</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#picking-random-points-in-the-unit-square"><i class="fa fa-check"></i>Picking random points in the unit square</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimate-the-value-of-pi"><i class="fa fa-check"></i>Estimate the value of <span class="math inline">\(\pi\)</span></a></li>
</ul></li>
<li class="chapter" data-level="D.2" data-path="R-continuousRV.html"><a href="R-continuousRV.html#normalR"><i class="fa fa-check"></i><b>D.2</b> Normal Distribution <code>norm</code></a>
<ul>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#sampling-distribution-of-a-sample-mean"><i class="fa fa-check"></i>Sampling Distribution of a sample mean</a></li>
</ul></li>
<li class="chapter" data-level="D.3" data-path="R-continuousRV.html"><a href="R-continuousRV.html#expR"><i class="fa fa-check"></i><b>D.3</b> Exponential Distribution <code>exp</code></a>
<ul>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#a-memoryless-distribution"><i class="fa fa-check"></i>A Memoryless distribution</a></li>
</ul></li>
<li class="chapter" data-level="D.4" data-path="R-continuousRV.html"><a href="R-continuousRV.html#gammaR"><i class="fa fa-check"></i><b>D.4</b> Gamma Distribution <code>gamma</code></a></li>
<li class="chapter" data-level="D.5" data-path="R-continuousRV.html"><a href="R-continuousRV.html#chiR"><i class="fa fa-check"></i><b>D.5</b> Chi-square Distribution <code>chisq</code></a></li>
<li class="chapter" data-level="D.6" data-path="R-continuousRV.html"><a href="R-continuousRV.html#betaR"><i class="fa fa-check"></i><b>D.6</b> Beta distribution <code>beta</code></a></li>
<li class="chapter" data-level="D.7" data-path="R-continuousRV.html"><a href="R-continuousRV.html#custom-continuous-R"><i class="fa fa-check"></i><b>D.7</b> Homemade Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#input-the-density-function"><i class="fa fa-check"></i>Input the density function</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#visualize-the-density-function"><i class="fa fa-check"></i>Visualize the density function</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimating-integrals-with-riemann-sums"><i class="fa fa-check"></i>Estimating Integrals with Riemann Sums</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimating-probabilities"><i class="fa fa-check"></i>Estimating Probabilities</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#the-distribution-function-fx"><i class="fa fa-check"></i>The distribution function <span class="math inline">\(F(X)\)</span></a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimating-moments"><i class="fa fa-check"></i>Estimating Moments</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#expected-value-1"><i class="fa fa-check"></i>Expected Value</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH 340 Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="central-limit-theorem" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">12</span> Central Limit Theorem<a href="central-limit-theorem.html#central-limit-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="sums-of-random-variables" class="section level2 hasAnchor" number="12.1">
<h2><span class="header-section-number">12.1</span> Sums of Random Variables<a href="central-limit-theorem.html#sums-of-random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> are random variables defined via a random sample of size <span class="math inline">\(n\)</span> taken from a distribution that is <span class="math inline">\(N(\mu,\sigma)\)</span>.</p>
<p>After the sample is chosen, each <span class="math inline">\(X_i = x_i\)</span> takes on a value (lower case corresponds to data, upper case corresponds to random variable).
We may then compute the sample mean <span class="math display">\[\overline{x} = \frac{1}{n}\sum_{i=1}^n x_i.\]</span>
Prior to picking our actual sample we can consider the function of the random variables <span class="math display">\[\overline{X} = \frac{1}{n} \sum_{i=1}^n X_i.\]</span></p>
<div class="theorem">
<p><span id="thm:normal-random-sample" class="theorem"><strong>Theorem 12.1  </strong></span>If <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> represents a random sample taken from a <span class="math inline">\(N(\mu,\sigma)\)</span> distribution, then <span class="math display">\[\overline{X} = \frac{1}{n} \sum_{i=1}^n X_i ~\text{ is }~ N\left(\mu,\frac{\sigma}{\sqrt{n}}\right).\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-56" class="proof"><em>Proof</em>. </span>This theorem is an immediate consequence of Theorem <a href="mgf.html#thm:sum-of-normal-rvs">11.3</a> where each <span class="math inline">\(a_i = 1/n\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:house-finch" class="example"><strong>Example 12.1  </strong></span>Let <span class="math inline">\(X\)</span> equal the duration of a randomly selected song (in seconds) for a house finch. Suppose <span class="math inline">\(X\)</span> is normal with unknown mean <span class="math inline">\(\mu\)</span> (we’re trying to get a handle on this) and standard deviation <span class="math inline">\(\sigma = 30\)</span> seconds (somehow we know this). A random sample of 25 song durations is observed. Find the probability that the sample mean will be within 5 seconds of the population mean <span class="math inline">\(\mu\)</span>.</p>
<p>If <span class="math inline">\(X_1, X_2, \ldots, X_{25}\)</span> denote the 25 song lengths to be observed, each <span class="math inline">\(X_i \sim N(\mu,30)\)</span>, so <span class="math display">\[\overline{X} \sim N\left(\mu,\frac{30}{\sqrt{25}}\right) = N(\mu,6).\]</span>
We want to know <span class="math display">\[P(|\overline{X}-\mu| &lt; 5).\]</span>
<span class="math display">\[\begin{align*}
P(|\overline{X}-\mu| &lt; 5) &amp;= P(-5 &lt; \overline{X}-\mu &lt; 5)\\
                          &amp;= P\left(\frac{-5}{6} &lt; \frac{\overline{X}-\mu}{6} &lt; \frac{5}{6}\right)\\
                          &amp;= P(-5/6 &lt; Z &lt; 5/6).
\end{align*}\]</span>
Using R, <span class="math inline">\(P(-5/6 &lt; Z &lt; 5/6)\)</span> = <code>pnorm(5/6)-pnorm(-5/6)</code> = 0.595.</p>
<p>A secondary question: How big a sample we we need so that the likelihood of the sample mean being within 5 seconds of <span class="math inline">\(\mu\)</span> is up to .95?</p>
<p>In this case, we want <span class="math inline">\(n\)</span> so that
<span class="math display">\[P\left(\frac{-5}{30/\sqrt{n}} &lt; Z &lt; \frac{5}{30/\sqrt{n}}\right) = .95.\]</span>
Equivalently, we want to find <span class="math inline">\(n\)</span> so that <span class="math display">\[P\left(Z &lt; \frac{-5}{30/\sqrt{n}}\right) = .025.\]</span>
In <span class="math inline">\(N(0,1)\)</span>, <code>qnorm(.025)</code> = -1.96, which means <span class="math inline">\(P(Z &lt; -1.96) = .025\)</span>.
So we want <span class="math display">\[\frac{-5}{30/\sqrt{n}} = -1.96,\]</span> and solving for <span class="math inline">\(n\)</span> and rounding up yields <span class="math inline">\(n = 139\)</span>.</p>
</div>
<div class="theorem">
<p><span id="thm:sample-variance-chisq" class="theorem"><strong>Theorem 12.2  </strong></span>Let <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> represent a random sample from a <span class="math inline">\(N(\mu,\sigma)\)</span> distribution, and <span class="math display">\[\overline{X} = \frac{1}{n} \sum_{i=1}^n X_i ~~~ \text { and } ~~~ S^2 = \frac{1}{n-1}\sum_{i=1}^n (X_i - \overline{X})^2.\]</span> Then <span class="math display">\[\frac{n-1}{\sigma^2}S^2 \sim \chi^2(n-1),\]</span> and <span class="math inline">\(\overline{X}\)</span> and <span class="math inline">\(S^2\)</span> are independent random variables.</p>
</div>
<p>We refer to <span class="math inline">\(\overline{X}\)</span> and <span class="math inline">\(S^2\)</span> as the sample mean and sample variance associated with the random sample.</p>
<p>Suppose we draw a sample of size <span class="math inline">\(n = 25\)</span> from a <span class="math inline">\(N(10,2)\)</span> distribution. In this case the preceding two theorems tell us that</p>
<ul>
<li><span class="math inline">\(\overline{X} \sim N(10,2/\sqrt{25}) = N(10,0.4)\)</span></li>
<li><span class="math inline">\(6 S^2 \sim \chi^2(24)\)</span> (since <span class="math inline">\(\frac{n-1}{\sigma^2} = 6\)</span> in this case)</li>
<li><span class="math inline">\(\overline{X}\)</span> and <span class="math inline">\(S^2\)</span> are independent random variables.</li>
</ul>
<p>Let’s look at a simulation in R to investigate these statements. The simulation works like this:</p>
<ol style="list-style-type: decimal">
<li>Draw a random sample of size <span class="math inline">\(25\)</span> from <span class="math inline">\(N(10,2)\)</span></li>
<li>Calculate <span class="math inline">\(\overline{x}\)</span> and <span class="math inline">\(s^2\)</span> from this sample.</li>
<li>Repeat steps 1 and 2 for many trials, and then consider
- a frequency plot for <span class="math inline">\(\overline{x}\)</span> (does it look <span class="math inline">\(N(10,0.4)\)</span>)
- a frequency plot for <span class="math inline">\(\frac{n-1}{\sigma^2}s^2\)</span> (does it look <span class="math inline">\(\chi^2(24)\)</span>?)
- a scatter plot of <span class="math inline">\(\overline{x}\)</span> against <span class="math inline">\(s^2\)</span> (do they look independent?)</li>
</ol>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="central-limit-theorem.html#cb16-1" tabindex="-1"></a>trials <span class="ot">=</span> <span class="dv">10000</span></span>
<span id="cb16-2"><a href="central-limit-theorem.html#cb16-2" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">25</span>; mu <span class="ot">=</span> <span class="dv">10</span>; sigma <span class="ot">=</span> <span class="dv">2</span> <span class="co">#define sample size and parameters</span></span>
<span id="cb16-3"><a href="central-limit-theorem.html#cb16-3" tabindex="-1"></a>sample_means <span class="ot">=</span> <span class="fu">c</span>() <span class="co">#stores mean of each sample</span></span>
<span id="cb16-4"><a href="central-limit-theorem.html#cb16-4" tabindex="-1"></a>sample_var <span class="ot">=</span> <span class="fu">c</span>() <span class="co">#stores variance of each sample</span></span>
<span id="cb16-5"><a href="central-limit-theorem.html#cb16-5" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>trials){</span>
<span id="cb16-6"><a href="central-limit-theorem.html#cb16-6" tabindex="-1"></a>  x <span class="ot">=</span> <span class="fu">rnorm</span>(n,mu,sigma) <span class="co">#draw sample</span></span>
<span id="cb16-7"><a href="central-limit-theorem.html#cb16-7" tabindex="-1"></a>  sample_means[i] <span class="ot">=</span> <span class="fu">mean</span>(x) <span class="co">#record sample mean</span></span>
<span id="cb16-8"><a href="central-limit-theorem.html#cb16-8" tabindex="-1"></a>  sample_var[i] <span class="ot">=</span> <span class="fu">var</span>(x) <span class="co">#record sample variance</span></span>
<span id="cb16-9"><a href="central-limit-theorem.html#cb16-9" tabindex="-1"></a>}</span></code></pre></div>
<p>Plots:
<img src="math340-notes_files/figure-html/unnamed-chunk-26-1.png" width="384" /></p>
<p><img src="math340-notes_files/figure-html/unnamed-chunk-27-1.png" width="384" /></p>
<p>The scatter plot below suggests no real association between <span class="math inline">\(\overline{x}\)</span> and <span class="math inline">\(s^2\)</span>.</p>
<p><img src="math340-notes_files/figure-html/unnamed-chunk-28-1.png" width="384" /></p>
</div>
<div id="t-distribution" class="section level2 hasAnchor" number="12.2">
<h2><span class="header-section-number">12.2</span> T distribution<a href="central-limit-theorem.html#t-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="definition">
<p><span id="def:t-distribution" class="definition"><strong>Definition 12.1  </strong></span>Let <span class="math inline">\(Z \sim N(0,1)\)</span> and <span class="math inline">\(W \sim \chi^2(\nu)\)</span>. If <span class="math inline">\(Z\)</span> and <span class="math inline">\(W\)</span> are independent then <span class="math display">\[\frac{Z}{\sqrt{W/\nu}}\]</span> is said to have a <strong>t distribution with <span class="math inline">\(\nu\)</span> degrees of freedom.</strong></p>
</div>
<p>Here’s our motivation for looking at such a thing. Look again at the house finch example (Example <a href="central-limit-theorem.html#exm:house-finch">12.1</a>). We took a sample of 25 song lengths to estimate <span class="math inline">\(\mu\)</span>, or rather the likelihood that <span class="math inline">\(\overline{x}\)</span> is within 5 seconds of <span class="math inline">\(\mu\)</span>, the population mean. In our solution we assumed we know <span class="math inline">\(\sigma\)</span>. It is perhaps not reasonable to assume we know <span class="math inline">\(\sigma\)</span> when we’re trying to estimate <span class="math inline">\(\mu\)</span>!</p>
<p>So, if we don’t know <span class="math inline">\(\sigma\)</span>, can we estimate it from the sample? Sure! How about estimating <span class="math inline">\(\sigma\)</span> with <span class="math inline">\(s\)</span>, the sample standard deviation?</p>
<p>Now, recall in our solution there came a point when we considered a <span class="math inline">\(Z\)</span>-score:
<span class="math display">\[z = \frac{\overline{x}-\mu}{\sigma/\sqrt{n}}.\]</span>
If we don’t know <span class="math inline">\(\sigma\)</span> can we replace it with the estimate <span class="math inline">\(s\)</span>?
Good question! Check this out:</p>
<p>From Theorem <a href="important-continuous-rv.html#thm:standardizing-normal-distributions">10.4</a> <span class="math inline">\(\displaystyle Z =\frac{ \overline{X}-\mu}{\sigma/\sqrt{n}}\)</span> is <span class="math inline">\(N(0,1)\)</span></p>
<p>From Theorem <a href="central-limit-theorem.html#thm:sample-variance-chisq">12.2</a>, <span class="math inline">\(\displaystyle\frac{(n-1)S^2}{\sigma^2}\)</span> is <span class="math inline">\(\chi^2(n-1)\)</span>,</p>
<p>So the ratio <span class="math inline">\(\displaystyle\frac{Z}{\sqrt{\frac{(n-1)S^2}{\sigma^2}\big/(n-1)}}\)</span> has a t distribution with <span class="math inline">\((n-1)\)</span> degrees of freedom!</p>
<p>Finally, observe
<span class="math display">\[\begin{align*}
  \frac{Z}{\sqrt{\frac{(n-1)S^2}{\sigma^2}\big/(n-1)}} &amp;= \frac{\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}}{s/\sigma} \\
  &amp;= \frac{\overline{X}-\mu}{\sigma/\sqrt{n}} \cdot (\sigma/s) \\
  &amp;= \frac{\overline{X}-\mu}{s/\sqrt{n}}.
\end{align*}\]</span></p>
<p>The point of this story is this:</p>
<p>If <span class="math inline">\(X_1,X_2,\ldots, X_n\)</span> represents a random sample drawn from <span class="math inline">\(N(\mu,\sigma)\)</span> then</p>
<ul>
<li><span class="math inline">\(\displaystyle \overline{X} \sim N(\mu,\sigma/\sqrt{n})\)</span></li>
<li>so <span class="math inline">\(\displaystyle Z = \frac{\overline{X}-\mu}{\sigma/\sqrt{n}}\)</span> is <span class="math inline">\(N(0,1)\)</span></li>
<li>while <span class="math inline">\(\displaystyle T = \frac{\overline{X}-\mu}{s/\sqrt{n}}\)</span> is a t distribution with <span class="math inline">\(n-1\)</span> degrees of freedom.</li>
</ul>
<p>We denote a <span class="math inline">\(t\)</span> distributioin with <span class="math inline">\(k\)</span> degrees of freedom by <span class="math inline">\(t(k)\)</span>. The density function for a <span class="math inline">\(t(k)\)</span> distribution, defined for all <span class="math inline">\(-\infty &lt; t &lt; \infty\)</span>, is
<span class="math display">\[f(t) = \frac{\Gamma(\frac{k+1}{2})}{\sqrt{k\pi}\Gamma(k/2)}\left(1+\frac{t^2}{2}\right)^{-\left(\frac{k+1}{2}\right)}\]</span></p>
<p>Suppose <span class="math inline">\(T \sim t(k)\)</span>.</p>
<p><strong>Facts about T</strong>:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(E(T) = 0\)</span></li>
<li>The distribution has mode at 0</li>
<li>The distribution is symmetric about the <span class="math inline">\(y\)</span>-axis</li>
<li>it has fatter tails than <span class="math inline">\(N(0,1)\)</span>, i.e.,for <span class="math inline">\(a &gt; 0\)</span>, <span class="math inline">\(P(t &gt; a) &gt; P(Z &gt; a)\)</span>.</li>
<li>As <span class="math inline">\(k \to \infty\)</span>, <span class="math inline">\(t(k) \to N(0,1)\)</span>.</li>
</ol>
<div class="figure"><span style="display:block;" id="fig:t-vs-st-norm"></span>
<img src="math340-notes_files/figure-html/t-vs-st-norm-1.png" alt="A t distribution and N(0,1)" width="384" />
<p class="caption">
Figure 12.1: A t distribution and N(0,1)
</p>
</div>
<div class="example">
<p><span id="exm:t-distribution-practice" class="example"><strong>Example 12.2  </strong></span>A forester studying the effects of fertilization on certain pine forests is interested in estimating the average basal area (in ft<span class="math inline">\(^2\)</span>) of pine trees.
Let <span class="math inline">\(X_1, X_2, \ldots, X_9\)</span> denote a random sample of size 9, and suppose <span class="math inline">\(X_i \sim N(\mu,\sigma)\)</span> with <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span> unknown.</p>
<p>Find two statistics (i.e., functions of the data) <span class="math inline">\(g_1\)</span> and <span class="math inline">\(g_2\)</span> such that <span class="math display">\[P(g_1 \leq \overline{X}-\mu \leq g_2) = .9.\]</span>
(The statistics <span class="math inline">\(g_1\)</span> and <span class="math inline">\(g_2\)</span> thus give us a range of values we believe with probability .9 captures <span class="math inline">\(\mu\)</span>.)</p>
<p>Well, the statistic <span class="math display">\[T = \frac{\sqrt{n}(\overline{X}-\mu)}{S}\]</span> lives in a <span class="math inline">\(t(8)\)</span> distribution.</p>
<p>Now <span class="math inline">\(t(8)\)</span> is plotted in figure <a href="central-limit-theorem.html#fig:t8">12.2</a>, and we can find constants <span class="math inline">\(c\)</span> and <span class="math inline">\(-c\)</span> such that the shaded area between them is 0.9.</p>
<div class="figure"><span style="display:block;" id="fig:t8"></span>
<img src="math340-notes_files/figure-html/t8-1.png" alt="Finding the middle 90% of a t(8) distribution" width="384" />
<p class="caption">
Figure 12.2: Finding the middle 90% of a t(8) distribution
</p>
</div>
<p>Using R, in which the t distribution is aptly named as <code>t</code>, <span class="math inline">\(c\)</span> and <span class="math inline">\(-c\)</span> are readily found with <code>qt()</code>:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="central-limit-theorem.html#cb17-1" tabindex="-1"></a><span class="fu">qt</span>(.<span class="dv">95</span>,<span class="dv">8</span>) <span class="co">#gives c</span></span></code></pre></div>
<pre><code>## [1] 1.859548</code></pre>
<p>So <span class="math display">\[P(-1.86 &lt; T &lt; 1.86) = .9,\]</span>
where <span class="math inline">\(T = 3(\overline{X}-\mu)/S\)</span>, and this allows us to solve the problem:</p>
<p><span class="math display">\[\begin{align*}
.9 &amp;= P(-1.86 &lt; T &lt; 1.86)\\
    &amp;= P(-1.86 &lt; 3(\overline{X}-\mu)/S &lt; 1.86) &lt; 1.86) \\
    &amp;= P(\frac{-1.86}{3}S &lt; \overline{X}-\mu &lt; \frac{1.86}{3}S )\\
    &amp;= P(-.62 S &lt; \overline{X}-\mu &lt; .62 S)
\end{align*}\]</span></p>
<p>So <span class="math inline">\(g_1 = -.62S\)</span> and <span class="math inline">\(g_2 = .62S\)</span> work!</p>
<p>In practice, this means that, once we have gathered our data of size <span class="math inline">\(n = 9\)</span>, it is “likely” that <span class="math inline">\(\mu\)</span> is captured by the interval <span class="math display">\[(\overline{X} - .62S, \overline{X} + .62S).\]</span></p>
<p>For instance, suppose our data is (units are ft<span class="math inline">\(^2\)</span>)</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="central-limit-theorem.html#cb19-1" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">c</span>(<span class="fl">85.5</span>,<span class="fl">71.4</span>,<span class="fl">60.4</span>,<span class="fl">70.9</span>,<span class="fl">78.3</span>,<span class="fl">67.9</span>,<span class="fl">65.3</span>,<span class="fl">63.1</span>,<span class="fl">68.4</span>)</span>
<span id="cb19-2"><a href="central-limit-theorem.html#cb19-2" tabindex="-1"></a>xbar <span class="ot">=</span> <span class="fu">mean</span>(data)</span>
<span id="cb19-3"><a href="central-limit-theorem.html#cb19-3" tabindex="-1"></a>s <span class="ot">=</span> <span class="fu">sd</span>(data)</span></code></pre></div>
<p>It is “likely” that <span class="math inline">\(\mu\)</span> falls between <code>xbar-.62*s</code> = 65.3 ft<span class="math inline">\(^2\)</span> and <code>xbar-.62*s</code> = 74.9 ft<span class="math inline">\(^2\)</span>.</p>
</div>
<p>The Central Limit Theorem says, roughly, that even if the underlying population is not normally distributed, it is still reasonable to follow this procedure to estimate <span class="math inline">\(\mu\)</span>.</p>
</div>
<div id="the-central-limit-theorem" class="section level2 hasAnchor" number="12.3">
<h2><span class="header-section-number">12.3</span> The Central Limit Theorem<a href="central-limit-theorem.html#the-central-limit-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="theorem">
<p><span id="thm:clt" class="theorem"><strong>Theorem 12.3  (Central Limit Theorem) </strong></span>Let <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> be independent and identically distributed random variables with <span class="math inline">\(E(X_i) = \mu\)</span> and <span class="math inline">\(V(X_i) = \sigma^2\)</span> for <span class="math inline">\(i = 1,2,\ldots,n\)</span>. Let <span class="math display">\[\overline{X} = \frac{1}{n}\sum_{i=1}^n X_i ~~~ \text{ and } ~~~ U_n = \frac{\overline{X}-\mu}{\sigma/\sqrt{n}}.\]</span>
Then the distribution function of <span class="math inline">\(U_n\)</span> converges to a standard normal distribution function as <span class="math inline">\(n \to \infty\)</span>.</p>
</div>
<p>The Central Limit Theorem (CLT) is the mathematical basis for the statistical analysis coming in the next chapter.</p>
<p><em>Sketch of Proof</em></p>
<p>TODO</p>
<div class="example">
<p><span id="exm:clt-use" class="example"><strong>Example 12.3  (Practical Use of the CLT) </strong></span>For large <span class="math inline">\(n\)</span>, <span class="math display">\[\frac{\overline{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1)\]</span> for a random sample taken from any distribution.
That is, for any distribution (Poisson, binomial, gamma, uniform, …) with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, if we take a simple random sample (SRS) of decent size, compute the sample mean, then this mean lives in a distribution that is approximately <span class="math inline">\(N(\mu,\sigma/\sqrt{n})\)</span>. Consequently, <span class="math display">\[\frac{\overline{X}-\mu}{S/\sqrt{n}}\]</span> will be approximately <span class="math inline">\(t(n-1)\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:walk-straight" class="example"><strong>Example 12.4  (Can we really walk straight?) </strong></span>Data on cadence (strides/sec) from a 1992 <a href="https://onlinelibrary.wiley.com/doi/10.1002/ajpa.1330890104">article</a> in the American Journal of Physical Anthropology, for a sample of size <span class="math inline">\(n = 20\)</span> “randomly selected healthy men.”</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="central-limit-theorem.html#cb20-1" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">c</span>(<span class="fl">0.95</span>, <span class="fl">0.85</span>, <span class="fl">0.92</span>, <span class="fl">0.95</span>, <span class="fl">0.93</span>, <span class="fl">0.86</span>, <span class="fl">1.00</span>, <span class="fl">0.92</span>, <span class="fl">0.85</span>, <span class="fl">0.81</span>,</span>
<span id="cb20-2"><a href="central-limit-theorem.html#cb20-2" tabindex="-1"></a><span class="fl">0.78</span>, <span class="fl">0.93</span>, <span class="fl">0.93</span>, <span class="fl">1.05</span>, <span class="fl">0.93</span>, <span class="fl">1.06</span>, <span class="fl">1.06</span>, <span class="fl">0.96</span>, <span class="fl">0.81</span>, <span class="fl">0.96</span>)</span></code></pre></div>
<p>The sample mean and standard deviation for these data are</p>
<ul>
<li><span class="math inline">\(\overline{x}\)</span> = 0.925</li>
<li><span class="math inline">\(s\)</span> = 0.081.</li>
</ul>
<p>We know that <span class="math inline">\(T = \frac{\overline{X}-\mu}{S/\sqrt{n}}\)</span> has a t(19) distribution (assuming the underlying population is normal), and we can find <span class="math inline">\(c\)</span> such that <span class="math display">\[P(|(\overline{x}-\mu)/(s/\sqrt{n})| &lt; c) = .95.\]</span></p>
</div>
</div>
<div id="normal-approximation-to-a-binomial-distribution" class="section level2 hasAnchor" number="12.4">
<h2><span class="header-section-number">12.4</span> Normal Approximation to a binomial distribution<a href="central-limit-theorem.html#normal-approximation-to-a-binomial-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If <span class="math inline">\(X\)</span> is binom<span class="math inline">\((n,p)\)</span>, we can view <span class="math inline">\(X\)</span> as a sum of Bernoulli random variables:
<span class="math inline">\(X = \sum_{i=1^n}Y_i\)</span> where each <span class="math inline">\(Y_i\)</span> is binom<span class="math inline">\((1,p)\)</span> [so <span class="math inline">\(P(Y_i = 1) = p\)</span> and <span class="math inline">\(P(Y_i = 0) = 1-p\)</span>, and <span class="math display">\[\mu_{Y_i} = p ~~~\text{ and } ~~~ \sigma_{Y_i} = \sqrt{p(1-p)}.\]</span></p>
<p>And <span class="math display">\[\frac{1}{n}X = \frac{1}{n}\sum_{i=1}^n Y_i.\]</span> By the Central Limit Theorem, for large <span class="math inline">\(n\)</span>, it follows that <span class="math inline">\(\frac{1}{n}X\)</span> is approximately <span class="math inline">\(N(p,\sqrt{p(1-p)/n})\)</span>.</p>
<blockquote>
<p>If <span class="math inline">\(X\)</span> is <span class="math inline">\(\text{binom}(n,p)\)</span> then <span class="math inline">\(X\)</span> is approximately <span class="math inline">\(N(np, \sqrt{np(1-p)})\)</span> for large <span class="math inline">\(n\)</span>.</p>
</blockquote>
<p>Let’s look at an example and then fine tune the approximation with a continuity correction.</p>
<div class="example">
<p><span id="exm:unlabeled-div-57" class="example"><strong>Example 12.5  </strong></span>Suppose 44% of a voting population actually plan to vote for candidate A (though we don’t know this :)). If we draw a random sample of <span class="math inline">\(n = 100\)</span> voters, what is the approximate probability that 51 or more of the 100 sampled plan to vote for candidate A?</p>
<p>If we know the size of the population we can answer this question precisely with the hypergeometric distribution:</p>
<p>For instance, suppose the population consists of 10000 voters, and <span class="math inline">\(X\)</span> equals the number of voters in a sample of size 100 that plan to vote for candidate A. Then for any <span class="math inline">\(x = 0, 1, \ldots, 100\)</span>,
<span class="math display">\[p(x) = \frac{\binom{4400}{x}\binom{5600}{100-x}}{\binom{10000}{100}},\]</span>
and <span class="math display">\[P(X \geq 51) = \sum_{x = 51}^{100} p(x),\]</span>
and this sum can be calculated in R by:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="central-limit-theorem.html#cb21-1" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">phyper</span>(<span class="dv">50</span>,<span class="dv">4400</span>,<span class="dv">5600</span>,<span class="dv">100</span>)</span></code></pre></div>
<pre><code>## [1] 0.09442696</code></pre>
<p>about a 9.4% chance.</p>
<p>Notice, if the populatioin is just 1000, the answer to this question would be <code>1-phyper(50,440,560,100)</code> = 0.0840868.</p>
<p>If we don’t know the size of the population, but assume it’s big, then the sampling process is close to that of 100 identical Bernoulli trials, where in each case, <span class="math inline">\(p = .44\)</span>. In this case, <span class="math inline">\(X\)</span> is <span class="math inline">\(\text{binom}(n=100,p=.44)\)</span>, and <span class="math inline">\(P(X \geq 51)\)</span> is found in R via</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="central-limit-theorem.html#cb23-1" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">pbinom</span>(<span class="dv">50</span>,<span class="dv">100</span>,.<span class="dv">44</span>)</span></code></pre></div>
<pre><code>## [1] 0.09553862</code></pre>
<p>Notice that the binomial approximation here is closer to the actual probability calculated with the hypergeometric distribution for <span class="math inline">\(n = 10000\)</span> than for <span class="math inline">\(n = 1000\)</span>.</p>
<p>Finally, let’s approximate the likelihood with a normal distribution.
According to the Central Limit Theorem, <span class="math inline">\(X\)</span> is approximately <span class="math inline">\(N(44,\sqrt{100(.44)(.56)})\)</span>, or <span class="math inline">\(N(44,4.964)\)</span>.
So <span class="math inline">\(P(X \geq 51) = 1 - P(X &lt; 51)\)</span> = <code>1 - pnorm(51,44,4.964)</code> = 0.079.</p>
<p>This normal estimate is a little low, and we can improve the estimate by making what is called a <em>continuity correction</em>.</p>
</div>
<div id="continuity-correction" class="section level3 unnumbered hasAnchor">
<h3>Continuity Correction<a href="central-limit-theorem.html#continuity-correction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose <span class="math inline">\(X\)</span> is <span class="math inline">\(\texttt{binom}(100,.44)\)</span>, as in the voting example, and we want to estimate <span class="math inline">\(P(51 \leq X \leq 55)\)</span> by using the normal approximation <span class="math inline">\(N(44,\sqrt{100(.44)(.56)})\)</span>.</p>
<p>The actual binomial probability can be represented as the sum of the 5 rectangle areas in Figure <a href="central-limit-theorem.html#fig:continuity-correction">12.3</a>.
Each rectangle has width 1, and the heights of the rectangles correspond to <span class="math inline">\(P(X = x)\)</span> (binomial probability) for each <span class="math inline">\(x = 51,\ldots,55.\)</span>
We also see in the figure a portion of the <span class="math inline">\(N(44,\sqrt{100(.44)(.56)})\)</span> density curve <span class="math inline">\(f(x)\)</span>. The area under <span class="math inline">\(f\)</span> that best approximates the rectangle areas will be the integral with bounds [50.5,55.5] (whose area is shaded in the figure), as opposed to the integral with bounds [51,55].</p>
<div class="figure"><span style="display:block;" id="fig:continuity-correction"></span>
<img src="math340-notes_files/figure-html/continuity-correction-1.png" alt="Continuity correction to estimate a binomial probability with a normal curve" width="480" />
<p class="caption">
Figure 12.3: Continuity correction to estimate a binomial probability with a normal curve
</p>
</div>
<p>In other words, to better approximate <span class="math inline">\(P(51\leq X \leq 55)\)</span> with a normal distribution, instead of evaluating <span class="math inline">\(\int_{51}^{55} f(x)~dx\)</span>, we should use a continuity correction and evaluate <span class="math display">\[\int_{50.5}^{55.5} f(x)~dx.\]</span></p>
<p>Observe:</p>
<ul>
<li>Actual value of <span class="math inline">\(P(51\leq X \leq 55)\)</span>:
<ul>
<li><code>sum(dbinom(51:55,100,.44))</code> = 0.08503</li>
</ul></li>
<li>Normal approximation without continuity correction:
<ul>
<li><code>pnorm(55,44,4.964)-pnorm(51,44,4.964)</code> = 0.0659</li>
</ul></li>
<li>Normal approximation with continuity correction:
<ul>
<li><code>pnorm(55.5,44,4.964)-pnorm(50.5,44,4.964)</code> = 0.08493</li>
</ul></li>
</ul>
<p>Now, we return to our voting example and the normal approximation to the probability that at least 51 people in a sample of 100 people will vote for candidate <span class="math inline">\(A\)</span>. With a continuity correction, <span class="math inline">\(P(X \geq 51)\)</span> is better approximated with:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="central-limit-theorem.html#cb25-1" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="fl">100.5</span>,<span class="dv">44</span>,<span class="fl">4.964</span>)<span class="sc">-</span><span class="fu">pnorm</span>(<span class="fl">50.5</span>,<span class="dv">44</span>,<span class="fl">4.964</span>)</span></code></pre></div>
<pre><code>## [1] 0.09519473</code></pre>
<p>Here’s one more example.</p>
<div class="example">
<p><span id="exm:unlabeled-div-58" class="example"><strong>Example 12.6  </strong></span>Use continuity correction to estimate <span class="math inline">\(P(460 \leq X \leq 480)\)</span> if <span class="math inline">\(X\)</span> is <span class="math inline">\(\texttt{binom}(1000,.5)\)</span>.</p>
<p>Well, with a continuity correction
<span class="math display">\[P(460 \leq X \leq 480) \approx P(459.5 \leq Y \leq 480.5),\]</span> where <span class="math inline">\(Y \sim N(500,\sqrt{1000(.5)(.5)})\)</span>.</p>
<ul>
<li>Actual probability: <code>pbinom(480,1000,.5)-pbinom(460,1000,.5)</code> = 0.1025.</li>
</ul>
<p>Estimated probability: <code>pnorm(480.5,500,sqrt(250))-pnorm(459.5,500,sqrt(250))</code> = 0.1035.</p>
</div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="mgf.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="estimation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["math340-notes.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
