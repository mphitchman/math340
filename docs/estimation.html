<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>13 Estimation | MATH 340 Notes</title>
  <meta name="description" content="13 Estimation | MATH 340 Notes" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="13 Estimation | MATH 340 Notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="13 Estimation | MATH 340 Notes" />
  
  
  

<meta name="author" content="Mike Hitchman" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="central-limit-theorem.html"/>
<link rel="next" href="confidence-intervals.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://github.com/mphitchman/math340.git" target="blank">Math 340 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="sets.html"><a href="sets.html"><i class="fa fa-check"></i><b>2</b> Sets</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sets.html"><a href="sets.html#algebra-of-sets"><i class="fa fa-check"></i><b>2.1</b> Algebra of Sets</a></li>
<li class="chapter" data-level="2.2" data-path="sets.html"><a href="sets.html#size-of-sets"><i class="fa fa-check"></i><b>2.2</b> Set sizes</a></li>
<li class="chapter" data-level="2.3" data-path="sets.html"><a href="sets.html#sets-in-r"><i class="fa fa-check"></i><b>2.3</b> Sets in R</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html"><i class="fa fa-check"></i><b>3</b> Discrete Probability Distributions</a>
<ul>
<li class="chapter" data-level="3.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#sample-space"><i class="fa fa-check"></i><b>3.1</b> Sample Space</a></li>
<li class="chapter" data-level="3.2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#discrete-rv-initial"><i class="fa fa-check"></i><b>3.2</b> Discrete Random Variables</a></li>
<li class="chapter" data-level="3.3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#calculating-probabilities"><i class="fa fa-check"></i><b>3.3</b> Calculating Probabilities</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#sample-point-method"><i class="fa fa-check"></i><b>3.3.1</b> Sample Point Method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="counting.html"><a href="counting.html"><i class="fa fa-check"></i><b>4</b> Counting Techniques</a>
<ul>
<li class="chapter" data-level="4.1" data-path="counting.html"><a href="counting.html#multipiclation-principle"><i class="fa fa-check"></i><b>4.1</b> Multipiclation Principle</a></li>
<li class="chapter" data-level="4.2" data-path="counting.html"><a href="counting.html#permutations"><i class="fa fa-check"></i><b>4.2</b> Permutations</a></li>
<li class="chapter" data-level="4.3" data-path="counting.html"><a href="counting.html#combinations"><i class="fa fa-check"></i><b>4.3</b> Combinations</a></li>
<li class="chapter" data-level="4.4" data-path="counting.html"><a href="counting.html#multinomial-coefficients"><i class="fa fa-check"></i><b>4.4</b> Multinomial Coefficients</a></li>
<li class="chapter" data-level="4.5" data-path="counting.html"><a href="counting.html#balls-and-bins"><i class="fa fa-check"></i><b>4.5</b> Balls and Bins</a></li>
<li class="chapter" data-level="4.6" data-path="counting.html"><a href="counting.html#prob-with-counting-tools"><i class="fa fa-check"></i><b>4.6</b> Calculating More Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>5</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="5.1" data-path="probability-theory.html"><a href="probability-theory.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>5.1</b> Conditional Probability and Independence</a></li>
<li class="chapter" data-level="5.2" data-path="probability-theory.html"><a href="probability-theory.html#two-laws-of-probability"><i class="fa fa-check"></i><b>5.2</b> Two Laws of Probability</a></li>
<li class="chapter" data-level="5.3" data-path="probability-theory.html"><a href="probability-theory.html#event-composition-method"><i class="fa fa-check"></i><b>5.3</b> Event-Composition Method</a></li>
<li class="chapter" data-level="5.4" data-path="probability-theory.html"><a href="probability-theory.html#bayes-rule"><i class="fa fa-check"></i><b>5.4</b> Bayes’ Rule</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>6</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#expected-value"><i class="fa fa-check"></i><b>6.1</b> Expected Value</a></li>
<li class="chapter" data-level="6.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance"><i class="fa fa-check"></i><b>6.2</b> Variance</a></li>
<li class="chapter" data-level="6.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#properties-of-expected-value"><i class="fa fa-check"></i><b>6.3</b> Properties of Expected Value</a></li>
<li class="chapter" data-level="6.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#tchebysheffs-theorem"><i class="fa fa-check"></i><b>6.4</b> Tchebysheff’s Theorem</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html"><i class="fa fa-check"></i><b>7</b> Important Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="7.1" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#binomial"><i class="fa fa-check"></i><b>7.1</b> Binomial Distributions</a></li>
<li class="chapter" data-level="7.2" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#geometric"><i class="fa fa-check"></i><b>7.2</b> Geometric Distributions</a></li>
<li class="chapter" data-level="7.3" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#negative-binomial"><i class="fa fa-check"></i><b>7.3</b> Negative Binomial Distribution</a></li>
<li class="chapter" data-level="7.4" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#hypergometric"><i class="fa fa-check"></i><b>7.4</b> Hypergeometric Distribution</a></li>
<li class="chapter" data-level="7.5" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#poisson"><i class="fa fa-check"></i><b>7.5</b> Poisson Distribution</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#poisson-process"><i class="fa fa-check"></i><b>7.5.1</b> Poisson Process</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="moments-and-moment-generating-functions.html"><a href="moments-and-moment-generating-functions.html"><i class="fa fa-check"></i><b>8</b> Moments and Moment-Generating Functions</a></li>
<li class="chapter" data-level="9" data-path="continuous-rv.html"><a href="continuous-rv.html"><i class="fa fa-check"></i><b>9</b> Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="9.1" data-path="continuous-rv.html"><a href="continuous-rv.html#distribution-functions"><i class="fa fa-check"></i><b>9.1</b> Distribution Functions</a></li>
<li class="chapter" data-level="9.2" data-path="continuous-rv.html"><a href="continuous-rv.html#expected-value-for-continuous-random-variables"><i class="fa fa-check"></i><b>9.2</b> Expected Value for Continuous Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html"><i class="fa fa-check"></i><b>10</b> Important Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="10.1" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#uniform-continuous"><i class="fa fa-check"></i><b>10.1</b> Uniform Distribution</a></li>
<li class="chapter" data-level="10.2" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#exponential-distribution"><i class="fa fa-check"></i><b>10.2</b> Exponential Distribution</a></li>
<li class="chapter" data-level="10.3" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#normal"><i class="fa fa-check"></i><b>10.3</b> Normal Distribution</a></li>
<li class="chapter" data-level="10.4" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#gamma-distribution"><i class="fa fa-check"></i><b>10.4</b> Gamma Distribution</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#exponential-distribution-1"><i class="fa fa-check"></i><b>10.4.1</b> Exponential Distribution</a></li>
<li class="chapter" data-level="10.4.2" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#chi-square-distribution"><i class="fa fa-check"></i><b>10.4.2</b> Chi-square distribution</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#beta-distribution"><i class="fa fa-check"></i><b>10.5</b> Beta Distribution</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="mgf.html"><a href="mgf.html"><i class="fa fa-check"></i><b>11</b> Moment Generating Functions</a></li>
<li class="chapter" data-level="12" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>12</b> Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="12.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#sums-of-random-variables"><i class="fa fa-check"></i><b>12.1</b> Sums of Random Variables</a></li>
<li class="chapter" data-level="12.2" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#t-distribution"><i class="fa fa-check"></i><b>12.2</b> T distribution</a></li>
<li class="chapter" data-level="12.3" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>12.3</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="12.4" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#normal-approximation-to-a-binomial-distribution"><i class="fa fa-check"></i><b>12.4</b> Normal Approximation to a binomial distribution</a>
<ul>
<li class="chapter" data-level="" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#continuity-correction"><i class="fa fa-check"></i>Continuity Correction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>13</b> Estimation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="estimation.html"><a href="estimation.html#unbiased-estimators"><i class="fa fa-check"></i><b>13.1</b> Unbiased Estimators</a></li>
<li class="chapter" data-level="13.2" data-path="estimation.html"><a href="estimation.html#order-statistics"><i class="fa fa-check"></i><b>13.2</b> Order Statistics</a></li>
<li class="chapter" data-level="13.3" data-path="estimation.html"><a href="estimation.html#common-unbiased-estimators"><i class="fa fa-check"></i><b>13.3</b> Common Unbiased Estimators</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="estimation.html"><a href="estimation.html#estimating-mu-a-population-mean"><i class="fa fa-check"></i><b>13.3.1</b> Estimating <span class="math inline">\(\mu,\)</span> a population mean</a></li>
<li class="chapter" data-level="13.3.2" data-path="estimation.html"><a href="estimation.html#estimating-p-a-population-proportion"><i class="fa fa-check"></i><b>13.3.2</b> Estimating <span class="math inline">\(p,\)</span> a population proportion</a></li>
<li class="chapter" data-level="13.3.3" data-path="estimation.html"><a href="estimation.html#estimating-mu_1---mu_2-the-difference-of-two-population-means"><i class="fa fa-check"></i><b>13.3.3</b> Estimating <span class="math inline">\(\mu_1 - \mu_2,\)</span> the difference of two population means</a></li>
<li class="chapter" data-level="13.3.4" data-path="estimation.html"><a href="estimation.html#estimating-p_1---p_2-the-difference-of-two-population-proportions"><i class="fa fa-check"></i><b>13.3.4</b> Estimating <span class="math inline">\(p_1 - p_2,\)</span> the difference of two population proportions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>14</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="14.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#pivotal-quantities"><i class="fa fa-check"></i><b>14.1</b> Pivotal Quantities</a></li>
<li class="chapter" data-level="14.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#large-sample-confidence-intervals"><i class="fa fa-check"></i><b>14.2</b> Large sample confidence intervals</a>
<ul>
<li class="chapter" data-level="" data-path="confidence-intervals.html"><a href="confidence-intervals.html#confidence-intervals-for-mu_1-mu_2"><i class="fa fa-check"></i>Confidence Intervals for <span class="math inline">\(\mu_1-\mu_2\)</span></a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Using R</b></span></li>
<li class="chapter" data-level="A" data-path="sampling-in-R.html"><a href="sampling-in-R.html"><i class="fa fa-check"></i><b>A</b> Sampling in R</a>
<ul>
<li class="chapter" data-level="A.1" data-path="sampling-in-R.html"><a href="sampling-in-R.html#vectors-R"><i class="fa fa-check"></i><b>A.1</b> Data vectors</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#vector-types"><i class="fa fa-check"></i>vector types</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#matrices"><i class="fa fa-check"></i>Matrices</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#data-frames"><i class="fa fa-check"></i>data frames</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#common-vector-commands"><i class="fa fa-check"></i>common vector commands</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#comparison-operators"><i class="fa fa-check"></i>Comparison Operators</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sum-and-which"><i class="fa fa-check"></i><code>sum()</code> and <code>which()</code></a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#extracting-elements"><i class="fa fa-check"></i>extracting elements</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#comparing-vectors"><i class="fa fa-check"></i>comparing vectors</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#vector-arithmetic"><i class="fa fa-check"></i>vector arithmetic</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#concatenate-vectors"><i class="fa fa-check"></i>concatenate vectors</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="sampling-in-R.html"><a href="sampling-in-R.html#special-vectors"><i class="fa fa-check"></i><b>A.2</b> Special vectors</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#consecutive-integers"><i class="fa fa-check"></i>consecutive integers</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#letters"><i class="fa fa-check"></i>letters</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#rep"><i class="fa fa-check"></i><code>rep()</code></a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#table"><i class="fa fa-check"></i><code>table()</code></a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#seq"><i class="fa fa-check"></i><code>seq()</code></a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sampling-in-R-section"><i class="fa fa-check"></i><b>A.3</b> Sampling</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sample-options"><i class="fa fa-check"></i><code>sample()</code> options</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sample-without-replacement"><i class="fa fa-check"></i>Sample without replacement</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sample-with-replacement"><i class="fa fa-check"></i>Sample with replacement</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sample-with-custom-probabilities"><i class="fa fa-check"></i>Sample with custom probabilities</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#example-lefties"><i class="fa fa-check"></i>Example: Lefties</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="sampling-in-R.html"><a href="sampling-in-R.html#repeated-sampling"><i class="fa fa-check"></i><b>A.4</b> Repeated Sampling</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#using-a-for-loop"><i class="fa fa-check"></i>using a <code>for</code> loop</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#using-replicate"><i class="fa fa-check"></i>using <code>replicate()</code></a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sampling-commands"><i class="fa fa-check"></i><b>A.5</b> Summary of R commands</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#defining-vectors"><i class="fa fa-check"></i>defining vectors</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#summarizing-vectors"><i class="fa fa-check"></i>summarizing vectors</a></li>
<li class="chapter" data-level="" data-path="sampling-in-R.html"><a href="sampling-in-R.html#sampling-from-vectors"><i class="fa fa-check"></i>sampling from vectors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="R-sim-probability.html"><a href="R-sim-probability.html"><i class="fa fa-check"></i><b>B</b> Simulating Probability in R</a>
<ul>
<li class="chapter" data-level="B.1" data-path="R-sim-probability.html"><a href="R-sim-probability.html#diff-2dice-R"><i class="fa fa-check"></i><b>B.1</b> Difference of two dice</a></li>
<li class="chapter" data-level="B.2" data-path="R-sim-probability.html"><a href="R-sim-probability.html#license-plates-R"><i class="fa fa-check"></i><b>B.2</b> Oregon License Plates</a></li>
<li class="chapter" data-level="B.3" data-path="R-sim-probability.html"><a href="R-sim-probability.html#id_10sided-die-R"><i class="fa fa-check"></i><b>B.3</b> Rolling a 10-sided die</a></li>
<li class="chapter" data-level="B.4" data-path="R-sim-probability.html"><a href="R-sim-probability.html#marbles-urn-R"><i class="fa fa-check"></i><b>B.4</b> Marbles from an urn</a></li>
<li class="chapter" data-level="B.5" data-path="R-sim-probability.html"><a href="R-sim-probability.html#flip-coin-R"><i class="fa fa-check"></i><b>B.5</b> Tracking runs of Heads in coin flips</a></li>
<li class="chapter" data-level="B.6" data-path="R-sim-probability.html"><a href="R-sim-probability.html#partition-set-R"><i class="fa fa-check"></i><b>B.6</b> Splitting a set into multiple subsets</a></li>
<li class="chapter" data-level="B.7" data-path="R-sim-probability.html"><a href="R-sim-probability.html#pollsters-R"><i class="fa fa-check"></i><b>B.7</b> Pollsters</a></li>
<li class="chapter" data-level="B.8" data-path="R-sim-probability.html"><a href="R-sim-probability.html#same-birthday-R"><i class="fa fa-check"></i><b>B.8</b> Matching Birthdays</a></li>
<li class="chapter" data-level="B.9" data-path="R-sim-probability.html"><a href="R-sim-probability.html#flipping-coins-with-fibonacci"><i class="fa fa-check"></i><b>B.9</b> Flipping Coins with Fibonacci</a></li>
<li class="chapter" data-level="B.10" data-path="R-sim-probability.html"><a href="R-sim-probability.html#seats-on-an-airplane"><i class="fa fa-check"></i><b>B.10</b> Seats on an airplane</a></li>
<li class="chapter" data-level="B.11" data-path="R-sim-probability.html"><a href="R-sim-probability.html#drawing-names-for-homemades"><i class="fa fa-check"></i><b>B.11</b> Drawing names for Homemades</a>
<ul>
<li class="chapter" data-level="" data-path="R-sim-probability.html"><a href="R-sim-probability.html#mathematical-addendum-to-the-question-of-drawing-names."><i class="fa fa-check"></i>Mathematical addendum to the question of drawing names.</a></li>
</ul></li>
<li class="chapter" data-level="B.12" data-path="R-sim-probability.html"><a href="R-sim-probability.html#idiots-delight"><i class="fa fa-check"></i><b>B.12</b> Idiot’s Delight</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="R-discreteRV.html"><a href="R-discreteRV.html"><i class="fa fa-check"></i><b>C</b> Discrete Random Variables in R</a>
<ul>
<li class="chapter" data-level="C.1" data-path="R-discreteRV.html"><a href="R-discreteRV.html#binomialR"><i class="fa fa-check"></i><b>C.1</b> Binomial <code>binom</code></a>
<ul>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#dbinom---probability-function"><i class="fa fa-check"></i><code>dbinom()</code> - probability function</a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#pbinom---cumulative-probability"><i class="fa fa-check"></i><code>pbinom()</code> - cumulative probability</a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#qbinom---quantiles"><i class="fa fa-check"></i><code>qbinom()</code> - quantiles</a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#rbinom---sampling"><i class="fa fa-check"></i><code>rbinom()</code> - sampling</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="R-discreteRV.html"><a href="R-discreteRV.html#geometricR"><i class="fa fa-check"></i><b>C.2</b> Geometric <code>geom</code></a></li>
<li class="chapter" data-level="C.3" data-path="R-discreteRV.html"><a href="R-discreteRV.html#negbinomR"><i class="fa fa-check"></i><b>C.3</b> Negative Binomial <code>nbinom</code></a></li>
<li class="chapter" data-level="C.4" data-path="R-discreteRV.html"><a href="R-discreteRV.html#hyperR"><i class="fa fa-check"></i><b>C.4</b> Hypergeometric <code>hyper</code></a></li>
<li class="chapter" data-level="C.5" data-path="R-discreteRV.html"><a href="R-discreteRV.html#poissonR"><i class="fa fa-check"></i><b>C.5</b> Poisson <code>pois</code></a></li>
<li class="chapter" data-level="C.6" data-path="R-discreteRV.html"><a href="R-discreteRV.html#custom-discrete-R"><i class="fa fa-check"></i><b>C.6</b> Homemade Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#expected-value-of-x"><i class="fa fa-check"></i>Expected Value of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#variance-of-x"><i class="fa fa-check"></i>Variance of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#distribution-plots"><i class="fa fa-check"></i>Distribution Plots</a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#sampling"><i class="fa fa-check"></i>Sampling</a></li>
<li class="chapter" data-level="C.6.1" data-path="R-discreteRV.html"><a href="R-discreteRV.html#discrete-uniform-distribution"><i class="fa fa-check"></i><b>C.6.1</b> Discrete Uniform Distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="R-continuousRV.html"><a href="R-continuousRV.html"><i class="fa fa-check"></i><b>D</b> Continuous Random Variables in R</a>
<ul>
<li class="chapter" data-level="D.1" data-path="R-continuousRV.html"><a href="R-continuousRV.html#unifR"><i class="fa fa-check"></i><b>D.1</b> Uniform Distribution</a>
<ul>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#picking-random-numbers"><i class="fa fa-check"></i>Picking random numbers</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#picking-random-points-in-the-unit-square"><i class="fa fa-check"></i>Picking random points in the unit square</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimate-the-value-of-pi"><i class="fa fa-check"></i>Estimate the value of <span class="math inline">\(\pi\)</span></a></li>
</ul></li>
<li class="chapter" data-level="D.2" data-path="R-continuousRV.html"><a href="R-continuousRV.html#normalR"><i class="fa fa-check"></i><b>D.2</b> Normal Distribution <code>norm</code></a>
<ul>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#sampling-distribution-of-a-sample-mean"><i class="fa fa-check"></i>Sampling Distribution of a sample mean</a></li>
</ul></li>
<li class="chapter" data-level="D.3" data-path="R-continuousRV.html"><a href="R-continuousRV.html#expR"><i class="fa fa-check"></i><b>D.3</b> Exponential Distribution <code>exp</code></a>
<ul>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#a-memoryless-distribution"><i class="fa fa-check"></i>A Memoryless distribution</a></li>
</ul></li>
<li class="chapter" data-level="D.4" data-path="R-continuousRV.html"><a href="R-continuousRV.html#gammaR"><i class="fa fa-check"></i><b>D.4</b> Gamma Distribution <code>gamma</code></a></li>
<li class="chapter" data-level="D.5" data-path="R-continuousRV.html"><a href="R-continuousRV.html#chiR"><i class="fa fa-check"></i><b>D.5</b> Chi-square Distribution <code>chisq</code></a></li>
<li class="chapter" data-level="D.6" data-path="R-continuousRV.html"><a href="R-continuousRV.html#betaR"><i class="fa fa-check"></i><b>D.6</b> Beta distribution <code>beta</code></a></li>
<li class="chapter" data-level="D.7" data-path="R-continuousRV.html"><a href="R-continuousRV.html#custom-continuous-R"><i class="fa fa-check"></i><b>D.7</b> Homemade Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#input-the-density-function"><i class="fa fa-check"></i>Input the density function</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#visualize-the-density-function"><i class="fa fa-check"></i>Visualize the density function</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimating-integrals-with-riemann-sums"><i class="fa fa-check"></i>Estimating Integrals with Riemann Sums</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimating-probabilities"><i class="fa fa-check"></i>Estimating Probabilities</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#the-distribution-function-fx"><i class="fa fa-check"></i>The distribution function <span class="math inline">\(F(X)\)</span></a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimating-moments"><i class="fa fa-check"></i>Estimating Moments</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#expected-value-1"><i class="fa fa-check"></i>Expected Value</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH 340 Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="estimation" class="section level1 hasAnchor" number="13">
<h1><span class="header-section-number">13</span> Estimation<a href="estimation.html#estimation" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><strong>The Scene</strong>: We want to estimate some parameter <span class="math inline">\(\theta\)</span> of a population by gathering and analyzing an independent random sample drawn from the population.</p>
<div id="unbiased-estimators" class="section level2 hasAnchor" number="13.1">
<h2><span class="header-section-number">13.1</span> Unbiased Estimators<a href="estimation.html#unbiased-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="definition">
<p><span id="def:statistic" class="definition"><strong>Definition 13.1  </strong></span>A <strong>statistic</strong> is any function of a random sample <span class="math inline">\(X_1, X_2, \ldots X_n\)</span> drawn from a population.</p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-59" class="definition"><strong>Definition 13.2  </strong></span>A statistic <span class="math inline">\(\hat{\theta}\)</span> based on a random sample <span class="math inline">\(X_1, X_2, \ldots X_n\)</span> is an <strong>unbiased estimator</strong> of the population parameter <span class="math inline">\(\theta\)</span> if <span class="math inline">\(E(\hat{\theta}) = \theta\)</span>.</p>
<p>The <strong>bias of <span class="math inline">\(\hat{\theta}_n\)</span></strong> is <span class="math inline">\(B(\hat{\theta}) = E(\hat{\theta})-\theta\)</span>.</p>
<p>The <strong>mean square error of <span class="math inline">\(\hat{\theta}_n\)</span></strong> is MSE<span class="math inline">\((\hat{\theta}) = E[(\hat{\theta}-\theta)^2]\)</span>.</p>
</div>
<p>A <em>good</em> estimator for the parameter <span class="math inline">\(\theta\)</span> is a statistic <span class="math inline">\(\hat{\theta}\)</span> that is unbiased with variance as small as possible. These features of <span class="math inline">\(\hat{\theta}\)</span> would ensure that for any random sample you happen to gather, the value <span class="math inline">\(\hat{\theta}\)</span> you compute from the data is likely to be close to <span class="math inline">\(\theta\)</span> (or at least likelier to be close to <span class="math inline">\(\theta\)</span> than some other statistic).</p>
<div class="example">
<p><span id="exm:estimating-uniform-parameter" class="example"><strong>Example 13.1  (Two unbiased estimators for the upper bound of a uniform distribution) </strong></span>Suppose <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> is an independent random sample drawn from a uniform distribution <span class="math inline">\(U(0,\theta),\)</span> where <span class="math inline">\(\theta\)</span> is unknown.
So each <span class="math inline">\(X_i\)</span> is a random real number between 0 and <span class="math inline">\(\theta\)</span>.</p>
<blockquote>
<p>How can we estimate the unknown parameter <span class="math inline">\(\theta\)</span> from the data?</p>
</blockquote>
<p><strong>First estimator</strong>: Create an estimator from the sample mean: <span class="math display">\[\overline{X} = \frac{1}{n}\sum_{i = 1}^n X_i.\]</span></p>
<p>By properties of expected value,
<span class="math display">\[\begin{align*}
E(\overline{X}) &amp;= \frac{1}{n}\sum_{i = 1}^n E(X_i) \\
                &amp;= \frac{1}{n}\sum_{i = 1}^n \frac{\theta}{2}
\end{align*}\]</span>
since each <span class="math inline">\(X_i\)</span> is <span class="math inline">\(U(0,\theta),\)</span> so <span class="math inline">\(E(X_i) = \frac{0 + \theta}{2}\)</span>.</p>
<p>It follows that <span class="math display">\[E(\overline{X}) = \frac{1}{n} \cdot n \cdot \frac{\theta}{2} = \frac{\theta}{2}.\]</span></p>
<p>Since <span class="math inline">\(E(\overline{X}) \neq \theta,\)</span> the sample mean <span class="math inline">\(\overline{X}\)</span> is not an unbiased estimator for <span class="math inline">\(\theta\)</span>. This makes sense. We shouldn’t expect the average of the random numbers to be a good estimate of the upper bound of the interval from which the numbers were picked.</p>
<p>However, <span class="math inline">\(E(\overline{X})\)</span> <em>does</em> equal <strong>a constant multiple</strong> of <span class="math inline">\(\theta,\)</span> which means we can easily adjust <span class="math inline">\(\overline{X}\)</span> to a statistic that <em>is</em> an unbiased estimator for <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[\hat{\theta}_1 = 2\overline{X} \tag{unbiased estimator 1}\]</span>
<strong>Second Estimator</strong>: Create an estimator from the maximum value of the data, since this max is “closest” to <span class="math inline">\(\theta\)</span> of all the data points.</p>
<p>Let <span class="math inline">\(Y = \max\{X_1, X_2, \ldots, X_n\}.\)</span> We prove below in <a href="estimation.html#order-statistics">13.2</a> that <span class="math display">\[E(Y) = \frac{n}{n+1}\theta.\]</span>
Assuming that for now, we can say that <span class="math display">\[\hat{\theta}_2 = \frac{n+1}{n}\cdot Y \tag{unbiased estimator 2}\]</span> is also an unbiased estimator for <span class="math inline">\(\theta\)</span>.</p>
<p>Let’s see how these different estimators do for a particular random sample generated in R.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="estimation.html#cb27-1" tabindex="-1"></a>theta <span class="ot">=</span> <span class="dv">20</span> <span class="co"># we pretend we don&#39;t know this parameter</span></span>
<span id="cb27-2"><a href="estimation.html#cb27-2" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">10</span> <span class="co"># the size of the sample</span></span>
<span id="cb27-3"><a href="estimation.html#cb27-3" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">runif</span>(n,<span class="dv">0</span>,theta) <span class="co"># generate the random sample</span></span>
<span id="cb27-4"><a href="estimation.html#cb27-4" tabindex="-1"></a>est_1 <span class="ot">=</span> <span class="dv">2</span><span class="sc">*</span><span class="fu">mean</span>(X)</span>
<span id="cb27-5"><a href="estimation.html#cb27-5" tabindex="-1"></a>est_2 <span class="ot">=</span> (n<span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span>n<span class="sc">*</span><span class="fu">max</span>(X)</span>
<span id="cb27-6"><a href="estimation.html#cb27-6" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">round</span>(X,<span class="dv">2</span>))</span></code></pre></div>
<pre><code>##  [1]  6.99 15.90 13.34 10.15  8.74  0.75 16.61  4.04 19.56 11.77</code></pre>
<p>For this single sample the estimators takes on these values:</p>
<ul>
<li>Estimator 1: <span class="math inline">\(\hat{\theta}_1\)</span> = 21.6</li>
<li>Estimator 2: <span class="math inline">\(\hat{\theta}_2\)</span> = 21.5.</li>
</ul>
<p>The fact that both estimators are unbiased means that in the long run, the average of all the <span class="math inline">\(\hat{\theta}_1\)</span> estimates would approach <span class="math inline">\(\theta,\)</span> and the same is true for the average of the <span class="math inline">\(\hat{\theta}_2\)</span> estimates.</p>
<p>So, they’re both good estimaors of <span class="math inline">\(\theta\)</span> in that regard. What makes one estimator better is if the <em>variation</em> of the estimates obtained from repeated sampling is smaller for one than the other.</p>
<p>Let’s simulate drawing 1000 different samples of size <span class="math inline">\(n = 10,\)</span> recording the distribution of values taken by the estimates <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_2,\)</span> and seeing which distribution has smaller variance.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="estimation.html#cb29-1" tabindex="-1"></a>theta <span class="ot">=</span> <span class="dv">20</span>;n <span class="ot">=</span> <span class="dv">10</span> <span class="co"># the size of the sample in each trial</span></span>
<span id="cb29-2"><a href="estimation.html#cb29-2" tabindex="-1"></a>trials <span class="ot">=</span> <span class="dv">1000</span> <span class="co"># number of times we take a sample of size n</span></span>
<span id="cb29-3"><a href="estimation.html#cb29-3" tabindex="-1"></a>dist_1 <span class="ot">=</span> <span class="fu">c</span>() <span class="co"># records estimator 1 values</span></span>
<span id="cb29-4"><a href="estimation.html#cb29-4" tabindex="-1"></a>dist_2 <span class="ot">=</span> <span class="fu">c</span>() <span class="co"># records estimator 2 values</span></span>
<span id="cb29-5"><a href="estimation.html#cb29-5" tabindex="-1"></a><span class="co"># run the trials</span></span>
<span id="cb29-6"><a href="estimation.html#cb29-6" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>trials){</span>
<span id="cb29-7"><a href="estimation.html#cb29-7" tabindex="-1"></a>  X <span class="ot">=</span> <span class="fu">runif</span>(n,<span class="dv">0</span>,theta) <span class="co"># generate the random sample</span></span>
<span id="cb29-8"><a href="estimation.html#cb29-8" tabindex="-1"></a>  dist_1[i] <span class="ot">=</span> <span class="dv">2</span><span class="sc">*</span><span class="fu">mean</span>(X)</span>
<span id="cb29-9"><a href="estimation.html#cb29-9" tabindex="-1"></a>  dist_2[i] <span class="ot">=</span> (n<span class="sc">+</span><span class="dv">1</span>)<span class="sc">/</span>n<span class="sc">*</span><span class="fu">max</span>(X)</span>
<span id="cb29-10"><a href="estimation.html#cb29-10" tabindex="-1"></a>}</span>
<span id="cb29-11"><a href="estimation.html#cb29-11" tabindex="-1"></a><span class="co"># create data frame of results for ggplot</span></span>
<span id="cb29-12"><a href="estimation.html#cb29-12" tabindex="-1"></a>df <span class="ot">=</span> <span class="fu">rbind</span>(<span class="fu">data.frame</span>(<span class="at">estimator =</span> <span class="st">&quot;1&quot;</span>,<span class="at">value =</span> dist_1),</span>
<span id="cb29-13"><a href="estimation.html#cb29-13" tabindex="-1"></a>           <span class="fu">data.frame</span>(<span class="at">estimator =</span> <span class="st">&quot;2&quot;</span>,<span class="at">value =</span> dist_2))</span>
<span id="cb29-14"><a href="estimation.html#cb29-14" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb29-15"><a href="estimation.html#cb29-15" tabindex="-1"></a><span class="fu">ggplot</span>(df)<span class="sc">+</span></span>
<span id="cb29-16"><a href="estimation.html#cb29-16" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x=</span>value,<span class="at">fill=</span>estimator),<span class="at">alpha =</span> .<span class="dv">4</span>)<span class="sc">+</span></span>
<span id="cb29-17"><a href="estimation.html#cb29-17" tabindex="-1"></a>  <span class="fu">theme_get</span>()</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-36"></span>
<img src="math340-notes_files/figure-html/unnamed-chunk-36-1.png" alt="Sampling distributions for two unbiased estimators" width="384" />
<p class="caption">
Figure 13.1: Sampling distributions for two unbiased estimators
</p>
</div>
<p>Both estimators have average value near 20. In fact,</p>
<ul>
<li><code>mean(dist_1)</code>- = 20</li>
<li><code>mean(dist_2)</code> = 20.01.</li>
</ul>
<p>But the estimator 2 distribution has visibly smaller variance. Indeed,</p>
<ul>
<li><code>sd(dist_1)</code> = 3.71</li>
<li><code>sd(dist_2)</code> = 1.84.</li>
</ul>
<p>It appears that the better estimator here is the one derived from the maximum value of the data as opposed to the mean of the data.</p>
</div>
</div>
<div id="order-statistics" class="section level2 hasAnchor" number="13.2">
<h2><span class="header-section-number">13.2</span> Order Statistics<a href="estimation.html#order-statistics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> is a sample drawn from a distribution with density function <span class="math inline">\(f_X(x),\)</span> let <span class="math display">\[Y = \text{max}\{X_1, X_2, \ldots, X_n\}.\]</span>
We can deduce the density function for <span class="math inline">\(Y\)</span> by first writing down the distribution function. For any real number <span class="math inline">\(y,\)</span>
<span class="math display">\[\begin{align*}
F_Y(y) &amp;= P(Y \leq y) \\
      &amp;= P(\text{all }X_i \leq y) \\
      &amp;= P(X_1 \leq y, X_2 \leq y, \ldots, X_n \leq y) \\
      &amp;= \left[F_X(y)\right]^n.
\end{align*}\]</span>
We differentiate <span class="math inline">\(F_Y\)</span> with the chain rule to find <span class="math inline">\(f_Y\)</span>:
Thus, <span class="math display">\[f_Y = n\left[F_X(y)\right]^{n-1}\cdot f_X(y). \tag{density for the max of sample}\]</span>
For <span class="math inline">\(X\)</span> is <span class="math inline">\(U(0,\theta)\)</span> as in the previous example, <span class="math inline">\(f_X(x) = 1/\theta,\)</span> and <span class="math inline">\(F_X(x) = x/\theta,\)</span> for <span class="math inline">\(0 \leq x \leq \theta\)</span>. So, the density function for <span class="math inline">\(Y = \text{max}(X_i),\)</span> where <span class="math inline">\(X_i\)</span> is <span class="math inline">\(U(0,\theta)\)</span> is
<span class="math display">\[\begin{align*}
f_Y(y) &amp;= n \left[\frac{y}{\theta}\right]^{n-1} \cdot \frac{1}{\theta}\\
      &amp;= \frac{n}{\theta^n}y^{n-1},
\end{align*}\]</span>
for <span class="math inline">\(0 \leq y \leq \theta,\)</span>
and <span class="math display">\[E(Y) = \int_0^\theta y \cdot \frac{n}{\theta^n}y^{n-1}~dy = \cdots = \frac{n}{n+1}\theta,\]</span>
giving us the result we assumed when defining estimator 2 in the previous example.</p>
<p>In the homework you derive the density function for the minimum of a random sample.</p>
</div>
<div id="common-unbiased-estimators" class="section level2 hasAnchor" number="13.3">
<h2><span class="header-section-number">13.3</span> Common Unbiased Estimators<a href="estimation.html#common-unbiased-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have seen the following strategy for finding unbiased estimators: Try a simple estimator (e.g., <span class="math inline">\(\overline{X}\)</span> or max<span class="math inline">\((X_i)\)</span>) and tweak it so that it becomes unbiased.</p>
<div id="estimating-mu-a-population-mean" class="section level3 hasAnchor" number="13.3.1">
<h3><span class="header-section-number">13.3.1</span> Estimating <span class="math inline">\(\mu,\)</span> a population mean<a href="estimation.html#estimating-mu-a-population-mean" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> is a sample drawn from a distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span> we have seen that the sample mean <span class="math inline">\(\overline{X}\)</span> has <span class="math inline">\(E(\overline{X}) = \mu\)</span> and standard deviation <span class="math inline">\(\sigma/\sqrt{n}\)</span>. That is,</p>
<blockquote>
<p><span class="math inline">\(\overline{X}\)</span> is an unbiased estimator for <span class="math inline">\(\mu,\)</span> and its standard deviation is <span class="math inline">\(\sigma/\sqrt{n}\)</span>.</p>
</blockquote>
</div>
<div id="estimating-p-a-population-proportion" class="section level3 hasAnchor" number="13.3.2">
<h3><span class="header-section-number">13.3.2</span> Estimating <span class="math inline">\(p,\)</span> a population proportion<a href="estimation.html#estimating-p-a-population-proportion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> is a sample drawn from a <span class="math inline">\(b(1,n)\)</span> distribution (Bernoulli trial!) and <span class="math inline">\(X = X_1 + X_2 + \cdots + X_n\)</span> equals the number of successes in <span class="math inline">\(n\)</span> trials, then we have seen that <span class="math inline">\(\hat{p} = X/n\)</span> has <span class="math inline">\(E(\hat{p}) = p\)</span> and standard deviation <span class="math inline">\(\displaystyle\sqrt{\frac{p(1-p)}{n}}\)</span>. That is,</p>
<blockquote>
<p><span class="math inline">\(\hat{p}\)</span> is an unbiased estimator for <span class="math inline">\(p,\)</span> and its standard deviation is <span class="math inline">\(\displaystyle\sqrt{\frac{p(1-p)}{n}}\)</span>.</p>
</blockquote>
<div class="example">
<p><span id="exm:unlabeled-div-60" class="example"><strong>Example 13.2  </strong></span>In a sample of 65 Linfield students, 24 are first-generation students. Estimate <span class="math inline">\(p,\)</span> the proportion of all Linfield students that are first-generation, and place a 2 standard deviation bound on the error of estimation.</p>
<p>From our sample, our point estimate for <span class="math inline">\(p\)</span> is <span class="math inline">\(\hat{p} = 24/65 \approx .369.\)</span> We know by the CLT that <span class="math display">\[\hat{p} \sim N(p, \sqrt{p(1-p)/n}),\]</span>
and in a normal distribution, about 95% of the distribution is within two standard deviations of the mean. In other words,
<span class="math display">\[P\left(~|\hat{p}-p|&lt;2\cdot\sqrt{p(1-p)/n}~\right) \approx 0.95.\]</span>
Now we don’t know <span class="math inline">\(p\)</span> (in fact, we’re trying to estimate it!), so we can’t know the value of the standard deviation <span class="math inline">\(\sqrt{p(1-p)/n}.\)</span> However, for large <span class="math inline">\(n,\)</span> the expression <span class="math inline">\(\sqrt{x(1-x)/n}\)</span> doesn’t change much for nearby inputs, except when the inputs are close to 0 or 1 (try it!). In other words, we can reasonably expect <span class="math display">\[\sqrt{\hat{p}(1-\hat{p})/n} ~\approx \sqrt{p(1-p)/n},\]</span> in which case we can estimate that
<span class="math display">\[P\left(~|\hat{p}-p|&lt;2\cdot\sqrt{\hat{p}(1-\hat{p})/n}~\right) \approx 0.95.\]</span>
In this problem <span class="math inline">\(\hat{p} \approx .37,\)</span> so <span class="math inline">\(2 \cdot \sqrt{p(1-p)/n} \approx 0.12,\)</span> so we can say that <span class="math display">\[|.37-p| &lt; 0.12\]</span> with probability about .95, and that
<span class="math display">\[ .25 &lt; p &lt; .49\]</span> gives a two standard deviation bound on the error of estimation.</p>
</div>
</div>
<div id="estimating-mu_1---mu_2-the-difference-of-two-population-means" class="section level3 hasAnchor" number="13.3.3">
<h3><span class="header-section-number">13.3.3</span> Estimating <span class="math inline">\(\mu_1 - \mu_2,\)</span> the difference of two population means<a href="estimation.html#estimating-mu_1---mu_2-the-difference-of-two-population-means" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose we have two independent random samples drawn from distinct normal distributions.</p>
<ul>
<li><span class="math inline">\(X_1, \ldots, X_{n_1} \sim N(\mu_1,\sigma_1)\)</span></li>
<li><span class="math inline">\(Y_1, \ldots, Y_{n_2} \sim N(\mu_2, \sigma_2)\)</span></li>
</ul>
<p>Let <span class="math inline">\(\overline{X}\)</span> and <span class="math inline">\(\overline{Y}\)</span> denote the respective sample means, and consider the point estimate <span class="math inline">\(\overline{X}-\overline{Y}\)</span> of <span class="math inline">\(\mu_1-\mu_2\)</span>.
Since <span class="math inline">\(\overline{X}-\overline{Y}\)</span> is a linear combination of normal random variables, we can show <span class="math inline">\(\overline{X}-\overline{Y}\)</span> is itself normal, with</p>
<ul>
<li>mean = <span class="math inline">\(E(\overline{X}-\overline{Y}) = E(\overline{X})-E(\overline{Y}) = \mu_1 - \mu_2\)</span></li>
<li>variance = <span class="math inline">\(V(\overline{X}-\overline{Y}) = V(\overline{X})+V(\overline{Y}) = \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}\)</span>.</li>
</ul>
<p>So <span class="math inline">\(\overline{X}-\overline{Y}\)</span> is an unbiased estimator for <span class="math inline">\(\mu_1 - \mu_2\)</span> with standard deviation equal to <span class="math inline">\(\displaystyle\sqrt{\sigma_1^2/n_1 + \sigma_2^2/n_2}.\)</span></p>
</div>
<div id="estimating-p_1---p_2-the-difference-of-two-population-proportions" class="section level3 hasAnchor" number="13.3.4">
<h3><span class="header-section-number">13.3.4</span> Estimating <span class="math inline">\(p_1 - p_2,\)</span> the difference of two population proportions<a href="estimation.html#estimating-p_1---p_2-the-difference-of-two-population-proportions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>An unbiased estimator for <span class="math inline">\(p_1-p_2\)</span> is <span class="math inline">\(\hat{p}_1-\hat{p}_2,\)</span> where <span class="math inline">\(\hat{p}_i\)</span> equals the sample proportion from a sample of size <span class="math inline">\(n_i\)</span> drawn from population <span class="math inline">\(i\)</span> (which has population proportion <span class="math inline">\(p_i\)</span>).</p>
<p>One can show that the point estimate <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span> is approximately normal with mean <span class="math inline">\(p_1-p_2\)</span> and standard deviation <span class="math inline">\(\displaystyle \sqrt{\frac{p_1(1-p_1)}{n_1}+\frac{p_2(1-p_2)}{n_2}}\)</span> for reasonably sized samples (more on this later). For now lets consider an example.</p>
<div class="example">
<p><span id="exm:unlabeled-div-61" class="example"><strong>Example 13.3  (Two Large Buckets) </strong></span>Each of two large buckets is full of two types of marbles, orange and green. Let <span class="math inline">\(p_i\)</span> denote the proportion of orange marbles in bucket <span class="math inline">\(i\)</span> (<span class="math inline">\(i = 1,2\)</span>).</p>
<blockquote>
<p>Estimate <span class="math inline">\(p_1-p_2,\)</span> and place a 2 standard deviation bound on the error of estimation.</p>
</blockquote>
<ul>
<li>Sample 1: <span class="math inline">\(n_1 = 120\)</span> marbles from bucket 1, of which 45 are orange, so <span class="math inline">\(\hat{p}_1 = .375\)</span></li>
<li>Sample 2: <span class="math inline">\(n_2 = 80\)</span> marbles from bucket 2, of which 36 are orange, so <span class="math inline">\(\hat{p}_2 = .45\)</span>.</li>
</ul>
<p>Point estimate: <span class="math display">\[\hat{p}_1 - \hat{p}_2 = -.075.\]</span>
Also, it is reasonable to assume that the sampling distribution for <span class="math inline">\(\hat{p}_1-\hat{p}_2\)</span> is approximately
<span class="math display">\[N\left(p_1-p_2, \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1}+\frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}\right)\]</span>
(again, plugging in <span class="math inline">\(\hat{p}_i\)</span> for <span class="math inline">\(p_i\)</span> in the standard deviation is “ok” for larger sample sizes and values of <span class="math inline">\(\hat{p}_i\)</span> not too close to 0 or 1.).</p>
<p>For a normal distribution, about 95% of the distribution falls within 2 standard deviations of the mean, so
<span class="math display">\[P\left(|(\hat{p}_1-\hat{p}_2)-(p_1-p_2)|&lt; c\right)\approx .95,\]</span>
where <span class="math display">\[c = 2\cdot \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1}+\frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}.\]</span></p>
<p>So, we can say that <span class="math display">\[\hat{p}_1-\hat{p}_2 - c &lt; p_1 - p_2 &lt; \hat{p}_1-\hat{p}_2 + c\]</span> with probability about .95. Plugging in numbers in this example, we obtain the interval <span class="math display">\[-0.217 &lt; p_1 - p_2 &lt; 0.067.\]</span></p>
<p>Hmm… this interval contains 0. While the sample proportions here are such that we may suspect the second bucket has a higher proportion of orange marbles, when we take into account the error of estimation due to sampling variability, our samples do not provide overwhelming evidence that the buckets have different proportions of orange marbles.</p>
</div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="central-limit-theorem.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="confidence-intervals.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["math340-notes.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
