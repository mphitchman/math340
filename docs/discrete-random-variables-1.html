<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 Discrete Random Variables | MATH 340 Notes</title>
  <meta name="description" content="6 Discrete Random Variables | MATH 340 Notes" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="6 Discrete Random Variables | MATH 340 Notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Discrete Random Variables | MATH 340 Notes" />
  
  
  

<meta name="author" content="Mike Hitchman" />


<meta name="date" content="2024-07-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="probability-theory.html"/>
<link rel="next" href="important-discrete-rv.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://github.com/mphitchman/math340.git" target="blank">Math 340 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="sets.html"><a href="sets.html"><i class="fa fa-check"></i><b>2</b> Sets</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sets.html"><a href="sets.html#algebra-of-sets"><i class="fa fa-check"></i><b>2.1</b> Algebra of Sets</a></li>
<li class="chapter" data-level="2.2" data-path="sets.html"><a href="sets.html#size-of-sets"><i class="fa fa-check"></i><b>2.2</b> Set sizes</a></li>
<li class="chapter" data-level="2.3" data-path="sets.html"><a href="sets.html#sets-in-r"><i class="fa fa-check"></i><b>2.3</b> Sets in R</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html"><i class="fa fa-check"></i><b>3</b> Discrete Probability Distributions</a>
<ul>
<li class="chapter" data-level="3.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#sample-space"><i class="fa fa-check"></i><b>3.1</b> Sample Space</a></li>
<li class="chapter" data-level="3.2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#discrete-random-variables"><i class="fa fa-check"></i><b>3.2</b> Discrete Random Variables</a></li>
<li class="chapter" data-level="3.3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#calculating-probabilities"><i class="fa fa-check"></i><b>3.3</b> Calculating Probabilities</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#sample-point-method"><i class="fa fa-check"></i><b>3.3.1</b> Sample Point Method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="counting.html"><a href="counting.html"><i class="fa fa-check"></i><b>4</b> Counting Techniques</a>
<ul>
<li class="chapter" data-level="4.1" data-path="counting.html"><a href="counting.html#multipiclation-principle"><i class="fa fa-check"></i><b>4.1</b> Multipiclation Principle</a></li>
<li class="chapter" data-level="4.2" data-path="counting.html"><a href="counting.html#permutations"><i class="fa fa-check"></i><b>4.2</b> Permutations</a></li>
<li class="chapter" data-level="4.3" data-path="counting.html"><a href="counting.html#combinations"><i class="fa fa-check"></i><b>4.3</b> Combinations</a></li>
<li class="chapter" data-level="4.4" data-path="counting.html"><a href="counting.html#multinomial-coefficients"><i class="fa fa-check"></i><b>4.4</b> Multinomial Coefficients</a></li>
<li class="chapter" data-level="4.5" data-path="counting.html"><a href="counting.html#balls-and-bins"><i class="fa fa-check"></i><b>4.5</b> Balls and Bins</a></li>
<li class="chapter" data-level="4.6" data-path="counting.html"><a href="counting.html#prob-with-counting-tools"><i class="fa fa-check"></i><b>4.6</b> Calculating More Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>5</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="5.1" data-path="probability-theory.html"><a href="probability-theory.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>5.1</b> Conditional Probability and Independence</a></li>
<li class="chapter" data-level="5.2" data-path="probability-theory.html"><a href="probability-theory.html#two-laws-of-probability"><i class="fa fa-check"></i><b>5.2</b> Two Laws of Probability</a></li>
<li class="chapter" data-level="5.3" data-path="probability-theory.html"><a href="probability-theory.html#event-composition-method"><i class="fa fa-check"></i><b>5.3</b> Event-Composition Method</a></li>
<li class="chapter" data-level="5.4" data-path="probability-theory.html"><a href="probability-theory.html#bayes-rule"><i class="fa fa-check"></i><b>5.4</b> Bayesâ€™ Rule</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="discrete-random-variables-1.html"><a href="discrete-random-variables-1.html"><i class="fa fa-check"></i><b>6</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="discrete-random-variables-1.html"><a href="discrete-random-variables-1.html#expected-value"><i class="fa fa-check"></i><b>6.1</b> Expected Value</a></li>
<li class="chapter" data-level="6.2" data-path="discrete-random-variables-1.html"><a href="discrete-random-variables-1.html#variance"><i class="fa fa-check"></i><b>6.2</b> Variance</a></li>
<li class="chapter" data-level="6.3" data-path="discrete-random-variables-1.html"><a href="discrete-random-variables-1.html#properties-of-expected-value"><i class="fa fa-check"></i><b>6.3</b> Properties of Expected Value</a></li>
<li class="chapter" data-level="6.4" data-path="discrete-random-variables-1.html"><a href="discrete-random-variables-1.html#tchebysheffs-theorem"><i class="fa fa-check"></i><b>6.4</b> Tchebysheffâ€™s Theorem</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html"><i class="fa fa-check"></i><b>7</b> Important Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="7.1" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#binomial"><i class="fa fa-check"></i><b>7.1</b> Binomial Distributions</a></li>
<li class="chapter" data-level="7.2" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#geometric"><i class="fa fa-check"></i><b>7.2</b> Geometric Distributions</a></li>
<li class="chapter" data-level="7.3" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#negative-binomial"><i class="fa fa-check"></i><b>7.3</b> Negative Binomial Distribution</a></li>
<li class="chapter" data-level="7.4" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#hypergometric"><i class="fa fa-check"></i><b>7.4</b> Hypergeometric Distribution</a></li>
<li class="chapter" data-level="7.5" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#poisson"><i class="fa fa-check"></i><b>7.5</b> Poisson Distribution</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#poisson-process"><i class="fa fa-check"></i><b>7.5.1</b> Poisson Process</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="moments-and-moment-generating-functions.html"><a href="moments-and-moment-generating-functions.html"><i class="fa fa-check"></i><b>8</b> Moments and Moment-Generating Functions</a></li>
<li class="chapter" data-level="9" data-path="continuous-rv.html"><a href="continuous-rv.html"><i class="fa fa-check"></i><b>9</b> Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="9.1" data-path="continuous-rv.html"><a href="continuous-rv.html#distribution-functions"><i class="fa fa-check"></i><b>9.1</b> Distribution Functions</a></li>
<li class="chapter" data-level="9.2" data-path="continuous-rv.html"><a href="continuous-rv.html#expected-value-for-continuous-random-variables"><i class="fa fa-check"></i><b>9.2</b> Expected Value for Continuous Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html"><i class="fa fa-check"></i><b>10</b> Important Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="10.1" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#uniform-continuous"><i class="fa fa-check"></i><b>10.1</b> Uniform Distribution</a></li>
<li class="chapter" data-level="10.2" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#exponential-distribution"><i class="fa fa-check"></i><b>10.2</b> Exponential Distribution</a></li>
<li class="chapter" data-level="10.3" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#normal"><i class="fa fa-check"></i><b>10.3</b> Normal Distribution</a></li>
<li class="chapter" data-level="10.4" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#gamma-distribution"><i class="fa fa-check"></i><b>10.4</b> Gamma Distribution</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#exponential-distribution-1"><i class="fa fa-check"></i><b>10.4.1</b> Exponential Distribution</a></li>
<li class="chapter" data-level="10.4.2" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#chi-square-distribution"><i class="fa fa-check"></i><b>10.4.2</b> Chi-square distribution</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#beta-distribution"><i class="fa fa-check"></i><b>10.5</b> Beta Distribution</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="mgf.html"><a href="mgf.html"><i class="fa fa-check"></i><b>11</b> Moment Generating Functions</a></li>
<li class="chapter" data-level="12" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>12</b> Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="12.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#sums-of-random-variables"><i class="fa fa-check"></i><b>12.1</b> Sums of Random Variables</a></li>
<li class="chapter" data-level="12.2" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#t-distribution"><i class="fa fa-check"></i><b>12.2</b> T distribution</a></li>
<li class="chapter" data-level="12.3" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>12.3</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="12.4" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#normal-approximation-to-a-binomial-distribution"><i class="fa fa-check"></i><b>12.4</b> Normal Approximation to a binomial distribution</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>13</b> Estimation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="estimation.html"><a href="estimation.html#unbiased-estimators"><i class="fa fa-check"></i><b>13.1</b> Unbiased Estimators</a></li>
<li class="chapter" data-level="13.2" data-path="estimation.html"><a href="estimation.html#order-statistics"><i class="fa fa-check"></i><b>13.2</b> Order Statistics</a></li>
<li class="chapter" data-level="13.3" data-path="estimation.html"><a href="estimation.html#common-unbiased-estimators"><i class="fa fa-check"></i><b>13.3</b> Common Unbiased Estimators</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="estimation.html"><a href="estimation.html#estimating-mu-a-population-mean"><i class="fa fa-check"></i><b>13.3.1</b> Estimating <span class="math inline">\(\mu\)</span>, a population mean</a></li>
<li class="chapter" data-level="13.3.2" data-path="estimation.html"><a href="estimation.html#estimating-p-a-population-proportion"><i class="fa fa-check"></i><b>13.3.2</b> Estimating <span class="math inline">\(p\)</span>, a population proportion</a></li>
<li class="chapter" data-level="13.3.3" data-path="estimation.html"><a href="estimation.html#estimating-mu_1---mu_2-the-difference-of-two-population-means"><i class="fa fa-check"></i><b>13.3.3</b> Estimating <span class="math inline">\(\mu_1 - \mu_2\)</span>, the difference of two population means</a></li>
<li class="chapter" data-level="13.3.4" data-path="estimation.html"><a href="estimation.html#estimating-p_1---p_2-the-difference-of-two-population-proportions"><i class="fa fa-check"></i><b>13.3.4</b> Estimating <span class="math inline">\(p_1 - p_2\)</span>, the difference of two population proportions</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Using R</b></span></li>
<li class="chapter" data-level="A" data-path="sampling-in-r.html"><a href="sampling-in-r.html"><i class="fa fa-check"></i><b>A</b> Sampling in R</a>
<ul>
<li class="chapter" data-level="A.1" data-path="sampling-in-r.html"><a href="sampling-in-r.html#vectors-R"><i class="fa fa-check"></i><b>A.1</b> Data vectors</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#vector-types"><i class="fa fa-check"></i>vector types</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#matrices"><i class="fa fa-check"></i>Matrices</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#data-frames"><i class="fa fa-check"></i>data frames</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#common-vector-commands"><i class="fa fa-check"></i>common vector commands</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#comparison-operators"><i class="fa fa-check"></i>Comparison Operators</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sum-and-which"><i class="fa fa-check"></i><code>sum()</code> and <code>which()</code></a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#extracting-elements"><i class="fa fa-check"></i>extracting elements</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#comparing-vectors"><i class="fa fa-check"></i>comparing vectors</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#vector-arithmetic"><i class="fa fa-check"></i>vector arithmetic</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#concatenate-vectors"><i class="fa fa-check"></i>concatenate vectors</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="sampling-in-r.html"><a href="sampling-in-r.html#special-vectors"><i class="fa fa-check"></i><b>A.2</b> Special vectors</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#consecutive-integers"><i class="fa fa-check"></i>consecutive integers</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#letters"><i class="fa fa-check"></i>letters</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#rep"><i class="fa fa-check"></i><code>rep()</code></a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#table"><i class="fa fa-check"></i><code>table()</code></a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#seq"><i class="fa fa-check"></i><code>seq()</code></a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sampling-in-R"><i class="fa fa-check"></i><b>A.3</b> Sampling</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sample-options"><i class="fa fa-check"></i><code>sample()</code> options</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sample-without-replacement"><i class="fa fa-check"></i>Sample without replacement</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sample-with-replacement"><i class="fa fa-check"></i>Sample with replacement</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sample-with-custom-probabilities"><i class="fa fa-check"></i>Sample with custom probabilities</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#example-lefties"><i class="fa fa-check"></i>Example: Lefties</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="sampling-in-r.html"><a href="sampling-in-r.html#repeated-sampling"><i class="fa fa-check"></i><b>A.4</b> Repeated Sampling</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#using-a-for-loop"><i class="fa fa-check"></i>using a <code>for</code> loop</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#using-replicate"><i class="fa fa-check"></i>using <code>replicate()</code></a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sampling-commands"><i class="fa fa-check"></i><b>A.5</b> Summary of R commands</a>
<ul>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#defining-vectors"><i class="fa fa-check"></i>defining vectors</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#summarizing-vectors"><i class="fa fa-check"></i>summarizing vectors</a></li>
<li class="chapter" data-level="" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sampling-from-vectors"><i class="fa fa-check"></i>sampling from vectors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="R-sim-probability.html"><a href="R-sim-probability.html"><i class="fa fa-check"></i><b>B</b> Simulating Probability in R</a>
<ul>
<li class="chapter" data-level="B.1" data-path="R-sim-probability.html"><a href="R-sim-probability.html#id_10sided-die-R"><i class="fa fa-check"></i><b>B.1</b> Rolling a 10-sided die</a></li>
<li class="chapter" data-level="B.2" data-path="R-sim-probability.html"><a href="R-sim-probability.html#diff-2dice-R"><i class="fa fa-check"></i><b>B.2</b> Difference of two dice</a></li>
<li class="chapter" data-level="B.3" data-path="R-sim-probability.html"><a href="R-sim-probability.html#flip-coin-R"><i class="fa fa-check"></i><b>B.3</b> Flipping a coin</a></li>
<li class="chapter" data-level="B.4" data-path="R-sim-probability.html"><a href="R-sim-probability.html#marbles-urn-R"><i class="fa fa-check"></i><b>B.4</b> Marbles from an urn</a></li>
<li class="chapter" data-level="B.5" data-path="R-sim-probability.html"><a href="R-sim-probability.html#partition-set-R"><i class="fa fa-check"></i><b>B.5</b> Splitting a set into multiple subsets</a></li>
<li class="chapter" data-level="B.6" data-path="R-sim-probability.html"><a href="R-sim-probability.html#license-plates-R"><i class="fa fa-check"></i><b>B.6</b> Oregon License Plates</a></li>
<li class="chapter" data-level="B.7" data-path="R-sim-probability.html"><a href="R-sim-probability.html#pollsters-R"><i class="fa fa-check"></i><b>B.7</b> Pollsters</a></li>
<li class="chapter" data-level="B.8" data-path="R-sim-probability.html"><a href="R-sim-probability.html#same-birthday-R"><i class="fa fa-check"></i><b>B.8</b> Matching Birthdays</a></li>
<li class="chapter" data-level="B.9" data-path="R-sim-probability.html"><a href="R-sim-probability.html#flipping-coins-with-fibonacci"><i class="fa fa-check"></i><b>B.9</b> Flipping Coins with Fibonacci</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="R-discreteRV.html"><a href="R-discreteRV.html"><i class="fa fa-check"></i><b>C</b> Discrete Random Variables in R</a>
<ul>
<li class="chapter" data-level="C.1" data-path="R-discreteRV.html"><a href="R-discreteRV.html#expected-value-of-x"><i class="fa fa-check"></i><b>C.1</b> Expected Value of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="C.2" data-path="R-discreteRV.html"><a href="R-discreteRV.html#variance-of-x"><i class="fa fa-check"></i><b>C.2</b> Variance of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="C.3" data-path="R-discreteRV.html"><a href="R-discreteRV.html#distribution-plots"><i class="fa fa-check"></i><b>C.3</b> Distribution Plots</a></li>
<li class="chapter" data-level="C.4" data-path="R-discreteRV.html"><a href="R-discreteRV.html#sampling"><i class="fa fa-check"></i><b>C.4</b> Sampling</a></li>
<li class="chapter" data-level="C.5" data-path="R-discreteRV.html"><a href="R-discreteRV.html#discrete-uniform-distribution"><i class="fa fa-check"></i><b>C.5</b> Discrete Uniform Distribution</a></li>
<li class="chapter" data-level="C.6" data-path="R-discreteRV.html"><a href="R-discreteRV.html#r-4distn-functions"><i class="fa fa-check"></i><b>C.6</b> Important discrete random variables</a></li>
<li class="chapter" data-level="C.7" data-path="R-discreteRV.html"><a href="R-discreteRV.html#binomial-distribution-binom"><i class="fa fa-check"></i><b>C.7</b> Binomial Distribution <code>binom</code></a>
<ul>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#dbinom---density-function"><i class="fa fa-check"></i><code>dbinom()</code> - density function</a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#pbinom---cumulative-probability"><i class="fa fa-check"></i><code>pbinom()</code> - cumulative probability</a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#qbinom---quantiles"><i class="fa fa-check"></i><code>qbinom()</code> - quantiles</a></li>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#rbinom---sampling"><i class="fa fa-check"></i><code>rbinom()</code> - sampling</a></li>
</ul></li>
<li class="chapter" data-level="C.8" data-path="R-discreteRV.html"><a href="R-discreteRV.html#geometric-distribution-geom"><i class="fa fa-check"></i><b>C.8</b> Geometric Distribution <code>geom</code></a></li>
<li class="chapter" data-level="C.9" data-path="R-discreteRV.html"><a href="R-discreteRV.html#negative-binomial-distribution-nbinom"><i class="fa fa-check"></i><b>C.9</b> Negative Binomial Distribution <code>nbinom</code></a></li>
<li class="chapter" data-level="C.10" data-path="R-discreteRV.html"><a href="R-discreteRV.html#hypergeometric-distribution-hyper"><i class="fa fa-check"></i><b>C.10</b> Hypergeometric Distribution <code>hyper</code></a></li>
<li class="chapter" data-level="C.11" data-path="R-discreteRV.html"><a href="R-discreteRV.html#poisson-distribution-pois"><i class="fa fa-check"></i><b>C.11</b> Poisson Distribution <code>pois</code></a>
<ul>
<li class="chapter" data-level="" data-path="R-discreteRV.html"><a href="R-discreteRV.html#poisson-process-1"><i class="fa fa-check"></i>Poisson Process</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="R-continuousRV.html"><a href="R-continuousRV.html"><i class="fa fa-check"></i><b>D</b> Continuous Random Variables in R</a>
<ul>
<li class="chapter" data-level="D.1" data-path="R-continuousRV.html"><a href="R-continuousRV.html#unifR"><i class="fa fa-check"></i><b>D.1</b> Uniform Distribution</a>
<ul>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#picking-random-numbers"><i class="fa fa-check"></i>Picking random numbers!</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#picking-random-points-in-the-unit-square"><i class="fa fa-check"></i>Picking random points in the unit square!</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimate-the-value-of-pi"><i class="fa fa-check"></i>Estimate the value of <span class="math inline">\(\pi\)</span></a></li>
</ul></li>
<li class="chapter" data-level="D.2" data-path="R-continuousRV.html"><a href="R-continuousRV.html#normalR"><i class="fa fa-check"></i><b>D.2</b> Normal Distribution <code>norm</code></a>
<ul>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#sampling-distribution-of-a-sample-mean"><i class="fa fa-check"></i>Sampling Distribution of a sample mean</a></li>
</ul></li>
<li class="chapter" data-level="D.3" data-path="R-continuousRV.html"><a href="R-continuousRV.html#expR"><i class="fa fa-check"></i><b>D.3</b> Exponential Distribution <code>exp</code></a></li>
<li class="chapter" data-level="D.4" data-path="R-continuousRV.html"><a href="R-continuousRV.html#gammaR"><i class="fa fa-check"></i><b>D.4</b> Gamma Distribution <code>gamma</code></a></li>
<li class="chapter" data-level="D.5" data-path="R-continuousRV.html"><a href="R-continuousRV.html#chiR"><i class="fa fa-check"></i><b>D.5</b> Chi-square Distribution <code>chisq</code></a></li>
<li class="chapter" data-level="D.6" data-path="R-continuousRV.html"><a href="R-continuousRV.html#betaR"><i class="fa fa-check"></i><b>D.6</b> Beta distribution <code>beta</code></a></li>
<li class="chapter" data-level="D.7" data-path="R-continuousRV.html"><a href="R-continuousRV.html#customR"><i class="fa fa-check"></i><b>D.7</b> Homemade Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#input-the-density-function"><i class="fa fa-check"></i>Input the density function</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#visualize-the-density-function"><i class="fa fa-check"></i>Visualize the density function</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimating-integrals-with-riemann-sums"><i class="fa fa-check"></i>Estimating Integrals with Riemann Sums</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimating-probabilities"><i class="fa fa-check"></i>Estimating Probabilities</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#the-distribution-function-fx"><i class="fa fa-check"></i>The distribution function <span class="math inline">\(F(X)\)</span></a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimating-moments"><i class="fa fa-check"></i>Estimating Moments</a></li>
<li class="chapter" data-level="" data-path="R-continuousRV.html"><a href="R-continuousRV.html#expected-value-1"><i class="fa fa-check"></i>Expected Value</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH 340 Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="discrete-random-variables-1" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">6</span> Discrete Random Variables<a href="discrete-random-variables-1.html#discrete-random-variables-1" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Recall, a random variable <span class="math inline">\(X\)</span> is a real-valued function defined over a sample space associated with a chance experiment.</p>
<p>The <strong>space of <span class="math inline">\(X\)</span></strong> is the set of possible outcomes for <span class="math inline">\(X\)</span>, and a <strong>probability model</strong> for <span class="math inline">\(X\)</span> is an assignment <span class="math inline">\(p(x)\)</span> to each <span class="math inline">\(x\)</span> in the space of <span class="math inline">\(X\)</span> such that</p>
<ul>
<li>each <span class="math inline">\(p(x) \geq 0\)</span>, and</li>
<li>the sum of all the <span class="math inline">\(p(x)\)</span> equals 1.</li>
</ul>
<p>Letâ€™s look at some examples.</p>
<div class="example">
<p><span id="exm:draw-2-balls" class="example"><strong>Example 6.1  </strong></span>Five balls numbered 1 through 5 are placed in a hat. Two balls are randomly selected without replacement. We consider two random variables associated to this chance experiment:</p>
<ul>
<li><span class="math inline">\(X\)</span> is the largest of the two selected balls, and</li>
<li><span class="math inline">\(Y\)</span> is the sum of the two selected balls.</li>
</ul>
<blockquote>
<p>Find the space of <span class="math inline">\(X\)</span>, the space of <span class="math inline">\(Y\)</span>, and reasonable probability models for both random variables.</p>
</blockquote>
<p>OK, drawing two balls from five, without replacement, we have <span class="math inline">\(\binom{5}{2} = 10\)</span> possible outcomes. These 10 possible outcomes form the sample space associated with the chance experiment, and we assume each of these 10 outcomes is equally likely.</p>
<p>We can brute-force our answers by following the sample-point method: list all the sample points, and go!</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:balls-from-hat-rv">Table 6.1: </span>Two random variables associated with drawing two balls from a hat.
</caption>
<tbody>
<tr>
<td style="text-align:left;border-right:1px solid;">
S
</td>
<td style="text-align:center;">
{1,2}
</td>
<td style="text-align:center;">
{1,3}
</td>
<td style="text-align:center;">
{1,4}
</td>
<td style="text-align:center;">
{1,5}
</td>
<td style="text-align:center;">
{2,3}
</td>
<td style="text-align:center;">
{2,4}
</td>
<td style="text-align:center;">
{2,5}
</td>
<td style="text-align:center;">
{3,4}
</td>
<td style="text-align:center;">
{3,5}
</td>
<td style="text-align:center;">
{4,5}
</td>
</tr>
<tr>
<td style="text-align:left;border-right:1px solid;">
X
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
5
</td>
</tr>
<tr>
<td style="text-align:left;border-right:1px solid;">
Y
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
9
</td>
</tr>
</tbody>
</table>
<p>Again, we assume each of the 10 elements in <span class="math inline">\(S\)</span> is equally likely, so the probability that <span class="math inline">\(X = 4\)</span>, say, will be the 3/10 since <span class="math inline">\(X\)</span> takes the value 4 for 3 of the 10 elements in <span class="math inline">\(S\)</span>.</p>
<p>The probability model for <span class="math inline">\(X\)</span> in table form:
<span class="math display">\[
\begin{array}{c|c|c|c|c}
x    &amp;  2 &amp;  3 &amp;  4 &amp;  5 \\ \hline
p(x) &amp; .1 &amp; .2 &amp; .3 &amp; .4
\end{array}
\]</span></p>
<p>The probability model for <span class="math inline">\(Y\)</span> in table form:
<span class="math display">\[
\begin{array}{c|c|c|c|c|c|c|c}
y &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9\\ \hline
p(y) &amp; .1 &amp; .1 &amp; .2 &amp; .2 &amp; .2 &amp;.1 &amp; .1
\end{array}
\]</span>
Observe that in each case, we have a valid probability model. Each probability is non-negative, and <span class="math inline">\(\sum_x p(x) = 1\)</span> and <span class="math inline">\(\sum_y p(y) = 1\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:roll-until-4" class="example"><strong>Example 6.2  </strong></span>Let <span class="math inline">\(X\)</span> equal the number of rolls of a 6-sided die needed to roll your first 4.</p>
<blockquote>
<p>Find the space of <span class="math inline">\(X\)</span> and give a reasonable probability model for <span class="math inline">\(X\)</span>.</p>
</blockquote>
<p>The space of <span class="math inline">\(X\)</span> is <span class="math inline">\(\mathbb{N} = \{1, 2, 3, \ldots \}\)</span>.</p>
<p>We assume each of the 6 values is equally likely on any given roll, and that the values are independent from roll to roll. So, the probability of rolling a 4 is 1/6, and the probability of not rolling a 4 is 5/6. Then, the probability of rolling our first 4 on roll <span class="math inline">\(x\)</span>, for each <span class="math inline">\(x \geq 1\)</span>, is
<span class="math display">\[P(X = x) = \left(\frac{5}{6}\right)^{x-1}\cdot\frac{1}{6}.\]</span></p>
<p>Is this a valid probability model? Certainly each probability is non-negative. Do they all sum to 1? This requires the geometric series formula from Calc II to check:</p>
<p><span class="math display">\[\begin{align*}
\sum_{x = 1}^\infty \left(\frac{5}{6}\right)^{x-1}\frac{1}{6} &amp;= \frac{1}{6}\sum_{x = 0}^\infty \left(\frac{5}{6}\right)^{x} \\
&amp;= \frac{1}{6} \cdot \frac{1}{1-5/6} \\
&amp;= 1.
\end{align*}\]</span>
Yes!</p>
</div>
<div id="expected-value" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Expected Value<a href="discrete-random-variables-1.html#expected-value" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Recall, a random variable is a real-valued function defined over a sample space, usually denoted by <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span>, and <span class="math inline">\(X\)</span> is <strong>discrete</strong> if the space of <span class="math inline">\(X\)</span> is finite or countably infinite.</p>
<div class="definition">
<p><span id="def:expected-value-discrete" class="definition"><strong>Definition 6.1  </strong></span>If <span class="math inline">\(X\)</span> is a discrete random variable with probability function <span class="math inline">\(p(x)\)</span>, then the <strong>expected value of <span class="math inline">\(X\)</span></strong>, denoted <span class="math inline">\(E(X)\)</span>, is <span class="math display">\[E(X) = \sum_{\text{all }x} x \cdot p(x).\]</span> The expected value <span class="math inline">\(E(X)\)</span> is also called the <strong>mean of <span class="math inline">\(X\)</span></strong>, and is often denoted as <span class="math inline">\(\mu_X\)</span>, or <span class="math inline">\(\mu\)</span> if the random variable <span class="math inline">\(X\)</span> is understood.</p>
</div>
<div class="example">
<p><span id="exm:first-EV" class="example"><strong>Example 6.3  </strong></span>In example <a href="discrete-random-variables-1.html#exm:draw-2-balls">6.1</a> we defined two random variables associated to the experiment of drawing two balls (numbered from 1 to 5) out of a hat.</p>
<p>The expected value of <span class="math inline">\(X\)</span>, the larger value of the two drawn, is <span class="math display">\[E(X) = 2 \cdot 0.1 + 3 \cdot 0.2 + 4 \cdot 0.3 + \cdot 0.4 = 4.\]</span> So, we should expect that after a large number of repetitions of this game the average value of <span class="math inline">\(X\)</span> is about 4.</p>
<p>The expected value of <span class="math inline">\(Y\)</span>, the sum of the two values drawn, is <span class="math display">\[E(Y) = 3 \cdot .1 + 4 \cdot .1 + 5 \cdot .2 + 6 \cdot .2 + 7 \cdot .2 + 8 \cdot .1 + 9 \cdot .1 = 6.\]</span>. We should expect the average value of <span class="math inline">\(Y\)</span> to be about 6 after a large number of repetitions of this game.</p>
<p>In Example <a href="discrete-random-variables-1.html#exm:roll-until-4">6.2</a>, the expected number of rolls needed to obtain a 4 is an infinite series:
<span class="math display">\[E(X) = \sum_{x = 1}^\infty x \cdot (5/6)^{x-1} \cdot (1/6).\]</span>
which requires Calc II techniques to evaluate. We do this review in Section <a href="important-discrete-rv.html#geometric">7.2</a>, but will mention here that this infinite sum is 6. That is, the expected value for the number of rolls to get our first 4 turns out to be 6.</p>
</div>
<div class="example">
<p><span id="exm:chuckaluck" class="example"><strong>Example 6.4  (Chuck-a-luck) </strong></span>The game Chuck-a-luck works like this. Roll 3 dice after choosing a number (1-6). If your chosen number comes up once, you win $1. If it comes up twice, you win $2. If it comes up three times, you win $5. If it doesnâ€™t come up at all, you lose $1.</p>
<blockquote>
<p>Would you expect to win in the long run if you played this game lots of times?</p>
</blockquote>
<p>Letâ€™s frame Chuck-a-luck as follows:</p>
<ul>
<li>We have the chance experiment of rolling 3 dice. We assume the three dice are distinct colors (red, blue, green).</li>
<li>We have sample space <span class="math display">\[S = \{(r,b,g)~|~ 1 \leq r, b, g \leq 6 \}\]</span> (<span class="math inline">\(r\)</span> is the value of the red die, <span class="math inline">\(b\)</span> is the value of the blue die, and <span class="math inline">\(g\)</span> is the value of the green die).</li>
<li>The size of the sample space is <span class="math inline">\(|S| = 6^3 = 216\)</span>, and we assume each of these 216 outcomes is equally likely.</li>
<li>For the sake of argument, letâ€™s say that our chosen number is 4.</li>
<li>We define the random variable <span class="math inline">\(X\)</span> to be the number of 4s we roll.</li>
<li>The space of <span class="math inline">\(X\)</span> is <span class="math inline">\(\{0, 1, 2, 3\}\)</span>.</li>
</ul>
<p>Now letâ€™s find the probability model for <span class="math inline">\(X\)</span>, one value of <span class="math inline">\(x\)</span> at a time.</p>
<ul>
<li><span class="math inline">\(p(0)\)</span> is the probability that all 3 dice are not 4, which is <span class="math inline">\((5/6)^3 = 125/216.\)</span></li>
<li><span class="math inline">\(p(3)\)</span> is the probability that all 3 dice are 4, which is <span class="math inline">\((1/6)^3 = 1/216\)</span>.</li>
<li>For <span class="math inline">\(p(1)\)</span> we have three cases to consider (based on which die comes up 4):
<ul>
<li>Red die is 4, the others arenâ€™t. This probability is <span class="math inline">\((1/6) \cdot (5/6) \cdot (5/6).\)</span></li>
<li>Blue die is 4, the others arenâ€™t: <span class="math inline">\((5/6) \cdot (1/6) \cdot (5/6).\)</span></li>
<li>Green die is 4, the others arenâ€™t: <span class="math inline">\((5/6) \cdot (5/6) \cdot (1/6).\)</span>
So, <span class="math inline">\(p(1) = 3 \cdot (1/6)\cdot (5/6)^2 = 75/216\)</span></li>
</ul></li>
<li><span class="math inline">\(p(2)\)</span> is found by three cases as well, depending on which die is not 4. We find <span class="math inline">\(p(2) = 3 \cdot (1/6)^2\cdot (5/6) = 15/216.\)</span></li>
</ul>
<p>We can check that these four probabilities add to 1. Check! To summarize, <span class="math inline">\(X\)</span> has probability function given here in table form:</p>
<p><span class="math display">\[
\begin{array}{c|c|c|c|c}
x &amp; 0 &amp; 1 &amp; 2 &amp; 3 \\ \hline
p(x) &amp; 125/216 &amp; 75/216 &amp; 15/216 &amp; 1/216
\end{array}
\]</span></p>
<p>With the probability model in hand, we can compute the expected value of <span class="math inline">\(X\)</span>: <span class="math display">\[E(X) = 0 \cdot (125/216) + 1 \cdot (75/216) + 2 \cdot (15/216) + 3 \cdot (1/216) = 1/2.\]</span></p>
<p>We interpret this result as follows: In a large number of games played, we would expect, on average, 0.5 fours to come up per game played.</p>
<p>This expected value of <span class="math inline">\(X\)</span> doesnâ€™t actually answer the original question in this example. Should we expect to win <em>money</em> in the long run? Our calculation hasnâ€™t taken into account the dollar amounts attached to the various outcomes. These dollar amounts (1 if <span class="math inline">\(X = 1\)</span>, 2 if <span class="math inline">\(X = 2\)</span>, 5 if <span class="math inline">\(X = 3\)</span> and -1 if <span class="math inline">\(X = 0\)</span>), mathematically, describe a function of <span class="math inline">\(X\)</span> (input is a value from the space of <span class="math inline">\(X\)</span>, output is a dollar amount). To decide whether we should expect to win money in the long run, we want to calculate the expected value of <em>a function</em> of the random variable <span class="math inline">\(X\)</span>.</p>
<p>We can estimate our average expected winnings by playing the game repeatedly, we could play 100 times, or a 1000 times, and see how we do on average (hello R!). Or we can turn to the computation of the theoretical expected winnings per turn via the following theorem.</p>
</div>
<div class="theorem">
<p><span id="thm:EV-discrete-fcnRV" class="theorem"><strong>Theorem 6.1  </strong></span>Let <span class="math inline">\(X\)</span> be a discrete random variable with probability function <span class="math inline">\(p(x)\)</span>, and suppose <span class="math inline">\(g(X)\)</span> is a real-valued function of <span class="math inline">\(X\)</span>. Then the expected value of <span class="math inline">\(g(X)\)</span> is <span class="math display">\[E(g(X)) = \sum_{\text{all }x} g(x) \cdot p(x).\]</span></p>
</div>
<div class="example">
<p><span id="exm:Chuckaluck-winnings" class="example"><strong>Example 6.5  (Chuck-a-luck for a living?) </strong></span>Now we focus on our winnings, <span class="math inline">\(W\)</span>. <span class="math inline">\(W\)</span> is a function of <span class="math inline">\(X\)</span>, and we summarize this function by adding the winnings to the probability model table:</p>
<p><span class="math display">\[
\begin{array}{c|c|c|c|c}
x &amp; 0 &amp; 1 &amp; 2 &amp; 3 \\ \hline
p(x) &amp; 125/216 &amp; 75/216 &amp; 15/216 &amp; 1/216 \\ \hline
w &amp; -1 &amp; 1 &amp; 2 &amp; 5
\end{array}
\]</span>
Then, Theorem <a href="discrete-random-variables-1.html#thm:EV-discrete-fcnRV">6.1</a> says <span class="math display">\[E(W) = -1\cdot(125/216) + 1 \cdot (75/216) + 2 \cdot (15/216) + 5\cdot (1/216)\]</span> which evaluates to <span class="math inline">\(-15/216 \approx -.07\)</span>.</p>
<p>In the long run we should expect, on average, to lose 7 cents per game. So, yes, we should definitely play Chuck-a-luck, itâ€™s cheap entertainment! If you figure a game pace of 1 roll per minute, it will cost you about $4.20 per hour to play!!</p>
</div>
<p>As an aside, hereâ€™s code to simulate Chuck-a-luck in R a bunch of times (betting on 4), storing the results of each game, and then printing the table of the results followed by the average winnings of all the trials.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="discrete-random-variables-1.html#cb4-1" tabindex="-1"></a>chosen_number <span class="ot">=</span> <span class="dv">4</span></span>
<span id="cb4-2"><a href="discrete-random-variables-1.html#cb4-2" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>)<span class="co">#space of X</span></span>
<span id="cb4-3"><a href="discrete-random-variables-1.html#cb4-3" tabindex="-1"></a>W <span class="ot">=</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">5</span>)<span class="co">#winnings based on X</span></span>
<span id="cb4-4"><a href="discrete-random-variables-1.html#cb4-4" tabindex="-1"></a>trials <span class="ot">=</span> <span class="dv">2160</span></span>
<span id="cb4-5"><a href="discrete-random-variables-1.html#cb4-5" tabindex="-1"></a>results <span class="ot">=</span> <span class="fu">c</span>() <span class="co">#stores winnings each trial </span></span>
<span id="cb4-6"><a href="discrete-random-variables-1.html#cb4-6" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>trials){</span>
<span id="cb4-7"><a href="discrete-random-variables-1.html#cb4-7" tabindex="-1"></a>  rolls <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>,<span class="dv">3</span>,<span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb4-8"><a href="discrete-random-variables-1.html#cb4-8" tabindex="-1"></a>  x <span class="ot">=</span> <span class="fu">sum</span>(rolls <span class="sc">==</span> chosen_number)</span>
<span id="cb4-9"><a href="discrete-random-variables-1.html#cb4-9" tabindex="-1"></a>  w <span class="ot">=</span> W[<span class="fu">which</span>(X <span class="sc">==</span> x)]</span>
<span id="cb4-10"><a href="discrete-random-variables-1.html#cb4-10" tabindex="-1"></a>  results[i] <span class="ot">=</span> w</span>
<span id="cb4-11"><a href="discrete-random-variables-1.html#cb4-11" tabindex="-1"></a>}</span>
<span id="cb4-12"><a href="discrete-random-variables-1.html#cb4-12" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">table</span>(results))</span></code></pre></div>
<pre><code>## results
##   -1    1    2    5 
## 1277  741  136    6</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="discrete-random-variables-1.html#cb6-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">mean</span>(results))</span></code></pre></div>
<pre><code>## [1] -0.1083333</code></pre>
<div class="example">
<p><span id="exm:unlabeled-div-18" class="example"><strong>Example 6.6  </strong></span>Suppose <span class="math inline">\(X\)</span> has probability model</p>
<p><span class="math display">\[
\begin{array}{c|c|c|c|c|c|c}
x &amp; 0 &amp; 10 &amp; 20 &amp; 30 &amp; 40 &amp; 50\\ \hline
p(x) &amp; .1 &amp; .2 &amp; .1 &amp; .1 &amp; .4 &amp; .1  
\end{array}
\]</span>
Perhaps <span class="math inline">\(X\)</span> models my scores per roll in skee ball? In any event, letâ€™s compute <span class="math inline">\(E(3X^2 + 1)\)</span>:</p>
<p><span class="math display">\[\begin{align*}
E(3X^2 + 1) &amp;= \sum_{\text{all }x} (3x^2 + 1)\cdot p(x)\\
&amp;= 0 \cdot .1 + 301\cdot .2 + 1201\cdot .1 + 2701 \cdot .1 + 4801 \cdot .4 + 7501 \cdot .1\\
&amp;= 3120
\end{align*}\]</span></p>
</div>
</div>
<div id="variance" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Variance<a href="discrete-random-variables-1.html#variance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="definition">
<p><span id="def:variance-discrete" class="definition"><strong>Definition 6.2  </strong></span>If <span class="math inline">\(X\)</span> is a random variable with expected value <span class="math inline">\(E(X) = \mu\)</span>, the <strong>variance of <span class="math inline">\(X\)</span></strong>, denoted <span class="math inline">\(V(X)\)</span>, is <span class="math display">\[V(X) = E((X-\mu)^2).\]</span>
The variance of <span class="math inline">\(X\)</span> is often denoted <span class="math inline">\(\sigma^2_X\)</span>, or <span class="math inline">\(\sigma^2\)</span> if the random variable is understood. Also, <span class="math inline">\(\sqrt{V(X)}\)</span>, denoted <span class="math inline">\(\sigma_X\)</span> or <span class="math inline">\(\sigma\)</span>, is called the <strong>standard deviation of <span class="math inline">\(X\)</span></strong>.</p>
</div>
<div class="example">
<p><span id="exm:variance-comparison" class="example"><strong>Example 6.7  </strong></span>Suppose <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> have the following random probability models.</p>
<p><span class="math display">\[
\begin{array}{c|c|c|c|c|c}
x &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 \\ \hline
p(x) &amp; .2 &amp; .3 &amp; .3 &amp; .1 &amp; .1
\end{array}
\]</span></p>
<p><span class="math display">\[
\begin{array}{c|c|c|c|c|c}
y &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4\\ \hline
p(y) &amp; .6 &amp; 0 &amp; 0 &amp; 0 &amp; .4
\end{array}
\]</span></p>
<blockquote>
<p>Compute the expected value and variance for each random variable.</p>
</blockquote>
<p>The expected value of <span class="math inline">\(X\)</span> is <span class="math display">\[E(X) = 0 + (1)(.3) + (2)(.3) + (3)(.1) + (4)(.1) = 1.6,\]</span> and the expected value of <span class="math inline">\(Y\)</span> is <span class="math display">\[E(Y) = 0 + (4)(.4) = 1.6,\]</span>
so the two random variables have the same mean: <span class="math inline">\(E(X) = E(Y)\)</span>, or, using the alternate notation, <span class="math inline">\(\mu_X = \mu_Y\)</span>.</p>
<p>The variance of <span class="math inline">\(X\)</span>: <span class="math display">\[V(X) = E((X-\mu_X)^2) = \sum_{x = 0}^4[(x-1.6)^2\cdot p(x)]= 1.44.\]</span></p>
<p>The variance of <span class="math inline">\(Y\)</span> is larger:</p>
<p><span class="math display">\[V(Y) = E((Y-\mu_Y)^2) = \sum_{y = 0}^4[(y-1.6)^2\cdot p(y)]= 3.84.\]</span></p>
<p>The variance of a random variable increases as more of the distribution lies further from <span class="math inline">\(\mu\)</span>. In this example, more of the probability distribution for <span class="math inline">\(Y\)</span> lies farther away from 1.6, than the distribution of <span class="math inline">\(X\)</span> does away from its mean (also 1.6).</p>
<p><img src="math340-notes_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
</div>
<div class="example">
<p><span id="exm:infinite-variance" class="example"><strong>Example 6.8  (Infinite Variance?) </strong></span>There exist discrete random variables with finite mean and infinite variance. Hereâ€™s one: Recall that the <span class="math inline">\(p\)</span>-series <span class="math display">\[\sum_{n=1}^\infty \frac{1}{n^p}\]</span> converges for <span class="math inline">\(p &gt; 1\)</span>, and diverges when <span class="math inline">\(p = 1\)</span>. Letâ€™s suppose the series <span class="math display">\[\sum_{n=1}^\infty \frac{1}{n^3} = c.\]</span>
(In fact, <span class="math inline">\(c\)</span> equals a known constant close to 1.2, called Aperyâ€™s constant after the mathematician who proved this constant is irrational.) Consider the discrete random variable <span class="math inline">\(X\)</span> whose distribution function is given by <span class="math display">\[p(x) = \frac{1}{cx^3} ~\text{ for }~ x = 1, 2, 3, \ldots.\]</span>
Then,
<span class="math display">\[\begin{align*}
E(X) &amp;= \sum_{x=1}^\infty x \cdot \frac{1}{cx^3}\\
    &amp;= \frac{1}{c} \sum{x=1}^\infty \frac{1}{x^2} \\
    &amp;= \frac{\pi^2}{6c},
\end{align*}\]</span>
since the <span class="math inline">\(p\)</span>-series <span class="math inline">\(\sum_{n=1}^\infty (1/n^2) = \pi^2/6.\)</span> So, <span class="math inline">\(E(X)\)</span> exists as a finite number.</p>
<p>However,
<span class="math display">\[\begin{align*}
E(X^2) &amp;= \sum_{x=1}^\infty x^2 \cdot \frac{1}{cx^3}\\
    &amp;= \frac{1}{c} \sum{x=1}^\infty \frac{1}{x},
\end{align*}\]</span>
which diverges as a multiple of the harmonic series. So, <span class="math inline">\(V(X)\)</span> does not exist as a finite number.</p>
</div>
</div>
<div id="properties-of-expected-value" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Properties of Expected Value<a href="discrete-random-variables-1.html#properties-of-expected-value" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="theorem">
<p><span id="thm:EV-properties-discrete" class="theorem"><strong>Theorem 6.2  </strong></span>Suppose <span class="math inline">\(X\)</span> is a discrete random variable, <span class="math inline">\(c \in \mathbb{R}\)</span> is a constant, and <span class="math inline">\(g\)</span>, <span class="math inline">\(g_1\)</span>, and <span class="math inline">\(g_2\)</span> are functions of <span class="math inline">\(X\)</span>.</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(E(c) = c\)</span>.</li>
<li><span class="math inline">\(E(c\cdot g(X))= cE(g(X))\)</span>.</li>
<li><span class="math inline">\(E(g_1(X) \pm g_2(X)) = E(g_1(X)\pm g_2(X))\)</span>.</li>
</ol>
</div>
<p>These properties can help us evaluate expected values without having to sum over all <span class="math inline">\(x\)</span>.</p>
<p>For instance, suppose we know <span class="math inline">\(X\)</span> is a discrete random variable with expected value <span class="math inline">\(E(X) = 1.6\)</span>.</p>
<p>Then</p>
<p><span class="math display">\[\begin{align*}
E(4+3X) &amp;= E(4) + E(3X) &amp;\text{ by property 3} \\
        &amp;= 4 + 3E(X) &amp;\text{ by properties 1 and 2}\\
        &amp;= 4 + 3 \cdot 1.6 &amp;\text { since }E(X) = 1.6 \\
        &amp;= 8.8. &amp;\text{ Nice.}
\end{align*}\]</span></p>
<p>Letâ€™s take the time to prove these properties. Each of them essentially follows by properties of summations.</p>
<div class="proof">
<p><span id="unlabeled-div-19" class="proof"><em>Proof</em>. </span></p>
<ol style="list-style-type: decimal">
<li>Given a constant <span class="math inline">\(c\)</span>, we can view this constant as a function of <span class="math inline">\(X\)</span>, say <span class="math inline">\(f(x) = c\)</span>. Then
<span class="math display">\[\begin{align*}
E(c) &amp;= \sum_{\text{all }x} c \cdot p(x) \\
&amp;= c \sum_{\text{all }x} p(x)
\end{align*}\]</span></li>
</ol>
<p>Since the sum over all <span class="math inline">\(x\)</span> of <span class="math inline">\(p(x)\)</span> is 1 for any probability model, the result follows.</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Here appeal to Theorem <a href="discrete-random-variables-1.html#thm:EV-discrete-fcnRV">6.1</a>} and arithmetic:
<span class="math display">\[\begin{align*}
E(c\cdot g(X)) &amp;= \sum_{\text{all }x} c \cdot g(x) \cdot p(x) &amp; \\
&amp;= c \sum_{\text{all }x} g(x) p(x) &amp;\text{by arithmetic}\\
&amp;= c E(g(X)) &amp;
\end{align*}\]</span></p></li>
<li><p>Here we also appeal to Theorem <a href="discrete-random-variables-1.html#thm:EV-discrete-fcnRV">6.1</a>} and arithmetic:
<span class="math display">\[\begin{align*}
E(g_1(x) \pm g_2(x)) &amp;= \sum_{\text{all }x} (g_1(x) \pm g_2(x))\cdot p(x) &amp;\\
&amp;= \sum_{\text{all }x} (g_1(x) p(x) \pm g_2(x) p(x)) &amp;\text{by arithmetic}\\
&amp;= \sum_{\text{all }x} g_1(x) p(x) \pm \sum_{\text{all }x} g_2(x) p(x)  &amp;\text{by arithmetic}\\
&amp;= E(g_1(X)) \pm E(g_2(X)) &amp;
\end{align*}\]</span></p></li>
</ol>
</div>
<div class="example">
<p><span id="exm:homes-near-firehouse" class="example"><strong>Example 6.9  </strong></span>The number <span class="math inline">\(N\)</span> of residential homes that a fire company can serve depends on the distance <span class="math inline">\(r\)</span> (in city blocks) that a fire engine can cover in a fixed period of time. If we assume that <span class="math inline">\(N\)</span> is proportional to the area of a circle <span class="math inline">\(R\)</span> blocks from the fire house, then <span class="math display">\[N = k \pi R^2,\]</span> where <span class="math inline">\(k\)</span> is a constant, and <span class="math inline">\(R\)</span> is a random variable. For a particular fire company, <span class="math inline">\(k = 8\)</span>, and the probability function for <span class="math inline">\(R\)</span> is
<span class="math display">\[
\begin{array}{c|c|c|c|c|c|c|c}
r    &amp;  21 &amp;  22 &amp;  23 &amp;  24 &amp; 25 &amp; 26 \\ \hline
p(r) &amp; .05 &amp; .20 &amp; .30 &amp; .25 &amp; .15 &amp; .05
\end{array}
\]</span>
Find <span class="math inline">\(E(N)\)</span>, the expected number of homes that the fire department can serve.</p>
<p>Well, <span class="math display">\[E(N) = E(8\pi R^2) = 8\pi E(R^2),\]</span>
so
<span class="math display">\[\begin{align*}
E(N) &amp;= 8\pi\left(21^2\cdot .05 + 22^2 \cdot .20 + 23^2 \cdot .30 + 24^2 \cdot .25 + 25^2 \cdot .15 + 26^2 \cdot .05\right) \\
&amp;= 8\pi(549.1) \\
&amp;\approx 13,800 \text{ homes}
\end{align*}\]</span></p>
</div>
<div class="theorem">
<p><span id="thm:variance-shortcut" class="theorem"><strong>Theorem 6.3  (Useful Variance Formula) </strong></span>Let <span class="math inline">\(X\)</span> be a discrete random variable with probability function <span class="math inline">\(p(x)\)</span> and expected value <span class="math inline">\(E(X) = \mu\)</span>. Then <span class="math display">\[V(X) = E(X^2)-\mu^2.\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-20" class="proof"><em>Proof</em>. </span>By definition,
<span class="math display">\[\begin{align*}
V(X) &amp;= E((X-\mu)^2)\\
     &amp;= E(X^2 - 2\mu X + \mu^2) &amp;\text{by expanding}\\
     &amp;= E(X^2) - E(2\mu X) + E(\mu^2) &amp;\text{by E() Property 3} \\
     &amp;= E(X^2) - 2\mu E(X) + \mu^2 &amp;\text{by E() Properties 2 and 1}\\
     &amp;= E(X^2) - 2\mu^2 + \mu^2 &amp; \text{since }E(X)=\mu \\
V(X) &amp;= E(X^2) - \mu^2
\end{align*}\]</span></p>
</div>
<p>This alternate formula for variance also provides us with a way to compute <span class="math inline">\(E(X^2)\)</span> from the expected value and variance of a random variable: <span class="math display">\[E(X^2) = V(X) + \mu^2,\]</span> or using the alternate variance notation:
<span class="math display">\[E(X^2) = \sigma^2 + \mu^2.\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-21" class="example"><strong>Example 6.10  </strong></span>Suppose <span class="math inline">\(X\)</span> is a discrete random variable with expected value <span class="math inline">\(\mu = 5\)</span> and variance <span class="math inline">\(\sigma^2 = 6\)</span>.
Find <span class="math inline">\(E(3+2X+4X^2)\)</span>.</p>
<p>Well, <span class="math display">\[\begin{align*}
E(3 + 2X + 4X^2) &amp;= E(3) + 2E(X) + 4E(X^2) \\
                 &amp;= 3 + 2\cdot \mu + 4[\sigma^2+\mu^2] \\
                 &amp;= 3 + 2 \cdot 5 + 4[6 + 5^2] \\
                 &amp;= 3 + 10 + 124 \\
                 &amp;= 137.
\end{align*}\]</span></p>
</div>
</div>
<div id="tchebysheffs-theorem" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Tchebysheffâ€™s Theorem<a href="discrete-random-variables-1.html#tchebysheffs-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="theorem">
<p><span id="thm:tcheby" class="theorem"><strong>Theorem 6.4  (Tchebysheff's Inequality) </strong></span>Let <span class="math inline">\(X\)</span> be a random variable with mean <span class="math inline">\(E(X) = \mu\)</span> and finite variance <span class="math inline">\(V(X) = \sigma^2 &gt; 0\)</span>. Then for any constant <span class="math inline">\(k &gt; 0\)</span>,
<span class="math display">\[P(|X - \mu| &lt; k\sigma ) \geq 1 - \frac{1}{k^2}.\]</span>
Equivalently, <span class="math display">\[P(|X - \mu| \geq k\sigma) \leq \frac{1}{k^2}.\]</span></p>
</div>
<p>For instance, if <span class="math inline">\(k = 2\)</span>, Tchebbysheffâ€™s inequality says that for any random variable <span class="math inline">\(X\)</span>, the probability that <span class="math inline">\(X\)</span> takes a value that is within 2 standard deviations of the mean is at least .75. For many distributions, this proability is closer to .95, but .75 holds for <em>all</em> distributions.
Of course, letting <span class="math inline">\(k = 1\)</span> in Tchebbysheffâ€™s inequality gives us the trivially true statement that the probability that <span class="math inline">\(X\)</span> takes a value within 1 standard deviation of the mean is at least 0.</p>
<div class="proof">
<p><span id="unlabeled-div-22" class="proof"><em>Proof</em>. </span>We prove Tchebbysheffâ€™s inequality in the case for a discrete random variable, and we come back to this theorem after defining continuous random variables.</p>
<p>Let <span class="math inline">\(k &gt; 0\)</span> be given.</p>
<p>Then <span class="math display">\[V(X) = \sum_{\text{all }x} (x - \mu)^2 p(x),\]</span> by the definition of variance. We can partition the space of <span class="math inline">\(X\)</span> into three disjoint sets, depending on the location of <span class="math inline">\(x\)</span> relative to <span class="math inline">\(\mu \pm k\sigma\)</span>:</p>
<p><span class="math display">\[V(X) = \sum_{\text{all } x \leq \mu - k\sigma} (x - \mu)^2 p(x) +
\sum_{\text{all } x \text{ s.t. } |x-\mu|&lt; k\sigma } (x - \mu)^2 p(x) + \sum_{\text{all } x \geq \mu + k\sigma} (x - \mu)^2 p(x)\]</span></p>
<p>Each of these three sums is non-negative, and for the first and third sums we can also say that <span class="math inline">\((x-\mu)^2 \geq k^2\sigma^2\)</span> for all <span class="math inline">\(x\)</span> in the given range, so it follows that <span class="math display">\[V(x) \geq \sum_{\text{all } x \leq \mu - k\sigma} k^2\sigma^2 p(x) + 0 + \sum_{\text{all } x \geq \mu + k\sigma} k^2\sigma^2 p(x).\]</span>
So,</p>
<p><span class="math display">\[\begin{align*}
\sigma^2 &amp;\geq \sum_{\text{all } x \leq \mu - k\sigma} k^2\sigma^2 p(x) + 0 + \sum_{\text{all } x \geq \mu + k\sigma} k^2\sigma^2 p(x)  \\
  &amp;= k^2\sigma^2 \left(\sum_{\text{all } x \leq \mu - k\sigma} p(x) + \sum_{\text{all } x \geq \mu + k\sigma} p(x) \right) \\
  &amp;= k^2\sigma^2\left(P(X\leq \mu-k\sigma)+P(X \geq \mu+k\sigma)\right) \\
  &amp;= k^2\sigma^2P(|X-\mu|\geq k\sigma)
\end{align*}\]</span></p>
<p>Dividing both sides of the inequality by the positive value <span class="math inline">\(k^2\sigma^2\)</span> gives us the result:
<span class="math display">\[P(|X-\mu| \geq k\sigma) \leq \frac{1}{k^2}.\]</span></p>
</div>
<div class="example">
<p><span id="exm:tchebby" class="example"><strong>Example 6.11  </strong></span>Suppose <span class="math inline">\(X\)</span> is a random variable with <span class="math inline">\(E(X) = 70\)</span> and <span class="math inline">\(V(X) = 25\)</span>, so <span class="math inline">\(\mu = 70\)</span> and <span class="math inline">\(\sigma = \sqrt{25} = 5\)</span>.
According to Tchebbysheffâ€™s inequality with <span class="math inline">\(k = 2\)</span>, the probability that <span class="math inline">\(X\)</span> takes a value between 60 and 80 is at least 3/4. Setting <span class="math inline">\(k = 3\)</span>, we find the probability that <span class="math inline">\(X\)</span> takes a value between 55 and 85 is at least 8/9.</p>
</div>
<p>Again, for many distributions, the probability of being within 2 standard deviations of the mean is much higher than .75 (often about .95, in fact), and the probability of being within 3 standard deviations of the mean is much higher than 8/9 (often about .99).</p>
<p>Hereâ€™s a distribution, however, that shows the bound in Tchebbysheffâ€™s inequality cannot be improved.</p>
<div class="example">
<p><span id="exm:tchebby-best-bound" class="example"><strong>Example 6.12  </strong></span>We show that there exists a probability distribution for which <span class="math inline">\(P(|X-\mu|&lt;2\sigma) = .75\)</span>.</p>
<p>Consider the discrete random variable <span class="math inline">\(X\)</span> whose probability distribution function is</p>
<p><span class="math display">\[
\begin{array}{c|c|c|c}
x   &amp;  -1 &amp;  0 &amp;  1   \\ \hline
p(x) &amp; .125 &amp; .75 &amp; .125
\end{array}
\]</span>
Then <span class="math display">\[\mu = E(X) = (-1)(.125) + (0)(.75) + (1)(.125) = 0,\]</span> and</p>
<p><span class="math display">\[\begin{align*}
\sigma^2 &amp;= E(X^2)-\mu^2 \\
  &amp;= (-1)^2(.125) + 0^2(.75) + 1^2(.125)\\
  &amp;=.25,
\end{align*}\]</span>
So, <span class="math inline">\(\sigma = 0.5\)</span>, and
<span class="math display">\[\begin{align*}
P(|X - \mu| &lt; 2 \sigma) &amp;= P(|X| &lt; 1) \\
&amp;= P(-1 &lt; X &lt; 1) \\
&amp;= P(X = 0) &amp; \text{ since the space of $X$ is } \{-1,0,1\} \\
&amp;= .75.
\end{align*}\]</span></p>
<p>Thus, there exists a discrete random variable for which <span class="math inline">\(P(|X - \mu| &lt; 2 \sigma) = .75\)</span>. In fact, for any <span class="math inline">\(k &gt; 0\)</span> the probability distribution given by
<span class="math display">\[
\begin{array}{c|c|c|c}
x   &amp;  -1 &amp;  0 &amp;  1   \\ \hline
p(x) &amp; \frac{1}{2k^2} &amp; 1-\frac{1}{k^2} &amp; \frac{1}{2k^2}
\end{array}
\]</span>
will satisfy <span class="math inline">\(P(|X-\mu|&lt;2\sigma)=1-\frac{1}{k^2}\)</span>, demonstrating that the bound in Tchebbyshefâ€™s inequality can not be increased.</p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probability-theory.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="important-discrete-rv.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["math340-notes.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
