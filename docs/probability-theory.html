<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Probability Theory | MATH 340 Notes</title>
  <meta name="description" content="5 Probability Theory | MATH 340 Notes" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Probability Theory | MATH 340 Notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Probability Theory | MATH 340 Notes" />
  
  
  

<meta name="author" content="Mike Hitchman" />


<meta name="date" content="2024-07-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="counting.html"/>
<link rel="next" href="discrete-random-variables-1.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://github.com/mphitchman/math340.git" target="blank">Math 340 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="sets.html"><a href="sets.html"><i class="fa fa-check"></i><b>2</b> Sets</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sets.html"><a href="sets.html#algebra-of-sets"><i class="fa fa-check"></i><b>2.1</b> Algebra of Sets</a></li>
<li class="chapter" data-level="2.2" data-path="sets.html"><a href="sets.html#size-of-sets"><i class="fa fa-check"></i><b>2.2</b> Set sizes</a></li>
<li class="chapter" data-level="2.3" data-path="sets.html"><a href="sets.html#sets-in-r"><i class="fa fa-check"></i><b>2.3</b> Sets in R</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html"><i class="fa fa-check"></i><b>3</b> Discrete Probability Distributions</a>
<ul>
<li class="chapter" data-level="3.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#sample-space"><i class="fa fa-check"></i><b>3.1</b> Sample Space</a></li>
<li class="chapter" data-level="3.2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#discrete-random-variables"><i class="fa fa-check"></i><b>3.2</b> Discrete Random Variables</a></li>
<li class="chapter" data-level="3.3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#calculating-probabilities"><i class="fa fa-check"></i><b>3.3</b> Calculating Probabilities</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#sample-point-method"><i class="fa fa-check"></i><b>3.3.1</b> Sample Point Method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="counting.html"><a href="counting.html"><i class="fa fa-check"></i><b>4</b> Counting Techniques</a>
<ul>
<li class="chapter" data-level="4.1" data-path="counting.html"><a href="counting.html#multipiclation-principle"><i class="fa fa-check"></i><b>4.1</b> Multipiclation Principle</a></li>
<li class="chapter" data-level="4.2" data-path="counting.html"><a href="counting.html#permutations"><i class="fa fa-check"></i><b>4.2</b> Permutations</a></li>
<li class="chapter" data-level="4.3" data-path="counting.html"><a href="counting.html#combinations"><i class="fa fa-check"></i><b>4.3</b> Combinations</a></li>
<li class="chapter" data-level="4.4" data-path="counting.html"><a href="counting.html#multinomial-coefficients"><i class="fa fa-check"></i><b>4.4</b> Multinomial Coefficients</a></li>
<li class="chapter" data-level="4.5" data-path="counting.html"><a href="counting.html#balls-and-bins"><i class="fa fa-check"></i><b>4.5</b> Balls and Bins</a></li>
<li class="chapter" data-level="4.6" data-path="counting.html"><a href="counting.html#prob-with-counting-tools"><i class="fa fa-check"></i><b>4.6</b> Calculating More Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>5</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="5.1" data-path="probability-theory.html"><a href="probability-theory.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>5.1</b> Conditional Probability and Independence</a></li>
<li class="chapter" data-level="5.2" data-path="probability-theory.html"><a href="probability-theory.html#two-laws-of-probability"><i class="fa fa-check"></i><b>5.2</b> Two Laws of Probability</a></li>
<li class="chapter" data-level="5.3" data-path="probability-theory.html"><a href="probability-theory.html#event-composition-method"><i class="fa fa-check"></i><b>5.3</b> Event-Composition Method</a></li>
<li class="chapter" data-level="5.4" data-path="probability-theory.html"><a href="probability-theory.html#bayes-rule"><i class="fa fa-check"></i><b>5.4</b> Bayes’ Rule</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="discrete-random-variables-1.html"><a href="discrete-random-variables-1.html"><i class="fa fa-check"></i><b>6</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="discrete-random-variables-1.html"><a href="discrete-random-variables-1.html#expected-value"><i class="fa fa-check"></i><b>6.1</b> Expected Value</a></li>
<li class="chapter" data-level="6.2" data-path="discrete-random-variables-1.html"><a href="discrete-random-variables-1.html#variance"><i class="fa fa-check"></i><b>6.2</b> Variance</a></li>
<li class="chapter" data-level="6.3" data-path="discrete-random-variables-1.html"><a href="discrete-random-variables-1.html#properties-of-expected-value"><i class="fa fa-check"></i><b>6.3</b> Properties of Expected Value</a></li>
<li class="chapter" data-level="6.4" data-path="discrete-random-variables-1.html"><a href="discrete-random-variables-1.html#tchebysheffs-theorem"><i class="fa fa-check"></i><b>6.4</b> Tchebysheff’s Theorem</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html"><i class="fa fa-check"></i><b>7</b> Important Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="7.1" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#binomial"><i class="fa fa-check"></i><b>7.1</b> Binomial Distributions</a></li>
<li class="chapter" data-level="7.2" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#geometric"><i class="fa fa-check"></i><b>7.2</b> Geometric Distributions</a></li>
<li class="chapter" data-level="7.3" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#negative-binomial"><i class="fa fa-check"></i><b>7.3</b> Negative Binomial Distribution</a></li>
<li class="chapter" data-level="7.4" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#hypergometric"><i class="fa fa-check"></i><b>7.4</b> Hypergeometric Distribution</a></li>
<li class="chapter" data-level="7.5" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#poisson"><i class="fa fa-check"></i><b>7.5</b> Poisson Distribution</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="important-discrete-rv.html"><a href="important-discrete-rv.html#poisson-process"><i class="fa fa-check"></i><b>7.5.1</b> Poisson Process</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="moments-and-moment-generating-functions.html"><a href="moments-and-moment-generating-functions.html"><i class="fa fa-check"></i><b>8</b> Moments and Moment-Generating Functions</a></li>
<li class="chapter" data-level="9" data-path="continuous-rv.html"><a href="continuous-rv.html"><i class="fa fa-check"></i><b>9</b> Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="9.1" data-path="continuous-rv.html"><a href="continuous-rv.html#distribution-functions"><i class="fa fa-check"></i><b>9.1</b> Distribution Functions</a></li>
<li class="chapter" data-level="9.2" data-path="continuous-rv.html"><a href="continuous-rv.html#expected-value-for-continuous-random-variables"><i class="fa fa-check"></i><b>9.2</b> Expected Value for Continuous Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html"><i class="fa fa-check"></i><b>10</b> Important Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="10.1" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#uniform-continuous"><i class="fa fa-check"></i><b>10.1</b> Uniform Distribution</a></li>
<li class="chapter" data-level="10.2" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#exponential-distribution"><i class="fa fa-check"></i><b>10.2</b> Exponential Distribution</a></li>
<li class="chapter" data-level="10.3" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#normal"><i class="fa fa-check"></i><b>10.3</b> Normal Distribution</a></li>
<li class="chapter" data-level="10.4" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#gamma-distribution"><i class="fa fa-check"></i><b>10.4</b> Gamma Distribution</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#exponential-distribution-1"><i class="fa fa-check"></i><b>10.4.1</b> Exponential Distribution</a></li>
<li class="chapter" data-level="10.4.2" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#chi-square-distribution"><i class="fa fa-check"></i><b>10.4.2</b> Chi-square distribution</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="important-continuous-rv.html"><a href="important-continuous-rv.html#beta-distribution"><i class="fa fa-check"></i><b>10.5</b> Beta Distribution</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="mgf.html"><a href="mgf.html"><i class="fa fa-check"></i><b>11</b> Moment Generating Functions</a></li>
<li class="chapter" data-level="12" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>12</b> Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="12.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#sums-of-random-variables"><i class="fa fa-check"></i><b>12.1</b> Sums of Random Variables</a></li>
<li class="chapter" data-level="12.2" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#t-distribution"><i class="fa fa-check"></i><b>12.2</b> T distribution</a></li>
<li class="chapter" data-level="12.3" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>12.3</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="12.4" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#normal-approximation-to-a-binomial-distribution"><i class="fa fa-check"></i><b>12.4</b> Normal Approximation to a binomial distribution</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>13</b> Estimation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="estimation.html"><a href="estimation.html#unbiased-estimators"><i class="fa fa-check"></i><b>13.1</b> Unbiased Estimators</a></li>
<li class="chapter" data-level="13.2" data-path="estimation.html"><a href="estimation.html#order-statistics"><i class="fa fa-check"></i><b>13.2</b> Order Statistics</a></li>
<li class="chapter" data-level="13.3" data-path="estimation.html"><a href="estimation.html#common-unbiased-estimators"><i class="fa fa-check"></i><b>13.3</b> Common Unbiased Estimators</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="estimation.html"><a href="estimation.html#estimating-mu-a-population-mean"><i class="fa fa-check"></i><b>13.3.1</b> Estimating <span class="math inline">\(\mu\)</span>, a population mean</a></li>
<li class="chapter" data-level="13.3.2" data-path="estimation.html"><a href="estimation.html#estimating-p-a-population-proportion"><i class="fa fa-check"></i><b>13.3.2</b> Estimating <span class="math inline">\(p\)</span>, a population proportion</a></li>
<li class="chapter" data-level="13.3.3" data-path="estimation.html"><a href="estimation.html#estimating-mu_1---mu_2-the-difference-of-two-population-means"><i class="fa fa-check"></i><b>13.3.3</b> Estimating <span class="math inline">\(\mu_1 - \mu_2\)</span>, the difference of two population means</a></li>
<li class="chapter" data-level="13.3.4" data-path="estimation.html"><a href="estimation.html#estimating-p_1---p_2-the-difference-of-two-population-proportions"><i class="fa fa-check"></i><b>13.3.4</b> Estimating <span class="math inline">\(p_1 - p_2\)</span>, the difference of two population proportions</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Using R</b></span></li>
<li class="chapter" data-level="A" data-path="sampling-in-r.html"><a href="sampling-in-r.html"><i class="fa fa-check"></i><b>A</b> Sampling in R</a>
<ul>
<li class="chapter" data-level="A.1" data-path="sampling-in-r.html"><a href="sampling-in-r.html#vectors-R"><i class="fa fa-check"></i><b>A.1</b> Data vectors</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="sampling-in-r.html"><a href="sampling-in-r.html#vector-types"><i class="fa fa-check"></i><b>A.1.1</b> vector types</a></li>
<li class="chapter" data-level="A.1.2" data-path="sampling-in-r.html"><a href="sampling-in-r.html#matrices"><i class="fa fa-check"></i><b>A.1.2</b> Matrices</a></li>
<li class="chapter" data-level="A.1.3" data-path="sampling-in-r.html"><a href="sampling-in-r.html#data-frames"><i class="fa fa-check"></i><b>A.1.3</b> data frames</a></li>
<li class="chapter" data-level="A.1.4" data-path="sampling-in-r.html"><a href="sampling-in-r.html#common-vector-commands"><i class="fa fa-check"></i><b>A.1.4</b> common vector commands</a></li>
<li class="chapter" data-level="A.1.5" data-path="sampling-in-r.html"><a href="sampling-in-r.html#comparison-operators"><i class="fa fa-check"></i><b>A.1.5</b> Comparison Operators</a></li>
<li class="chapter" data-level="A.1.6" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sum-and-which"><i class="fa fa-check"></i><b>A.1.6</b> <code>sum()</code> and <code>which()</code></a></li>
<li class="chapter" data-level="A.1.7" data-path="sampling-in-r.html"><a href="sampling-in-r.html#extracting-elements"><i class="fa fa-check"></i><b>A.1.7</b> extracting elements</a></li>
<li class="chapter" data-level="A.1.8" data-path="sampling-in-r.html"><a href="sampling-in-r.html#comparing-vectors"><i class="fa fa-check"></i><b>A.1.8</b> comparing vectors</a></li>
<li class="chapter" data-level="A.1.9" data-path="sampling-in-r.html"><a href="sampling-in-r.html#vector-arithmetic"><i class="fa fa-check"></i><b>A.1.9</b> vector arithmetic</a></li>
<li class="chapter" data-level="A.1.10" data-path="sampling-in-r.html"><a href="sampling-in-r.html#concatenate-vectors"><i class="fa fa-check"></i><b>A.1.10</b> concatenate vectors</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="sampling-in-r.html"><a href="sampling-in-r.html#special-vectors"><i class="fa fa-check"></i><b>A.2</b> Special vectors</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="sampling-in-r.html"><a href="sampling-in-r.html#consecutive-integers"><i class="fa fa-check"></i><b>A.2.1</b> consecutive integers</a></li>
<li class="chapter" data-level="A.2.2" data-path="sampling-in-r.html"><a href="sampling-in-r.html#letters"><i class="fa fa-check"></i><b>A.2.2</b> letters</a></li>
<li class="chapter" data-level="A.2.3" data-path="sampling-in-r.html"><a href="sampling-in-r.html#rep"><i class="fa fa-check"></i><b>A.2.3</b> <code>rep()</code></a></li>
<li class="chapter" data-level="A.2.4" data-path="sampling-in-r.html"><a href="sampling-in-r.html#table"><i class="fa fa-check"></i><b>A.2.4</b> <code>table()</code></a></li>
<li class="chapter" data-level="A.2.5" data-path="sampling-in-r.html"><a href="sampling-in-r.html#seq"><i class="fa fa-check"></i><b>A.2.5</b> <code>seq()</code></a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sampling-in-R"><i class="fa fa-check"></i><b>A.3</b> Sampling</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sample-options"><i class="fa fa-check"></i><b>A.3.1</b> <code>sample()</code> options</a></li>
<li class="chapter" data-level="A.3.2" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sample-without-replacement"><i class="fa fa-check"></i><b>A.3.2</b> Sample without replacement</a></li>
<li class="chapter" data-level="A.3.3" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sample-with-replacement"><i class="fa fa-check"></i><b>A.3.3</b> Sample with replacement</a></li>
<li class="chapter" data-level="A.3.4" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sample-with-custom-probabilities"><i class="fa fa-check"></i><b>A.3.4</b> Sample with custom probabilities</a></li>
<li class="chapter" data-level="A.3.5" data-path="sampling-in-r.html"><a href="sampling-in-r.html#example-lefties"><i class="fa fa-check"></i><b>A.3.5</b> Example: Lefties</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="sampling-in-r.html"><a href="sampling-in-r.html#repeated-sampling"><i class="fa fa-check"></i><b>A.4</b> Repeated Sampling</a>
<ul>
<li class="chapter" data-level="A.4.1" data-path="sampling-in-r.html"><a href="sampling-in-r.html#using-a-for-loop"><i class="fa fa-check"></i><b>A.4.1</b> using a <code>for</code> loop</a></li>
<li class="chapter" data-level="A.4.2" data-path="sampling-in-r.html"><a href="sampling-in-r.html#using-replicate"><i class="fa fa-check"></i><b>A.4.2</b> using <code>replicate()</code></a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sampling-commands"><i class="fa fa-check"></i><b>A.5</b> Summary of R commands</a>
<ul>
<li class="chapter" data-level="A.5.1" data-path="sampling-in-r.html"><a href="sampling-in-r.html#defining-vectors"><i class="fa fa-check"></i><b>A.5.1</b> defining vectors</a></li>
<li class="chapter" data-level="A.5.2" data-path="sampling-in-r.html"><a href="sampling-in-r.html#summarizing-vectors"><i class="fa fa-check"></i><b>A.5.2</b> summarizing vectors</a></li>
<li class="chapter" data-level="A.5.3" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sampling-from-vectors"><i class="fa fa-check"></i><b>A.5.3</b> sampling from vectors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="R-sim-probability.html"><a href="R-sim-probability.html"><i class="fa fa-check"></i><b>B</b> Simulating Probability in R</a>
<ul>
<li class="chapter" data-level="B.1" data-path="R-sim-probability.html"><a href="R-sim-probability.html#id_10sided-die-R"><i class="fa fa-check"></i><b>B.1</b> Rolling a 10-sided die</a>
<ul>
<li class="chapter" data-level="B.1.1" data-path="R-sim-probability.html"><a href="R-sim-probability.html#final-code"><i class="fa fa-check"></i><b>B.1.1</b> Final Code</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="R-sim-probability.html"><a href="R-sim-probability.html#diff-2dice-R"><i class="fa fa-check"></i><b>B.2</b> Difference of two dice</a></li>
<li class="chapter" data-level="B.3" data-path="R-sim-probability.html"><a href="R-sim-probability.html#flip-coin-R"><i class="fa fa-check"></i><b>B.3</b> Flipping a coin</a></li>
<li class="chapter" data-level="B.4" data-path="R-sim-probability.html"><a href="R-sim-probability.html#marbles-urn-R"><i class="fa fa-check"></i><b>B.4</b> Marbles from an urn</a></li>
<li class="chapter" data-level="B.5" data-path="R-sim-probability.html"><a href="R-sim-probability.html#partition-set-R"><i class="fa fa-check"></i><b>B.5</b> Splitting a set into multiple subsets</a>
<ul>
<li class="chapter" data-level="B.5.1" data-path="R-sim-probability.html"><a href="R-sim-probability.html#final-code-1"><i class="fa fa-check"></i><b>B.5.1</b> Final Code</a></li>
</ul></li>
<li class="chapter" data-level="B.6" data-path="R-sim-probability.html"><a href="R-sim-probability.html#license-plates-R"><i class="fa fa-check"></i><b>B.6</b> Oregon License Plates</a>
<ul>
<li class="chapter" data-level="B.6.1" data-path="R-sim-probability.html"><a href="R-sim-probability.html#final-code-2"><i class="fa fa-check"></i><b>B.6.1</b> Final Code</a></li>
</ul></li>
<li class="chapter" data-level="B.7" data-path="R-sim-probability.html"><a href="R-sim-probability.html#pollsters-R"><i class="fa fa-check"></i><b>B.7</b> Pollsters</a></li>
<li class="chapter" data-level="B.8" data-path="R-sim-probability.html"><a href="R-sim-probability.html#same-birthday-R"><i class="fa fa-check"></i><b>B.8</b> Matching Birthdays</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="R-discreteRV.html"><a href="R-discreteRV.html"><i class="fa fa-check"></i><b>C</b> Discrete Random Variables in R</a>
<ul>
<li class="chapter" data-level="C.1" data-path="R-discreteRV.html"><a href="R-discreteRV.html#expected-value-of-x"><i class="fa fa-check"></i><b>C.1</b> Expected Value of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="C.2" data-path="R-discreteRV.html"><a href="R-discreteRV.html#variance-of-x"><i class="fa fa-check"></i><b>C.2</b> Variance of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="C.3" data-path="R-discreteRV.html"><a href="R-discreteRV.html#distribution-plots"><i class="fa fa-check"></i><b>C.3</b> Distribution Plots</a></li>
<li class="chapter" data-level="C.4" data-path="R-discreteRV.html"><a href="R-discreteRV.html#sampling"><i class="fa fa-check"></i><b>C.4</b> Sampling</a></li>
<li class="chapter" data-level="C.5" data-path="R-discreteRV.html"><a href="R-discreteRV.html#estimating-distributions-via-simulation"><i class="fa fa-check"></i><b>C.5</b> Estimating Distributions via Simulation</a></li>
<li class="chapter" data-level="C.6" data-path="R-discreteRV.html"><a href="R-discreteRV.html#discrete-uniform-distribution"><i class="fa fa-check"></i><b>C.6</b> Discrete Uniform Distribution</a></li>
<li class="chapter" data-level="C.7" data-path="R-discreteRV.html"><a href="R-discreteRV.html#r-4distn-functions"><i class="fa fa-check"></i><b>C.7</b> Important discrete random variables</a>
<ul>
<li class="chapter" data-level="C.7.1" data-path="R-discreteRV.html"><a href="R-discreteRV.html#binomial-distribution-binom"><i class="fa fa-check"></i><b>C.7.1</b> Binomial Distribution <code>binom</code></a></li>
<li class="chapter" data-level="C.7.2" data-path="R-discreteRV.html"><a href="R-discreteRV.html#geometric-distribution-geom"><i class="fa fa-check"></i><b>C.7.2</b> Geometric Distribution <code>geom</code></a></li>
<li class="chapter" data-level="C.7.3" data-path="R-discreteRV.html"><a href="R-discreteRV.html#negative-binomial-distribution-nbinom"><i class="fa fa-check"></i><b>C.7.3</b> Negative Binomial Distribution <code>nbinom</code></a></li>
<li class="chapter" data-level="C.7.4" data-path="R-discreteRV.html"><a href="R-discreteRV.html#hypergeometric-distribution-hyper"><i class="fa fa-check"></i><b>C.7.4</b> Hypergeometric Distribution <code>hyper</code></a></li>
<li class="chapter" data-level="C.7.5" data-path="R-discreteRV.html"><a href="R-discreteRV.html#poisson-distribution-pois"><i class="fa fa-check"></i><b>C.7.5</b> Poisson Distribution <code>pois</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="R-continuousRV.html"><a href="R-continuousRV.html"><i class="fa fa-check"></i><b>D</b> Continuous Random Variables in R</a>
<ul>
<li class="chapter" data-level="D.1" data-path="R-continuousRV.html"><a href="R-continuousRV.html#unifR"><i class="fa fa-check"></i><b>D.1</b> Uniform Distribution</a>
<ul>
<li class="chapter" data-level="D.1.1" data-path="R-continuousRV.html"><a href="R-continuousRV.html#picking-random-numbers"><i class="fa fa-check"></i><b>D.1.1</b> Picking random numbers!</a></li>
<li class="chapter" data-level="D.1.2" data-path="R-continuousRV.html"><a href="R-continuousRV.html#picking-random-points-in-the-unit-square"><i class="fa fa-check"></i><b>D.1.2</b> Picking random points in the unit square!</a></li>
<li class="chapter" data-level="D.1.3" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimate-the-value-of-pi"><i class="fa fa-check"></i><b>D.1.3</b> Estimate the value of <span class="math inline">\(\pi\)</span></a></li>
</ul></li>
<li class="chapter" data-level="D.2" data-path="R-continuousRV.html"><a href="R-continuousRV.html#normalR"><i class="fa fa-check"></i><b>D.2</b> Normal Distribution <code>norm</code></a>
<ul>
<li class="chapter" data-level="D.2.1" data-path="R-continuousRV.html"><a href="R-continuousRV.html#sampling-distribution-of-a-sample-mean"><i class="fa fa-check"></i><b>D.2.1</b> Sampling Distribution of a sample mean</a></li>
</ul></li>
<li class="chapter" data-level="D.3" data-path="R-continuousRV.html"><a href="R-continuousRV.html#expR"><i class="fa fa-check"></i><b>D.3</b> Exponential Distribution <code>exp</code></a></li>
<li class="chapter" data-level="D.4" data-path="R-continuousRV.html"><a href="R-continuousRV.html#gammaR"><i class="fa fa-check"></i><b>D.4</b> Gamma Distribution <code>gamma</code></a></li>
<li class="chapter" data-level="D.5" data-path="R-continuousRV.html"><a href="R-continuousRV.html#chiR"><i class="fa fa-check"></i><b>D.5</b> Chi-square Distribution <code>chisq</code></a></li>
<li class="chapter" data-level="D.6" data-path="R-continuousRV.html"><a href="R-continuousRV.html#betaR"><i class="fa fa-check"></i><b>D.6</b> Beta distribution <code>beta</code></a></li>
<li class="chapter" data-level="D.7" data-path="R-continuousRV.html"><a href="R-continuousRV.html#customR"><i class="fa fa-check"></i><b>D.7</b> Homemade Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="D.7.1" data-path="R-continuousRV.html"><a href="R-continuousRV.html#input-the-density-function"><i class="fa fa-check"></i><b>D.7.1</b> Input the density function</a></li>
<li class="chapter" data-level="D.7.2" data-path="R-continuousRV.html"><a href="R-continuousRV.html#visualize-the-density-function"><i class="fa fa-check"></i><b>D.7.2</b> Visualize the density function</a></li>
<li class="chapter" data-level="D.7.3" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimating-integrals-with-riemann-sums"><i class="fa fa-check"></i><b>D.7.3</b> Estimating Integrals with Riemann Sums</a></li>
<li class="chapter" data-level="D.7.4" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimating-probabilities"><i class="fa fa-check"></i><b>D.7.4</b> Estimating Probabilities</a></li>
<li class="chapter" data-level="D.7.5" data-path="R-continuousRV.html"><a href="R-continuousRV.html#the-distribution-function-fx"><i class="fa fa-check"></i><b>D.7.5</b> The distribution function <span class="math inline">\(F(X)\)</span></a></li>
<li class="chapter" data-level="D.7.6" data-path="R-continuousRV.html"><a href="R-continuousRV.html#estimating-moments"><i class="fa fa-check"></i><b>D.7.6</b> Estimating Moments</a></li>
<li class="chapter" data-level="D.7.7" data-path="R-continuousRV.html"><a href="R-continuousRV.html#expected-value-1"><i class="fa fa-check"></i><b>D.7.7</b> Expected Value</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH 340 Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="probability-theory" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">5</span> Probability Theory<a href="probability-theory.html#probability-theory" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="conditional-probability-and-independence" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Conditional Probability and Independence<a href="probability-theory.html#conditional-probability-and-independence" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose we have a probability model associated to a sample space <span class="math inline">\(S\)</span>. If we are told some event <span class="math inline">\(B\)</span> has occurred, how would the probability of other events change? Calculating a new probability for event <span class="math inline">\(A\)</span>, given that <span class="math inline">\(B\)</span> has occurred is called a conditional probability, and will be denoted <span class="math inline">\(P(A|B)\)</span>.</p>
<p>For instance, Let <span class="math inline">\(X\)</span> denote the outcome if we roll a fair six-sided die. Let <span class="math inline">\(A\)</span> be the event that we roll a 4, and <span class="math inline">\(B\)</span> the event that we roll an even number. Since the die is fair, we expect that <span class="math inline">\(P(A) = 1/6\)</span>. Now suppose that the die is rolled and we are told that the event <span class="math inline">\(B\)</span> has occurred. This leaves only three possible outcomes: 2, 4, and 6. The new, conditional probability of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span> would be <span class="math inline">\(P(A|B) = 1/3.\)</span></p>
<div class="definition">
<p><span id="def:cond-prob" class="definition"><strong>Definition 5.1  </strong></span>The <strong>conditional probability</strong> of an event <span class="math inline">\(A\)</span>, given that an event <span class="math inline">\(B\)</span> has occurred, denoted <span class="math inline">\(P(A|B)\)</span>, is
<span class="math display" id="eq:condprob">\[\begin{equation}
  P(A|B) = \frac{P(A \cap B)}{P(B)},
  \tag{5.1}
\end{equation}\]</span>
provided that <span class="math inline">\(P(B) &gt; 0\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-7" class="example"><strong>Example 5.1  </strong></span>For the 2023 Major League Baseball season, 328 hitters had at least 250 plate appearances. In this group, 71% of them hit at least 10 HR for the season, and 31% of them hit at least 20 HR. If you pick a player from this group at random, and you are told they hit over at least 10 HR, what is the probability that they hit at least 20 HR?</p>
<p>Let <span class="math inline">\(A\)</span> be the event that the player hits at least 20 HR, and <span class="math inline">\(B\)</span> the event that a player hit at least 10. Then we have been asked to find <span class="math inline">\(P(A|B)\)</span>. Note that <span class="math inline">\(A\)</span> is a subset of <span class="math inline">\(B\)</span> (if a player hit at least 20, then they also hit at least 10), so <span class="math inline">\(A \cap B\)</span> = <span class="math inline">\(A\)</span>, and it follows that
<span class="math display">\[\begin{align*}
P(A|B) &amp;= \frac{P(A \cap B)}{P(B)} \\
      &amp;= \frac{P(A)}{P(B)} \\
      &amp;= \frac{.31}{.71}\\
      &amp;\approx .437.
\end{align*}\]</span></p>
</div>
<p>Note that from the conditional probability formula,</p>
<p><span class="math display">\[P(A \cap B) = P(B) \cdot P(A~|~B), \text{ provided }P(B)&gt;0,\]</span>
and that</p>
<p><span class="math display">\[P(A \cap B) = P(A) \cdot P(B~|~A), \text{ provided }P(A)&gt;0.\]</span></p>
<div class="definition">
<p><span id="def:unlabeled-div-8" class="definition"><strong>Definition 5.2  </strong></span>Two events are called <strong>independent</strong> if any of the following statements holds:</p>
<p><span class="math display">\[\begin{align*}
  P(A~|~B) &amp;= P(A) \\
  P(B~|~A) &amp;= P(B) \\
  P(A \cap B) &amp;= P(A)\cdot P(B)
\end{align*}\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-9" class="example"><strong>Example 5.2  </strong></span>The chance experiment “roll a 6-sided die” has sample space <span class="math inline">\(S = \{1, 2, 3, 4, 5, 6\}\)</span>.
Consider the events</p>
<p><span class="math display">\[\begin{align*}
A &amp;= \{1,3,5\}\\
B &amp;= \{1\}\\
C &amp;= \{2\}\\
D &amp;= \{1,2\}
\end{align*}\]</span></p>
<p>Then <span class="math inline">\(P(A) = 1/2, P(B) = 1/6, P(C) = 1/6\)</span>, and <span class="math inline">\(P(D) = 1/3.\)</span></p>
<p><strong>Claim 1</strong>: <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> are independent events.</p>
<p><strong>Reason 1</strong>: Well, <span class="math inline">\(A \cap D = \{1\}\)</span>, so
<span class="math display">\[P(A~|~D) = \frac{P(A\cap D)}{P(D)} = \frac{1/6}{1/3} = 1/2 = P(A).\]</span>
<strong>Claim 2</strong>: <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> are not independent events.</p>
<p><strong>Reason 2</strong>: <span class="math inline">\(B \cap C = \emptyset\)</span>, so <span class="math display">\[P(B~|~C) = \frac{P(B\cap C)}{P(C)} = \frac{0}{1/6} = 0 \neq P(B).\]</span></p>
<p>These simple examples help me remember that for events associated to a sample space,</p>
<blockquote>
<p>independent is different than disjoint!</p>
</blockquote>
<p>In this example <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> are independent but not disjoint, while <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> are disjoint but not independent.</p>
</div>
<div class="example">
<p><span id="exm:plumbing" class="example"><strong>Example 5.3  </strong></span>Suppose over the last five years, 10% of all people in a town who have hired a plumber to do some work have been unhappy with the job that was done. One of the plumbers in the town is Frances. Frances has done 40% of the plumbing jobs in town over these five years, and 25% of all plumbing jobs that left the customer unhappy have been done by Frances.</p>
<blockquote>
<p>Find the probability that a customer will be unhappy with the results if they hire Francis?</p>
</blockquote>
<p>We begin by translating what we know and what we want into symbols and probability notation.</p>
<p>Let <span class="math inline">\(S = \{ \text{all plumbing jobs in the town over the last 5 years} \}.\)</span></p>
<p>Let <span class="math inline">\(A = \{ \text{jobs handled by Frances} \}.\)</span></p>
<p>Let <span class="math inline">\(B = \{ \text{jobs in which the customer is unhappy} \}.\)</span></p>
<p>What do we want? <span class="math inline">\(P(B~|~A).\)</span></p>
<p>When do we want it? Now! So let’s write down what we know.</p>
<p>What do we know?</p>
<ul>
<li>10% of the jobs have left the customer unhappy <span class="math inline">\(~~\Rightarrow~~~~ P(B) = 0.1\)</span>.</li>
<li>Frances has done 40% of all jobs <span class="math inline">\(~~\Rightarrow~~~~ P(A) = 0.4\)</span>.</li>
<li>25% of all complaints dealt with Frances <span class="math inline">\(~~\Rightarrow~~~~ P(A~|~B) = 0.25\)</span>.</li>
</ul>
<p>Well,
<span class="math display">\[\begin{align*}
P(B~|~A) &amp;= \frac{P(A\cap B)}{P(A)} \\
         &amp;= \frac{P(A ~|~B)\cdot P(B)}{P(A)} \\
         &amp;= \frac{(0.25)(0.1)}{(0.4)} \\
         &amp;= 0.0625.
\end{align*}\]</span></p>
<p>Ok, there is about a 6 percent chance that a customer will be unhappy with their plumbing job if they hire Francis.</p>
<p>An irresponsible person who wants to be intentionally misleading could rant in all caps “25 PERCENT OF UNHAPPY CUSTOMERS HIRED FRANCIS!!!” Let’s be better than that. Knowing the full context here, which includes what proportion of the town’s plumbing jobs have gone to Frances, is necessary to establish how effective Frances has been as a plumber these last five years.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-10" class="example"><strong>Example 5.4  </strong></span></p>
<blockquote>
<p>Roll 2 6-sided dice. What is the probability that both values are less than 3?</p>
</blockquote>
<p>We assume the two dice are independent. (What appears on one die is independent of what appears on the other.)</p>
<p>Let <span class="math inline">\(A = \{ \text{first die is less than 3}\}\)</span> and <span class="math inline">\(B = \{ \text{second die is less than 3}\}.\)</span></p>
<p>“Less than 3” means “1 or 2” so <span class="math inline">\(P(A) = P(B) = 2/6 = 1/3.\)</span>
The question asks for <span class="math inline">\(P(A \cap B).\)</span> Since <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent, <span class="math display">\[P(A \cap B) = P(A)\cdot P(B) = (1/3)\cdot(1/3) = 1/9.\]</span></p>
<p>We remark that we can also use counting techniques to find this probability directly in Section <a href="counting.html#prob-with-counting-tools">4.6</a>.</p>
<p>The sample space <span class="math inline">\(S\)</span> of this chance experiment consists of all possible rolls of the two dice. That is, <span class="math inline">\(S\)</span> consists of all ordered pairs of the form <span class="math inline">\((i,j)\)</span> with <span class="math inline">\(i, j \in \mathbb{N}\)</span> and <span class="math inline">\(1\leq i, j \leq 6\)</span>, and <span class="math inline">\(|S| = 6^2\)</span>. The event of interest, <span class="math inline">\(E\)</span>, consists of all rolls <span class="math inline">\((i,j)\)</span> in <span class="math inline">\(S\)</span> such that <span class="math inline">\(i, j \leq 2\)</span>. So, <span class="math inline">\(|E| = 2^2\)</span>, and <span class="math inline">\(P(E) = 4/36 = 1/9\)</span>.</p>
<p>So, thinking of the chance experiment as a sequence of independent events we calculate the probability of interest as <span class="math inline">\(\frac{2}{6} \cdot \frac{2}{6},\)</span>, and thinking of the probability via the “(outcomes of interest)/(all possible outcomes)” approach we think of the probability as <span class="math inline">\(\frac{2\cdot 2}{6 \cdot 6}\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:four-on-rolll-8" class="example"><strong>Example 5.5  </strong></span>Roll a regular 6-sided die until a 4 comes up. What is the probability that this occurs on the 8th roll?</p>
<p>The values of the rolls are independent events, the probability of not rolling a four on a given roll is 5/6, and the probability of rolling a 4 is 1/6. It follows that the probability of rolling 7 non-4s followed by 1 4 is
<span class="math display">\[P(\text{first 4 on roll 8}) = \left(\frac{5}{6}\right)^7 \cdot \left(\frac{1}{6}\right).\]</span>
More generally, the probability that our first 4 comes up on roll <span class="math inline">\(n\)</span> (for any <span class="math inline">\(n \in \mathbb{N}\)</span>) will be
<span class="math display">\[P(\text{first 4 on roll }n) = \left(\frac{5}{6}\right)^{n-1} \cdot \left(\frac{1}{6}\right).\]</span></p>
</div>
</div>
<div id="two-laws-of-probability" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Two Laws of Probability<a href="probability-theory.html#two-laws-of-probability" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="theorem">
<p><span id="thm:two-prob-laws" class="theorem"><strong>Theorem 5.1  </strong></span>Suppose <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are two events.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Multiplicative Law of Probability</strong>:
<span class="math display">\[\begin{align*}
  P(A \cap B) &amp;= P(A)\cdot P(B~|~A) \\
           &amp;= P(B) \cdot (A~|~B)
  \end{align*}\]</span></p></li>
<li><p><strong>Additive Law of Probability</strong>:
<span class="math display">\[P(A\cup B) = P(A) + P(B) - P(A \cap B).\]</span></p></li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-11" class="proof"><em>Proof</em>. </span></p>
<ol style="list-style-type: decimal">
<li><p>This proof follows directly from the definition of conditional probability (<a href="probability-theory.html#def:cond-prob">5.1</a>).</p></li>
<li><p>For finite sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, we know <span class="math display">\[|A \cup B| = |A| + |B| - |A \cap B|,\]</span> from which the result follows.</p></li>
</ol>
<p>More generally, for any sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, the union <span class="math inline">\(A \cup B\)</span> can be decomposed into disjoint sets: <span class="math inline">\(A \cup B = A \cup (\overline{A} \cap B).\)</span>
So, <span class="math display">\[P(A \cup B) = P(A) + P(\overline{A} \cap B).\]</span></p>
<p>Similarly, we can decompose the set <span class="math inline">\(B\)</span> into disjoint sets as follows: <span class="math inline">\(B = (\overline{A} \cap B) \cup (A \cap B).\)</span>
So <span class="math display">\[P(B) = P(\overline{A}\cap B) + P(A \cap B).\]</span>
Combining these two probability equations we see <span class="math display">\[P(A \cup B) = P(A) + \left[P(B)-P(A\cap B)\right].\]</span></p>
</div>
<p>For three events, <span class="math inline">\(A_1, A_2, A_3\)</span> it follows that</p>
<p><span class="math display">\[\begin{align*}
P(A_1 \cap A_2 \cap A_3) &amp;= P((A_1\cap A_2) \cap A_3) \\
                         &amp;= P(A_1 \cap A_2) \cdot P(A_3~|~A_1 \cap A_2)\\
                         &amp;= P(A_1) \cdot P(A_2~|~A_1) \cdot P(A_3~|~A_1 \cap A_2).
\end{align*}\]</span></p>
<p>This formula may be extended to the intersection of any number of sets.</p>
<p><span class="math display" id="eq:prob-intersection">\[\begin{equation}
  P(A_1 \cap \cdots \cap A_k) = P(A_1) \cdot P(A_2 ~|~ A_1) \cap  \cdots \cap P(A_k ~|~ (A_1 \cap \cdots \cap A_{k-1}))
  \tag{5.2}
\end{equation}\]</span></p>
<div class="example">
<p><span id="exm:all-hearts" class="example"><strong>Example 5.6  </strong></span>Flip over 4 cards from a regular 52-card deck. What is the probability they are all hearts?</p>
<p>We flip the cards over one at a time, and define the four events <span class="math inline">\(A_i\)</span> = the event that card <span class="math inline">\(i\)</span> is a hearts, for <span class="math inline">\(i = 1, 2, 3, 4\)</span>.</p>
<p>We want the probability that all four events occur. That is, we want <span class="math inline">\(P(A_1 \cap A_2 \cap A_3 \cap A_4),\)</span> and we find this using Equation <a href="probability-theory.html#eq:prob-intersection">(5.2)</a>.</p>
<p><span class="math display">\[\begin{align*}
P(A_1 \cap A_2 \cap A_3 \cap A_4) &amp;= P(A_1) \cdot P(A_2 ~|~ A_1) \cdot P(A_3 ~|~ A_1 \cap A_2) \cdot P(A_4 ~|~ A_1 \cap A_2 \cap A_{3})\\
&amp;= \frac{13}{52} \cdot \frac{12}{51} \cdot \frac{11}{50} \cdot \frac{10}{49} \\
&amp;\approx 0.0026.
\end{align*}\]</span></p>
</div>
<div class="example">
<p><span id="exm:mult-law" class="example"><strong>Example 5.7  </strong></span></p>
<blockquote>
<p>Find the probability that a random 4 digit number has distinct odd digits.</p>
</blockquote>
<p>Two notes: We have 5 odd digits, and the leading (thousands) digit of a 4-digit number cannot be 0.</p>
<p>Using the multiplicative law of probability we calculate the probability of a sequence of events and multiply them:</p>
<ul>
<li>The probability that the leading digit is odd: 5/9.</li>
<li>The probability that the 2nd digit is odd, given the first was: 4/10.</li>
<li>The probability that the 3rd digit is odd, given the first two were: 3/10.</li>
<li>The probability that the 4th digit is odd, given the first three were: 2/10.</li>
</ul>
<p>By the multiplicative law of probability, the probability that a random 4-digit number has distinct odd digits is <span class="math display">\[\frac{5}{9} \cdot \frac{4}{10} \cdot \frac{3}{10} \cdot \frac{2}{10} \approx 0.0133.\]</span></p>
</div>
<p>We have three corollaries to Theorem <a href="probability-theory.html#thm:two-prob-laws">5.1</a>.</p>
<div class="corollary">
<p><span id="cor:comp-prob" class="corollary"><strong>Corollary 5.1  </strong></span>For any event <span class="math inline">\(A\)</span>, <span class="math display">\[P(\overline{A}) = 1 - P(A).\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-12" class="proof"><em>Proof</em>. </span>By the additive law, <span class="math display">\[P(A \cup \overline{A}) = P(A) + P(\overline{A})-P(A \cap \overline{A}).\]</span>
Since <span class="math inline">\(A\cup \overline{A} = S\)</span> and <span class="math inline">\(A \cap \overline{A} = \emptyset\)</span>, <span class="math inline">\(P(A \cup \overline{A}) = 1\)</span> and <span class="math inline">\(P(A \cap \overline{A}) = 0\)</span>, so <span class="math display">\[1 = P(A) + P(\overline{A}),\]</span> and the result follows.</p>
</div>
<div class="corollary">
<p><span id="cor:unlabeled-div-13" class="corollary"><strong>Corollary 5.2  </strong></span>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are disjoint events, then <span class="math inline">\(P(A \cup B) = P(A) + P(B).\)</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-14" class="proof"><em>Proof</em>. </span>Since <span class="math inline">\(A\cap B = \emptyset\)</span>, <span class="math inline">\(P(A \cap B) = 0\)</span> and the result follows from the Additive Law of Probability.</p>
</div>
<div class="corollary">
<p><span id="cor:unlabeled-div-15" class="corollary"><strong>Corollary 5.3  </strong></span>For three events <span class="math inline">\(A, B, C\)</span>.</p>
<p>The probability of their union is</p>
<p><span class="math display">\[\begin{align*}
P(A \cup B \cup C) &amp;= P(A)+P(B)+P(C)\\
                   &amp;~~~~ - [P(A\cap B) + P(A \cap C) + P(B \cap C)]\\
                   &amp;~~~~ + P(A \cap B \cap C).
\end{align*}\]</span></p>
<p>The probability of their intersection is
<span class="math display">\[P(A \cap B \cap C) = P(A) \cdot P(B~|~A) \cdot P(C ~|~ A \cap B).\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-16" class="proof"><em>Proof</em>. </span>First we tackle the union case by appealing to the additive law of probability twice, along a the distributive law of sets.</p>
<p><span class="math display">\[\begin{align*}
P(A \cup B \cup C) &amp;= P(A \cup (B \cup C)) \\
                   &amp;= P(A) + P(B \cup C) - P(A \cap (B \cup C)) \\
                   &amp;= P(A) + [P(B) + P(C)- P(B \cap C)] - P((A\cap B) \cup (A \cap C)) \\
                   &amp;= P(A) + P(B) + P(C) - P(B \cap C) \\
                   &amp;~~~~ - [P(A \cap B)+ P(A \cap C)-P((A \cap B) \cap (A \cap C))]\\
                   &amp;= P(A) + P(B) + P(C) \\
                   &amp;~~~~ - [P(A\cap B) + P(A \cap C) + P(B \cap C)] \\
                   &amp;~~~~ + P((A \cap B) \cap (A \cap C))
\end{align*}\]</span></p>
<p>from which the result follows since <span class="math inline">\(A \cap B \cap A \cap C = A \cap B \cap C\)</span>.</p>
<p>For the intersection case, by definition of conditional probability the right hand side of the equation is
<span class="math display">\[\text{RHS } = P(A) \cdot \frac{P(A \cap B)}{P(A)} \cdot \frac{P(C\cap A\cap B)}{P(A \cap B)},\]</span> and the result follows by cancellation.</p>
</div>
</div>
<div id="event-composition-method" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Event-Composition Method<a href="probability-theory.html#event-composition-method" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We’ve been using a method called the event-composition method for calculating probabilities associated to an experiment.</p>
<blockquote>
<p><strong>Event-Composition Method</strong>: Describe the sample space and relevant events; write down what information we’re given regarding probabilities etc. via the symbols representing these events; Express what we want to know via these symbols, and use our probability laws to use what we know to determine what we want.</p>
</blockquote>
<div class="example">
<p><span id="exm:craps-4-before-7" class="example"><strong>Example 5.8  </strong></span>Two regular 6-sided dice are rolled and we record the sum.</p>
<blockquote>
<p>What is the probability that we roll a 4 before we roll a 7?</p>
</blockquote>
<p>We define two key events:</p>
<ul>
<li><span class="math inline">\(A\)</span>: we roll a sum of 4; and</li>
<li><span class="math inline">\(B\)</span>: we do not roll a 4 or 7.</li>
</ul>
<p>From our handy <span class="math inline">\(6 \times 6\)</span> grid describing all possible sums when rolling 2 dice (Example <a href="discrete-probability-distributions.html#exm:roll2dice">3.3</a>), we know <span class="math display">\[P(A) = \frac{3}{36}, P(B) = \frac{27}{36}.\]</span></p>
<p>In this game we roll the dice until we roll a 4 or a 7, and we <strong>win</strong> if we roll a 4 before rolling a 7.</p>
<p>There is no limit to how many rolls we might need in order to win.
We might win on the 1st roll, or the 2nd roll, or the 3rd roll, or the 4th roll, … etc. In fact, for each <span class="math inline">\(n \in \mathbb{N}\)</span>, we might win on roll <span class="math inline">\(n\)</span>.</p>
<p>Put another way, we can partition the event of winning into a countably infinite collection of mutually disjoint events: winning on roll 1, winning on roll 2, winning on roll 3, etc. Then,
<span class="math display">\[P(\text{winning}) = \sum_{n=1}^\infty P(\text{winning on roll }n).\]</span></p>
<p>The probability of winning on the 1st roll is <span class="math inline">\(P(A)\)</span>.</p>
<p>The probability of winning on the 2nd roll is <span class="math inline">\(P(B) \cdot P(A)\)</span> (no 4 or 7 on 1st roll and yes 4 on the 2nd roll).</p>
<p>The probability of winning on the 3rd roll is <span class="math inline">\(P(B) \cdot P(B) \cdot P(A)\)</span>, and, more generally, the probability of winning on roll <span class="math inline">\(n\)</span> is <span class="math display">\[P(B)^{n-1}\cdot P(A).\]</span></p>
<p>The sum of these probabilities is an honest-to-goodness-living-in-the-wild geometric series:</p>
<p><span class="math display">\[\begin{align*}
P(\text{4 before 7}) &amp;= \sum_{n=1}^\infty P(B)^{n-1}P(A)\\
                     &amp;= P(A)\sum_{n=0}^\infty P(B)^n\\
                     &amp;= (3/36)\sum_{n=0}^\infty (27/36)^n
\end{align*}\]</span></p>
<p>As a reminder, the sum of a geometric series is given by
<span class="math display" id="eq:geometric-series">\[\begin{equation}
\sum_{n=0}^\infty r^n = \frac{1}{1-r} \text{ if } |r| &lt; 1
\tag{5.3}
\end{equation}\]</span></p>
<p>Using this formula with <span class="math inline">\(r = 27/36\)</span>, we see the probability that we roll a 4 before a 7 is <span class="math display">\[P(\text{4 before 7}) = \frac{1}{3}.\]</span></p>
</div>
</div>
<div id="bayes-rule" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Bayes’ Rule<a href="probability-theory.html#bayes-rule" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="definition">
<p><span id="def:partition" class="definition"><strong>Definition 5.3  </strong></span>A collection <span class="math inline">\(\{B_1, B_2, \ldots, B_n\}\)</span> of nonempty subsets of <span class="math inline">\(S\)</span> is called a <strong>partition</strong> of <span class="math inline">\(S\)</span> provided that</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(S = B_1 \cup B_2 \cup \cdots \cup B_n\)</span>, and</li>
<li>the collection is pairwise disjoint.</li>
</ol>
</div>
<div class="theorem">
<p><span id="thm:total-law-prob" class="theorem"><strong>Theorem 5.2  (Law of Total Probability) </strong></span>Assume <span class="math inline">\(\{B_1, B_2, \ldots B_k\}\)</span> is a partition of the sample space <span class="math inline">\(S\)</span>, and <span class="math inline">\(P(B_i) &gt; 0\)</span> for each <span class="math inline">\(i = 1, 2, \ldots k\)</span>. Then for any event <span class="math inline">\(A\)</span>, <span class="math display">\[P(A) = \sum_{i=1}^k P(A~|~B_i)\cdot P(B_i).\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-17" class="proof"><em>Proof</em>. </span>Notice that as a set,
<span class="math display">\[\begin{align*}
A &amp;= A \cap S \\
  &amp;= A \cap (B_1 \cup B_2 \cup \cdots \cup B_k) \\
  &amp;= (A \cap B_1) \cup (A \cap B_2) \cup \cdots \cup (A \cap B_k).
\end{align*}\]</span></p>
<p>Furthermore, since the <span class="math inline">\(B_i\)</span> are pairwise disjoint, the <span class="math inline">\((A \cap B_i)\)</span> are pairwise dijoint as well, and by the additive law of probability <span class="math display">\[P(A) = \sum_{i = 1}^k P(A \cap B_i).\]</span></p>
<p>The result then follows since each <span class="math inline">\(P(A \cap B_i) = P(A~|~B_i)\cdot P(B_i)\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:ad-agency" class="example"><strong>Example 5.9  </strong></span>An ad agency notices</p>
<ul>
<li>1 in 50 potential buyers of a particular product sees an advertisement for it on television</li>
<li>1 in 5 potential buyers sees the ad on YouTube.</li>
<li>1 in 100 sees the ad on both TV and YouTube.</li>
<li>1 in 3 potential buyers actually purchase the product after seeing an ad, and</li>
<li>1 in 10 potential buyers buy it without seeing an ad.</li>
</ul>
<blockquote>
<p>What is the probability that a radnomly selected potential buyer will purchase the product?</p>
</blockquote>
<p>We define relevant events for the sample space <span class="math inline">\(S = \{ \text{ all potential buyers }\}\)</span>. In particular, we let</p>
<ul>
<li><span class="math inline">\(A\)</span> = the set of potential buyers who purchase the product,</li>
<li><span class="math inline">\(B\)</span> = the set of potential buyers who see the ad on TV,</li>
<li><span class="math inline">\(C\)</span> = the set of potential buyers who see the ad on YouTube.</li>
</ul>
<p>Next we translate what we know and what we want into symbols.</p>
<p>What we want: <span class="math inline">\(P(A)\)</span>.</p>
<p>What we know:</p>
<ul>
<li><span class="math inline">\(P(B) = 1/50\)</span>,</li>
<li><span class="math inline">\(P(C) = 1/5\)</span>,</li>
<li><span class="math inline">\(P(B \cap C) = 1/100\)</span>,</li>
<li><span class="math inline">\(P(A ~|~ B \cup C) = 1/3\)</span>, and</li>
<li><span class="math inline">\(P(A ~|~ \overline{B \cup C}) = 1/10.\)</span></li>
</ul>
<p>We also know by the additive law of probability that</p>
<p><span class="math display">\[P(B \cup C) = \frac{1}{50} + \frac{1}{5} - \frac{1}{100} = \frac{21}{100},\]</span> so by Corollary <a href="probability-theory.html#cor:comp-prob">5.1</a>, <span class="math display">\[P(\overline{B \cup C}) = 1 - \frac{21}{100} = \frac{79}{100}.\]</span>
Finally, notice that since <span class="math inline">\(B \cup C\)</span> and <span class="math inline">\(\overline{B \cup C}\)</span> partition the sample space, <span class="math display">\[A = \left[A \cap (B \cup C)\right] \cup \left[A \cap (\overline{B \cup C})\right],\]</span> where these two sets are disjoint.</p>
<p>By the Law of Total Probability,</p>
<p><span class="math display">\[\begin{align*}
P(A) &amp;= P(A \cap (B \cup C)) + P(A \cap (\overline{B \cup C)})\\
     &amp;= P(B \cup C) \cdot P(A ~|~ B \cup C) + P(\overline{B \cup C})\cdot P(A~|~\overline{B \cup C})\\
     &amp;= \frac{21}{100} \cdot {1}{3} + \frac{79}{100}\cdot {1}{10} \\
     &amp;= \frac{7}{100} \cdot \frac{7.9}{100} \\
     &amp;= 0.149.
\end{align*}\]</span></p>
</div>
<div class="example">
<p><span id="exm:bayes-intro" class="example"><strong>Example 5.10  </strong></span>Suppose you have taken a test for a deadly disease. The doctor tells you that the test is quite accurate in that if you have the disease then the test will correctly tell you that you have the disease 100% of the time. However, if you don’t have the disease, the test will very occasionally (1 time in 10) mistakenly tell you that you have it.</p>
<p>The test comes back positive (it says you have the disease)! Are you worried!? In particular, can you estimate the probability that you actually have the disease given that the test came back positive?</p>
<p>What information were we given? What information do we want?</p>
<p>We were given:</p>
<ul>
<li>The probability of a positive test given I have the disease is 1.</li>
<li>The probability of a positive test given I do not have the disease is 0.1</li>
</ul>
<p>We want:</p>
<ul>
<li>The probability I have the disease given that I have a positive test.</li>
</ul>
<p>Let <span class="math inline">\(A\)</span> denote the event that I have a positive test, <span class="math inline">\(B\)</span> the event that I have the disease.</p>
<p>Then I want <span class="math inline">\(P(B|A)\)</span> and I know <span class="math inline">\(P(A|B) = 1\)</span> and <span class="math inline">\(P(A|\overline{B}) = 0.1.\)</span></p>
<p>It turns out I need more information than I’ve been given to answer this question, as the following scenarios demonstrate.</p>
<p><em>Scenario 1</em>: Suppose the population consists of 100 people, and 50 people, in fact, have the disease (blue - healthy, red - sick in the figure below). Then, if we tested each individual we would find 55 positive tests (the circled dots below) (all 50 of the sick people would test positive, and 10% of the 50 healthy people, so 5 healthy people would also test positive.)</p>
<div class="figure"><span style="display:block;" id="fig:50-50-sick"></span>
<img src="math340-notes_files/figure-html/50-50-sick-1.png" alt="50% of population has the disease" width="288" />
<p class="caption">
Figure 5.1: 50% of population has the disease
</p>
</div>
<p>In this scenario, given that I tested positive, there is a 50/55 chance that I have the disease.</p>
<p><em>Scenario 2</em>: Suppose the population consists of 100 people, and 1 person, in fact, has the disease (blue - healthy, red - sick in the figure below). Then, if we tested each individual we would find about 11 positive tests (the circled dots below) (the one sick people would test positive, and 10% of the 99 healthy people, so about 10 healthy people would also test positive.)</p>
<div class="figure"><span style="display:block;" id="fig:1-99-sick"></span>
<img src="math340-notes_files/figure-html/1-99-sick-1.png" alt="1% of population has the disease" width="288" />
<p class="caption">
Figure 5.2: 1% of population has the disease
</p>
</div>
<p>In this scenario, given that I tested positive, there is a 1/11 chance that I have the disease.</p>
<p>So, it seems to answer the question in this example, it is important to know what percentage of the population have the disease. Baye’s Theorem below tells us that this is all the additional information we need.</p>
</div>
<div class="theorem">
<p><span id="thm:Bayes-rule" class="theorem"><strong>Theorem 5.3  (Bayes' Rule) </strong></span>Assume <span class="math inline">\(\{B_1, B_2, \ldots B_k\}\)</span> is a partition of the sample space <span class="math inline">\(S\)</span>, and <span class="math inline">\(P(B_i) &gt; 0\)</span> for each <span class="math inline">\(i = 1, 2, \ldots k\)</span>. Then for any particular <span class="math inline">\(B_j\)</span>, <span class="math display">\[P(B_j ~|~ A) = \frac{P(A~|~B_j)\cdot P(B_j)}{\sum_{i=1}^k P(A~|~B_i)\cdot P(B_i)}.\]</span></p>
</div>
<div class="example">
<p><span id="exm:bad-apples" class="example"><strong>Example 5.11  </strong></span>A grocery store has an apple bin. 70% of the apples are Liberty, and 30% are Braeburn. From past experience, we know that 8% of Liberty apples are bad, and 15% of Braeburn apples are bad. Suppose you pick an apple at random and find it is bad. What is the probability that the apple is a Braeburn?</p>
<p>We define our relevant sets.</p>
<ul>
<li><span class="math inline">\(S\)</span> = all apples in the bin</li>
<li><span class="math inline">\(B_1\)</span> = all Liberty apples in <span class="math inline">\(S\)</span></li>
<li><span class="math inline">\(B_2\)</span> = all Braeburn apples in <span class="math inline">\(S\)</span> (and the <span class="math inline">\(B_i\)</span> partition <span class="math inline">\(S\)</span>!)</li>
<li><span class="math inline">\(A\)</span> = bad apples in <span class="math inline">\(S\)</span>.</li>
</ul>
<p>We know:</p>
<ul>
<li><span class="math inline">\(P(B_1) = .7\)</span>, and <span class="math inline">\(P(B_2) = .3\)</span></li>
<li><span class="math inline">\(P(A~|~B_1) = .08\)</span>, and <span class="math inline">\(P(A~|~B_2) = .15\)</span>.</li>
</ul>
<p>We want:</p>
<ul>
<li><span class="math inline">\(P(B_2 ~|~ A)\)</span>.</li>
</ul>
<p>This task calls for Bayes’ Rule.</p>
<p><span class="math display">\[P(B_2~|~A) = \frac{P(A~|~B_2)\cdot P(B_1)}{P(A~|~B_1)\cdot P(B_2)+P(A~|~B_2)\cdot P(B_2)}.\]</span>
We know each probability in the right-hand side of the equation:
<span class="math display">\[P(B_2~|~A) = \frac{(.15)(.3)}{(.08)(.7)+(.15)(.3)} \approx .446.\]</span>
About a 44% chance that if we drew a bad apple it’s a Braeburn.</p>
<p>We can also use a tree diagram to arrive at this answer:</p>
<div class="figure"><span style="display:block;" id="fig:bayes-apple"></span>
<img src="math340-notes_files/figure-html/bayes-apple-1.png" alt="Picking an Apple" width="384" />
<p class="caption">
Figure 5.3: Picking an Apple
</p>
</div>
<p>From the diagram, the probability of picking a bad apple is <span class="math inline">\((.7)(.08) + (.3)(.15)\)</span> and the probability of picking a bad Braeburn is <span class="math inline">\((.3)(.15)\)</span>, so the probability of having picked a Braeburn, given we picked a bad apple is <span class="math display">\[\frac{(.3)(.15)}{(.7)(.08) + (.3)(.15)}.\]</span></p>
</div>
<div class="example">
<p><span id="exm:factory-skill" class="example"><strong>Example 5.12  </strong></span>Two methods, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are available for teaching a certain skill at a factory. The failure rate for <span class="math inline">\(A\)</span> is 20%, and for <span class="math inline">\(B\)</span> is 10%. However, <span class="math inline">\(B\)</span> is more expensive and is used only 30% of the time (<span class="math inline">\(A\)</span> is used the other 70%). A worker was taught the skill by one of the methods but failed to learn it correctly. What is the probability they were taught by Method <span class="math inline">\(A\)</span>?</p>
<p>Let <span class="math inline">\(S\)</span> denote the sample space of all workers who have been trained in this skill.</p>
<p>We have this partition of <span class="math inline">\(S\)</span>:</p>
<ul>
<li><span class="math inline">\(A\)</span> = those taught by method <span class="math inline">\(A\)</span></li>
<li><span class="math inline">\(B\)</span> = those taught by method <span class="math inline">\(B\)</span>.</li>
</ul>
<p>We also have <span class="math inline">\(F\)</span> = those who fail to learn the skill correctly.</p>
<p>We want: <span class="math inline">\(P(A~|~F)\)</span>.</p>
<p>We know: <span class="math inline">\(P(A) = .7\)</span>, <span class="math inline">\(P(B) = .3\)</span>, <span class="math inline">\(P(F~|~A) = .2\)</span>, and <span class="math inline">\(P(F~|~B) = .1\)</span>.</p>
<p>Using Bayes’ Rule,
<span class="math display">\[\begin{align*}
P(A~|~F) &amp;= \frac{P(A)\cdot P(F~|~A)}{P(A)\cdot P(F~|~A)+P(B)\cdot P(F~|~B)}\\
&amp;= \frac{(.7)(.2)}{(.7)(.2)+(.3)(.1)}\\
&amp;\approx .82.
\end{align*}\]</span>
Given a worker failed to learn the skill, there is about an 82% chance they had been taught by Method <span class="math inline">\(A\)</span>.</p>
<div class="figure"><span style="display:block;" id="fig:bayes-instruct-method"></span>
<img src="math340-notes_files/figure-html/bayes-instruct-method-1.png" alt="Learning by a Method" width="432" />
<p class="caption">
Figure 5.4: Learning by a Method
</p>
</div>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="counting.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="discrete-random-variables-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["math340-notes.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
